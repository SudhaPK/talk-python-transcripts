WEBVTT

00:00:00.000 --> 00:00:04.540
If you're a fan of Pydantic or data classes, you'll definitely be interested in this episode.


00:00:04.540 --> 00:00:09.800
We are talking about a super fast data modeling and validation framework called MessageSpec.


00:00:09.800 --> 00:00:15.800
And some of the types in here might even be better for general purpose use than Python's native classes.


00:00:15.800 --> 00:00:19.740
Join me and Jim Chris Hariff to talk about his framework, MessageSpec.


00:00:19.740 --> 00:00:25.460
This is Talk Python to Me, episode 442, recorded November 2nd, 2023.


00:00:25.460 --> 00:00:43.000
Welcome to Talk Python to Me, a weekly podcast on Python.


00:00:43.000 --> 00:00:44.760
This is your host, Michael Kennedy.


00:00:44.760 --> 00:00:52.240
Follow me on Mastodon, where I'm@mkennedy, and follow the podcast using @talkpython, both on fosstodon.org.


00:00:52.240 --> 00:00:55.340
Keep up with the show and listen to over seven years of past,


00:00:55.340 --> 00:00:57.340
episodes at talkpython.fm.


00:00:57.340 --> 00:01:01.100
We've started streaming most of our episodes live on YouTube.


00:01:01.100 --> 00:01:04.860
Subscribe to our YouTube channel over at talkpython.fm/youtube


00:01:04.860 --> 00:01:08.660
to get notified about upcoming shows and be part of that episode.


00:01:08.660 --> 00:01:14.200
This episode is sponsored by Posit Connect from the makers of Shiny.


00:01:14.200 --> 00:01:18.700
Publish, share, and deploy all of your data projects that you're creating using Python.


00:01:18.700 --> 00:01:24.560
Streamlet, Dash, Shiny, Bokeh, FastAPI, Flask, Reports, Dashboards, and APIs.


00:01:24.560 --> 00:01:25.040
Streamlet, Dash, Shiny, Bokeh, FastAPI, Flask, Reports, Dashboards, and APIs.


00:01:25.040 --> 00:01:25.160
Streamlet, Dash, Shiny, Bokeh, FastAPI, Flask, Reports, Dashboards, and APIs.


00:01:25.160 --> 00:01:25.180
Streamlet, Dash, Shiny, Bokeh, FastAPI, Flask, Reports, Dashboards, and APIs.


00:01:25.180 --> 00:01:27.040
Posit Connect supports all of them.


00:01:27.040 --> 00:01:32.700
Try Posit Connect for free by going to talkpython.fm/Posit, P-O-S-I-T.


00:01:32.700 --> 00:01:36.960
And it's brought to you by us over at Talk Python Training.


00:01:36.960 --> 00:01:41.580
Did you know that we have over 250 hours of Python courses?


00:01:41.580 --> 00:01:42.760
Yeah, that's right.


00:01:42.760 --> 00:01:45.320
Check them out at talkpython.fm/courses.


00:01:45.320 --> 00:01:48.000
Jim.


00:01:48.000 --> 00:01:48.580
Hello.


00:01:48.580 --> 00:01:48.940
Hello.


00:01:48.940 --> 00:01:50.080
Welcome to Talk Python To Me.


00:01:50.080 --> 00:01:50.960
It's awesome to have you here.


00:01:50.960 --> 00:01:51.920
Yeah, thanks for having me.


00:01:51.920 --> 00:01:52.640
Yeah, of course.


00:01:52.640 --> 00:01:54.660
I spoke to the Lightstar guys.


00:01:54.660 --> 00:01:57.140
You know, at Lightstar.dev and had them on the show.


00:01:57.140 --> 00:02:04.300
And I was talking about their DTOs, different types of objects they can pass around in their APIs and their web apps.


00:02:04.300 --> 00:02:12.720
And like FastAPI, they've got this concept where you kind of bind a type, like a class or something, to an input to a web API.


00:02:12.720 --> 00:02:15.460
And it does all that sort of magic like FastAPI.


00:02:15.460 --> 00:02:17.120
And I said, oh, so you guys probably work with PyDanta.


00:02:17.120 --> 00:02:19.800
It's like, yes, but let me tell you about MessageSpec.


00:02:19.800 --> 00:02:21.500
Because that's where the action is.


00:02:21.500 --> 00:02:24.640
They were so enamored with your project that I just had to reach out.


00:02:24.640 --> 00:02:25.320
And have you on.


00:02:25.320 --> 00:02:26.540
It looks super cool.


00:02:26.540 --> 00:02:28.620
I think people are going to really enjoy learning about it.


00:02:28.620 --> 00:02:29.380
Thanks.


00:02:29.380 --> 00:02:30.900
Yeah, it's nice to hear that.


00:02:30.900 --> 00:02:31.180
Yeah.


00:02:31.180 --> 00:02:33.080
We're going to dive into the details.


00:02:33.080 --> 00:02:33.960
It's going to be a lot of fun.


00:02:33.960 --> 00:02:39.760
Before we get to them, though, give us just a quick introduction on who you are so people don't know you yet.


00:02:39.760 --> 00:02:41.040
So my name's Jim Christreif.


00:02:41.040 --> 00:02:51.680
I am currently an engineering manager doing actually mostly dev work at Voltron Data, working on the IBIS project, which is a completely different conversation than what we're going to have today.


00:02:51.680 --> 00:02:53.600
Prior to that, I've worked on a couple of startups.


00:02:53.600 --> 00:02:54.600
And was.


00:02:54.600 --> 00:03:01.240
Most of them doing Dask was the main thing I've contributed to in the past on an open source Python front.


00:03:01.240 --> 00:03:04.360
For those not aware, Dask is a distributed compute ecosystem.


00:03:04.360 --> 00:03:09.200
I come from the PyData side of the Python ecosystem, not the web dev side.


00:03:09.200 --> 00:03:09.600
Nice.


00:03:09.600 --> 00:03:13.900
Yeah, I've had Matthew Rocklin on a couple of times, but it's been a while, so people don't necessarily know.


00:03:13.900 --> 00:03:18.120
But it's like super distributed pandas, kind of.


00:03:18.120 --> 00:03:19.920
Grid computing for pandas, sort of.


00:03:19.920 --> 00:03:22.860
Or say like Spark written in Python.


00:03:22.860 --> 00:03:23.300
Sure.


00:03:23.300 --> 00:03:24.500
You know, another thing that's been.


00:03:24.500 --> 00:03:29.780
Kind of on my radar, but I didn't really necessarily realize it was associated with you.


00:03:29.780 --> 00:03:31.280
Tell people just a bit about IBIS.


00:03:31.280 --> 00:03:33.120
Like IBIS is looking pretty interesting.


00:03:33.120 --> 00:03:35.300
I don't want to say the wrong thing.


00:03:35.300 --> 00:03:38.800
IBIS is a portable data frame library is the current tagline we're using.


00:03:38.800 --> 00:03:42.580
If you're coming from R, it's dplyr for Python.


00:03:42.580 --> 00:03:43.480
It's more than that.


00:03:43.480 --> 00:03:46.900
And it's not exactly that, but that's a quick mental model.


00:03:46.900 --> 00:03:49.480
So you write data frame like code.


00:03:49.480 --> 00:03:50.780
We're not pandas compatible.


00:03:50.780 --> 00:03:53.360
We're pandas like enough that you might find something familiar.


00:03:53.360 --> 00:03:54.460
And it can compile.


00:03:54.460 --> 00:03:58.840
Down to, you know, generate SQL for 18 plus different database backends.


00:03:58.840 --> 00:03:59.740
Also like pies.


00:03:59.740 --> 00:04:00.240
More interesting.


00:04:00.240 --> 00:04:01.080
A couple other things.


00:04:01.080 --> 00:04:01.420
Okay.


00:04:01.420 --> 00:04:03.340
So you write your code once and you kind of run it on whatever.


00:04:03.340 --> 00:04:03.760
I see.


00:04:03.760 --> 00:04:08.420
And you do pandas like things, but it converts those into database queries.


00:04:08.420 --> 00:04:08.800
Is that.


00:04:08.800 --> 00:04:09.420
Yeah.


00:04:09.420 --> 00:04:09.640
Yeah.


00:04:09.640 --> 00:04:11.200
So it's a data frame API.


00:04:11.200 --> 00:04:16.180
It's not pandas compatible, but if you're familiar with pandas, you should be able to pick it up.


00:04:16.180 --> 00:04:19.220
You know, we cleaned up what we thought as a bunch of rough edges with the pandas API.


00:04:19.220 --> 00:04:19.540
Yeah.


00:04:19.540 --> 00:04:22.120
Were those pandas one or pandas two rough edges?


00:04:22.120 --> 00:04:22.960
Uh, both.


00:04:22.960 --> 00:04:23.700
It's, I don't know.


00:04:23.700 --> 00:04:24.220
It's.


00:04:24.220 --> 00:04:24.440
Yeah.


00:04:24.440 --> 00:04:25.100
It's pandas like.


00:04:25.100 --> 00:04:25.580
We'll say.


00:04:25.580 --> 00:04:25.880
Sure.


00:04:25.880 --> 00:04:25.880
Yeah.


00:04:25.880 --> 00:04:27.140
This looks really cool.


00:04:27.140 --> 00:04:29.860
That's a topic for another day, but awesome.


00:04:29.860 --> 00:04:30.620
People can check that out.


00:04:30.620 --> 00:04:37.560
But this time you're here to talk about your personal project message spec.


00:04:37.560 --> 00:04:38.660
Am I saying that right?


00:04:38.660 --> 00:04:40.520
How are you saying MSG or message spec?


00:04:40.520 --> 00:04:41.320
Message spec.


00:04:41.320 --> 00:04:42.120
Is right on.


00:04:42.120 --> 00:04:42.620
It is.


00:04:42.620 --> 00:04:48.240
I think a lot of these projects sometimes need a little, like here's the MP3 you can press


00:04:48.240 --> 00:04:53.200
play on, like how it's meant to be said, you know, sometimes it's kind of obvious like


00:04:53.200 --> 00:04:54.320
PI PI versus.


00:04:54.320 --> 00:04:55.320
Pie pie.


00:04:55.320 --> 00:04:59.080
Other times it's just like, okay, I know you have a really clever name.


00:04:59.080 --> 00:05:00.080
Yes, I know.


00:05:00.080 --> 00:05:01.080
People say numpy all the time.


00:05:01.080 --> 00:05:04.400
I'm like, I don't want to, I try to not correct guests.


00:05:04.400 --> 00:05:06.560
Cause it's, it's not kind of, I also feel awkward.


00:05:06.560 --> 00:05:08.660
They will say numpy and I'll say, how do you feel about numpy?


00:05:08.660 --> 00:05:09.660
Like numpy is great.


00:05:09.660 --> 00:05:12.380
I'm like, okay, we're just going back and forth like this for the next hour.


00:05:12.380 --> 00:05:13.380
It's fine.


00:05:13.380 --> 00:05:17.560
But yeah, it's, it's always, I think some of these could use a little, like a little


00:05:17.560 --> 00:05:18.560
play by.


00:05:18.560 --> 00:05:20.200
So message spec, tell people about what it is.


00:05:20.200 --> 00:05:21.200
Yeah.


00:05:21.200 --> 00:05:22.200
So gone through a couple of different taglines.


00:05:22.200 --> 00:05:24.200
The, the current one is a fast serial.


00:05:24.200 --> 00:05:28.820
Stylization and validation library with a built-in support for JSON message pack, YAML


00:05:28.820 --> 00:05:29.820
and Toml.


00:05:29.820 --> 00:05:31.880
If you are familiar with.


00:05:31.880 --> 00:05:35.000
Pydantic that's probably one of the closest, you know, most popular libraries that does


00:05:35.000 --> 00:05:36.100
a similar thing.


00:05:36.100 --> 00:05:40.440
You define kind of a structure of your data using type annotations and message spec will


00:05:40.440 --> 00:05:44.960
parse your data to ensure it is that structure and does so efficiently.


00:05:44.960 --> 00:05:48.820
It's also compatible with a lot of the other serialization libraries.


00:05:48.820 --> 00:05:53.080
You could also use it as a stand in for JSON, you know, with the JSON dumps, JSON loads,


00:05:53.080 --> 00:05:54.080
you don't need to.


00:05:54.080 --> 00:05:55.080
To specify the types.


00:05:55.080 --> 00:05:56.080
Right.


00:05:56.080 --> 00:06:01.560
It's I think the mental model of kind of like it swims in the same water or the same pond


00:06:01.560 --> 00:06:06.280
as Pydantic, but it's also fairly distinguished from Pydantic, right.


00:06:06.280 --> 00:06:09.280
As we're gonna explore throughout our, our chat here.


00:06:09.280 --> 00:06:14.080
The goal from my side, one of, one of the goals, was to replicate more of the experience


00:06:14.080 --> 00:06:19.380
writing rust or go with rust Surde or goes JSON where the serializer kind of stands in


00:06:19.380 --> 00:06:23.960
the background rather than my experience working with, with Pydantic, where it felt like the


00:06:23.960 --> 00:06:25.960
base model kind of stood in the foreground.


00:06:25.960 --> 00:06:29.680
You're defining the model of serialization kind of comes onto the types you've defined,


00:06:29.680 --> 00:06:31.960
but you're not actually working with the serializers on the types themselves.


00:06:31.960 --> 00:06:32.960
Got it.


00:06:32.960 --> 00:06:36.120
So an example, let me see if I see if I do have it.


00:06:36.120 --> 00:06:41.560
An example might be if I want to take some message I got from some response I got from


00:06:41.560 --> 00:06:44.460
an API, I wanna turn it into a Pydantic model or I'm writing an API.


00:06:44.460 --> 00:06:46.500
I wanna take something from a client, whatever.


00:06:46.500 --> 00:06:51.960
I'll go and create a Pydantic class and then I, the way I use it is I go to that class


00:06:51.960 --> 00:06:53.840
and I'll say star, star.


00:06:53.840 --> 00:06:57.840
Dictionary I got, and then it comes to life like that, right?


00:06:57.840 --> 00:07:02.600
Mm-hmm where there's a little more focused on just the, the serialization and has this


00:07:02.600 --> 00:07:06.340
capability, but like, like you said, it's optional in the sense.


00:07:06.340 --> 00:07:11.780
Yeah, I, in message spec, all types are on equal footing.


00:07:11.780 --> 00:07:17.240
So we use functions, not methods, because if you wanna decode into a list of ints, I


00:07:17.240 --> 00:07:18.520
can't add a method to a list.


00:07:18.520 --> 00:07:20.080
You know, it's a Python built in type.


00:07:20.080 --> 00:07:21.080
Yeah.


00:07:21.080 --> 00:07:23.720
So you'd say message spec, dot JSON dot.


00:07:23.720 --> 00:07:25.720
Decode your message.


00:07:25.720 --> 00:07:29.480
And then you'd specify the type annotation, as part of that function call.


00:07:29.480 --> 00:07:30.960
So it could be, you know, list bracket int.


00:07:30.960 --> 00:07:31.960
Right.


00:07:31.960 --> 00:07:36.960
So you'll say decode and then, then you might say type equals list of, of your type or list,


00:07:36.960 --> 00:07:38.340
like you say, list of int.


00:07:38.340 --> 00:07:42.800
And that's hard when you have to have a class that knows how to basically become what the


00:07:42.800 --> 00:07:46.340
model, the data passed in is, even if it's just a list.


00:07:46.340 --> 00:07:51.080
Mm-hmm some Pydantic classes, you gotta kinda jump through some hoops to say, hey, Pydantic,


00:07:51.080 --> 00:07:52.600
I don't have a thing to give you.


00:07:52.600 --> 00:07:53.600
I want a list of the.


00:07:53.600 --> 00:07:54.600
List of those things.


00:07:54.600 --> 00:07:57.200
And that's the, the top level thing is, you know, bracket bracket.


00:07:57.200 --> 00:08:00.640
It's not, it's, it's not any one thing I can specify in Python easily.


00:08:00.640 --> 00:08:01.640
Yeah.


00:08:01.640 --> 00:08:04.840
To, to be fair to the Pydantic project, I believe in V2, the type adapter.


00:08:04.840 --> 00:08:05.840
Yes, exactly.


00:08:05.840 --> 00:08:06.840
Uh, object can work with that.


00:08:06.840 --> 00:08:09.980
But that is, you know, it's a, it's a different way of working with it.


00:08:09.980 --> 00:08:12.360
I, I wanted to have one API that did it all.


00:08:12.360 --> 00:08:13.360
Sure.


00:08:13.360 --> 00:08:14.360
And it's awesome.


00:08:14.360 --> 00:08:18.340
They made a, I mean, I wanna boost, put this out front, like I'm a massive fan of Pydantic.


00:08:18.340 --> 00:08:23.000
What Samuel's done there is incredible and it's just, it's really made a big difference


00:08:23.000 --> 00:08:23.480
in the way that people.


00:08:23.480 --> 00:08:24.720
People work with data and Python.


00:08:24.720 --> 00:08:25.720
It's, it's awesome.


00:08:25.720 --> 00:08:29.680
But it's also awesome that you have this project that is an alternative and, and it makes different


00:08:29.680 --> 00:08:34.280
assumptions and you can see those really play out in like the performance or the APIs.


00:08:34.280 --> 00:08:38.980
So you know, like Pydantic encourages you to take your classes and then send them the


00:08:38.980 --> 00:08:42.900
data, but you've kind of gotta know like, oh, there's this type adapter thing that I


00:08:42.900 --> 00:08:45.720
can give a list of my class and then make it work.


00:08:45.720 --> 00:08:46.720
Right.


00:08:46.720 --> 00:08:51.360
But it's not just, oh, you just fall into that by trying to play with the API, you know?


00:08:51.360 --> 00:08:52.360
Yeah.


00:08:53.360 --> 00:08:59.040
By any type means we work with standard library data classes, the same as we work with our built in struct type.


00:08:59.040 --> 00:09:00.640
We also work with adders types.


00:09:00.640 --> 00:09:02.460
Everything is kind of on equal footing.


00:09:02.460 --> 00:09:02.700
Yeah.


00:09:02.700 --> 00:09:10.000
And what I want to really dig into is your custom struct type that has some really cool properties.


00:09:10.000 --> 00:09:11.860
Not class properties, but components.


00:09:11.860 --> 00:09:14.680
Features of the class of the type there.


00:09:14.680 --> 00:09:16.460
Let's look at a couple of things here.


00:09:16.580 --> 00:09:23.940
So as you said, it's fast and I love how somehow italicize on the word fast makes it feel even faster.


00:09:23.940 --> 00:09:26.540
Like it's leaning forward, you know, it's leaning into the speed.


00:09:26.540 --> 00:09:28.980
A fast serialization and validation library.


00:09:28.980 --> 00:09:32.360
The validation is kind of can be, but not required, right?


00:09:32.360 --> 00:09:34.400
The types can be, but they don't have to be.


00:09:34.400 --> 00:09:37.820
So I think that's one of the ways it really differs from Pydantic.


00:09:37.820 --> 00:09:41.760
But the other is Pydantic is quite focused on JSON.


00:09:41.760 --> 00:09:45.580
Whereas this is JSON, MessagePack, YAML, and TOML.


00:09:45.580 --> 00:09:46.560
Everyone knows what JSON is.


00:09:46.560 --> 00:09:49.940
I always thought of TOML as kind of like YAML.


00:09:49.940 --> 00:09:51.000
Are they really different?


00:09:51.000 --> 00:09:54.180
It's another configuration focused language.


00:09:54.180 --> 00:09:59.340
I think some people do JSON for config files, but I personally don't like to handwrite JSON.


00:09:59.340 --> 00:10:04.240
YAML and TOML are like more human friendly, in quotes, forms of that.


00:10:04.240 --> 00:10:06.800
YAML is a superset of JSON.


00:10:06.800 --> 00:10:08.180
TOML is its own thing.


00:10:08.180 --> 00:10:08.540
Got it.


00:10:08.540 --> 00:10:12.480
And then MessagePack is a binary JSON-like file format.


00:10:12.480 --> 00:10:13.440
Yeah, MessagePack.


00:10:13.440 --> 00:10:14.920
I don't know how many people work with that.


00:10:14.920 --> 00:10:16.540
Where would people run into MessagePack?


00:10:16.720 --> 00:10:17.160
Yeah.


00:10:17.160 --> 00:10:23.260
If they were, say, consuming an API, or what API framework would people be generating MessagePack in Python?


00:10:23.260 --> 00:10:24.500
That's a good question.


00:10:24.500 --> 00:10:30.020
So going back to the creation of this project, actually, MessageSpec sounds a lot like MessagePack.


00:10:30.020 --> 00:10:33.240
And that was intentional because that's what I wrote it for originally.


00:10:33.240 --> 00:10:37.500
So as I said at the beginning, I'm one of the original contributors to Dask.


00:10:37.500 --> 00:10:38.600
Worked on Dask forever.


00:10:38.600 --> 00:10:43.880
And the Dask distributed scheduler uses MessagePack for its RPC serialization layer.


00:10:43.880 --> 00:10:46.060
That kind of fell out of what was available at the time.


00:10:46.260 --> 00:10:47.660
We benchmarked a bunch of different libraries.


00:10:47.660 --> 00:10:52.720
And that was the fastest way to send bytes between nodes in 2015.


00:10:52.720 --> 00:10:58.800
The distributed scheduler's RPC framework has kind of grown haphazardly over time.


00:10:58.800 --> 00:11:01.720
And there were a bunch of bugs due to some hacky things we were doing with it.


00:11:01.720 --> 00:11:03.620
And also, it was slower than we would have wanted.


00:11:03.620 --> 00:11:10.700
So this was an attempt to write a faster MessagePack library for Python that also did fancier things.


00:11:10.700 --> 00:11:11.700
Supported more types.


00:11:11.700 --> 00:11:16.160
Did some schema validation because we wanted to catch the worker is sending this data.


00:11:16.240 --> 00:11:18.000
And the scheduler's getting it and saying it's wrong.


00:11:18.000 --> 00:11:22.760
And we wanted to also add in a way to make schema evolution.


00:11:22.760 --> 00:11:27.800
Meaning that I can have different versions of my worker and scheduler and client process.


00:11:27.800 --> 00:11:28.920
And things kind of work.


00:11:28.920 --> 00:11:33.220
If I add new features to the scheduler, they don't break the client.


00:11:33.220 --> 00:11:36.460
We have a nice forward and backward compatibility story.


00:11:36.460 --> 00:11:38.100
And so that's what kind of fell out.


00:11:38.100 --> 00:11:39.640
Yeah, it's a really nice feature.


00:11:39.640 --> 00:11:40.720
We're going to dive into that.


00:11:40.720 --> 00:11:45.360
But you might think, oh, well, just update your client or update the server.


00:11:45.360 --> 00:11:46.220
But there's all sorts.


00:11:46.220 --> 00:11:47.880
There's all sorts of situations that get really weird.


00:11:47.880 --> 00:11:54.520
Like if you have Redis as a caching layer and you create a MessagePack object and stick it in there.


00:11:54.520 --> 00:11:57.140
And then you deploy a new version of the app.


00:11:57.140 --> 00:12:00.740
It maybe can't deserialize anything in the cache anymore.


00:12:00.740 --> 00:12:04.160
Because it says something's missing or something's there that it doesn't expect.


00:12:04.160 --> 00:12:04.480
Right?


00:12:04.480 --> 00:12:07.100
And so this evolution is important there.


00:12:07.100 --> 00:12:10.800
If you've got long running work and you stash it into a database and you pull it back out.


00:12:10.800 --> 00:12:14.020
Like all these things where it kind of lives a little outside the process.


00:12:14.020 --> 00:12:15.880
All of a sudden it starts to matter that.


00:12:16.200 --> 00:12:19.620
Before you even consider clients that run separate code, right?


00:12:19.620 --> 00:12:20.880
You could be the client.


00:12:20.880 --> 00:12:22.440
Just different places in time.


00:12:22.440 --> 00:12:27.680
So adding a little bit more structure to how you define messages in a way to make the scheduler more maintainable.


00:12:27.680 --> 00:12:28.880
That work never landed.


00:12:28.880 --> 00:12:33.800
As it is with open source projects, it's a democracy and also a duocracy.


00:12:33.800 --> 00:12:34.920
And you don't always.


00:12:34.920 --> 00:12:36.580
Paths can be dead ends.


00:12:36.580 --> 00:12:38.180
I still think it'll be valuable in the future.


00:12:38.180 --> 00:12:40.280
But some stuff was changed in the scheduler.


00:12:40.280 --> 00:12:46.000
And serialization is no longer the bottleneck that it was two and a half years ago when this originally started.


00:12:46.180 --> 00:12:48.300
So let me put this in context.


00:12:48.300 --> 00:12:49.540
People maybe make it relevant.


00:12:49.540 --> 00:12:58.680
Like maybe right now someone's got a fast API API and they're using Pydantic and obviously generates all the awesome JSON they want.


00:12:58.680 --> 00:13:11.400
Is there a way to how would you go about creating, say, a Python server based system set of APIs that maybe as an option take message pack or maybe use that as a primary way?


00:13:11.400 --> 00:13:15.760
Like it could be maybe, you know, passing in accept header to take message pack.


00:13:16.040 --> 00:13:19.460
If you want to exchange message pack client server Python right now, what do you do?


00:13:19.460 --> 00:13:20.720
That's a good question.


00:13:20.720 --> 00:13:22.060
To be clear, I am not a web dev.


00:13:22.060 --> 00:13:23.400
I do not do this for a living.


00:13:23.400 --> 00:13:26.840
I think there is no standard application slash message pack.


00:13:26.840 --> 00:13:28.980
I think people can use it if they want.


00:13:28.980 --> 00:13:32.400
But that's not a it's a standardized thing the same way that JSON is.


00:13:32.400 --> 00:13:32.740
Yeah.


00:13:32.740 --> 00:13:35.920
I think that Lightstar as a framework does support this out of the box.


00:13:35.920 --> 00:13:37.220
I don't know about fast API.


00:13:37.220 --> 00:13:40.840
I'm sure there's a way to hack it in as there is with any ASCII server.


00:13:40.840 --> 00:13:41.760
Yeah.


00:13:41.760 --> 00:13:42.080
Lightstar.


00:13:42.080 --> 00:13:44.680
Like I said, I had Lightstar on those guys maybe a month ago.


00:13:44.680 --> 00:13:45.920
And yeah.


00:13:46.020 --> 00:13:47.380
It's super, super cool about that.


00:13:47.380 --> 00:13:52.160
So, yeah, I know that they support message spec and a lot of different options there.


00:13:52.160 --> 00:13:58.120
But, you know, you could just I imagine you could just return binary bits between you and your your client.


00:13:58.120 --> 00:14:04.360
I'm thinking of like latency sensitive microservice type things sort of within your data center.


00:14:04.360 --> 00:14:10.260
How can you lower serialization, deserialization, serialization, like all that that cost that could be the max.


00:14:10.260 --> 00:14:14.060
You know, the biggest part of what's making your app spend time and energy.


00:14:14.060 --> 00:14:16.000
Michael out there says, would.


00:14:16.000 --> 00:14:18.960
I love high arrow parquet support for large data.


00:14:18.960 --> 00:14:22.840
There's been a request for arrow integration with message spec.


00:14:22.840 --> 00:14:24.420
I'm not exactly sure what that would look like.


00:14:24.420 --> 00:14:26.700
Arrow containers are pretty efficient on their own.


00:14:26.700 --> 00:14:32.500
Breaking them out into a bunch of objects or stuff to work with message spec doesn't necessarily make sense in my mind.


00:14:32.500 --> 00:14:36.700
But anyway, if you have ideas on that, please open an issue or comment on the existing issue.


00:14:36.700 --> 00:14:37.680
Yeah, indeed.


00:14:37.680 --> 00:14:38.380
All right.


00:14:38.380 --> 00:14:39.800
So let's see.


00:14:39.800 --> 00:14:43.980
Some of the highlights are high performance encoders and decoders across those protocols.


00:14:43.980 --> 00:14:45.180
We talked benchmarks.


00:14:45.180 --> 00:14:45.980
We'll look at them.


00:14:45.980 --> 00:14:52.840
You have a really nice lot of support for different types that can go in there that can be serialized.


00:14:52.840 --> 00:15:01.400
But there's also a way to extend it to say, I've got a custom type that you don't think is serializable to whatever end thing, a message pack, JSON, whatever.


00:15:01.400 --> 00:15:04.520
But I can write a little code that'll take it either way.


00:15:04.520 --> 00:15:07.260
You know, dates are something that drive me crazy.


00:15:07.260 --> 00:15:13.000
But it could be like object ID out of MongoDB or other things that seem like they should go back and forth, but don't.


00:15:13.000 --> 00:15:13.760
You know, right.


00:15:13.760 --> 00:15:14.680
So that's really nice.


00:15:14.680 --> 00:15:15.880
And then zero.


00:15:15.960 --> 00:15:17.300
Cost schema validation.


00:15:17.300 --> 00:15:18.040
Right.


00:15:18.040 --> 00:15:24.740
It validates, decodes and validates JSON two times as fast as ORJSON, which is one of the high performance JSON decoders.


00:15:24.740 --> 00:15:26.040
And that's just decoding.


00:15:26.040 --> 00:15:26.600
Right.


00:15:26.600 --> 00:15:33.740
And then the struct thing that we're going to talk about, which is the struct type is kind of what brings the parity with Pydantic, right?


00:15:33.740 --> 00:15:34.060
Yeah.


00:15:34.060 --> 00:15:36.100
You could think of it as Pydantic's base model.


00:15:36.100 --> 00:15:38.600
It's our built in data class like type.


00:15:38.600 --> 00:15:38.960
Nice.


00:15:38.960 --> 00:15:44.640
So structs are data class like, like everything in message spec are implemented fully as a C extension.


00:15:44.640 --> 00:15:45.740
Getting these.


00:15:45.940 --> 00:15:54.080
To work required reading a lot of the CPython source code because we're doing some things that I don't want to say that they're not they don't want you to do.


00:15:54.080 --> 00:15:57.340
We're not doing them wrong, but they're not really documented.


00:15:57.340 --> 00:16:06.400
So, for example, the when you subclass for message pack or message spec dot struct that's using a meta class mechanism, which is a way of defining types to define types.


00:16:06.400 --> 00:16:11.900
And the meta class is written in C, which CPython doesn't make easy to do.


00:16:11.900 --> 00:16:15.640
So it's a meta class that creates.


00:16:15.760 --> 00:16:16.600
New C types.


00:16:16.600 --> 00:16:17.580
They're pretty speedy.


00:16:17.580 --> 00:16:25.940
They are 10 to 100 X faster for most operations than even handwriting a class that does the same thing, but definitely more than data classes or adders.


00:16:25.940 --> 00:16:27.160
Yeah, it's super interesting.


00:16:27.160 --> 00:16:28.540
And I really want to dive into that.


00:16:28.540 --> 00:16:34.820
Like I almost can see the struct type being relevant even outside of message spec and in general, potentially.


00:16:34.820 --> 00:16:36.720
So, yeah, we'll see about that.


00:16:36.720 --> 00:16:37.380
But it's super cool.


00:16:37.380 --> 00:16:40.980
And Michael also points out like he's the one who made the issue.


00:16:40.980 --> 00:16:42.800
So sorry about that.


00:16:42.800 --> 00:16:45.300
He's commented already, I suppose.


00:16:45.300 --> 00:16:45.740
Yeah.


00:16:45.780 --> 00:16:46.720
But yeah, awesome.


00:16:46.720 --> 00:16:47.340
Cool.


00:16:47.340 --> 00:16:47.620
All right.


00:16:47.620 --> 00:16:49.000
So let's do this.


00:16:49.000 --> 00:16:53.600
I think probably the best way to get started is we could talk through an example.


00:16:53.600 --> 00:16:59.880
And there's a really nice article by it's more Turner Trowing who's been on the show a couple of times.


00:16:59.880 --> 00:17:04.380
Faster, more memory efficient Python JSON parsing with message spec.


00:17:04.380 --> 00:17:09.560
And just as a couple of examples that I thought maybe we could throw up and and you could talk to speak to your thoughts.


00:17:09.560 --> 00:17:11.460
Like, why is the API work this way?


00:17:11.460 --> 00:17:13.020
Here's the advantages and so on.


00:17:13.020 --> 00:17:13.140
Yeah.


00:17:13.140 --> 00:17:15.620
So there's this big believe this is the GitHub API.


00:17:15.620 --> 00:17:18.560
Just returning these giant blobs of stuff about users.


00:17:18.560 --> 00:17:19.260
OK.


00:17:19.260 --> 00:17:26.580
And says, well, if we want to find out what users follow what repos or how many given a user, how many repos do they follow?


00:17:26.580 --> 00:17:27.180
Right.


00:17:27.180 --> 00:17:34.220
We could just say with open read this and then just do a JSON load and then do the standard dictionary stuff.


00:17:34.220 --> 00:17:34.420
Right.


00:17:34.420 --> 00:17:35.180
Like for everything.


00:17:35.180 --> 00:17:40.500
We're going to go go to the element that we got out and say bracket some key bracket some key.


00:17:40.500 --> 00:17:44.640
Now it looks like key not found errors are just lurking in here all over the place.


00:17:44.640 --> 00:17:45.600
But, you know.


00:17:45.600 --> 00:17:47.880
It's you should know that maybe it'll work.


00:17:47.880 --> 00:17:48.060
Right.


00:17:48.060 --> 00:17:51.020
If you know the API, I guess it was like this is the standard way.


00:17:51.020 --> 00:17:52.320
How much memory does this use?


00:17:52.320 --> 00:17:54.240
How much time does it take to look?


00:17:54.240 --> 00:17:56.420
We can basically swap out.


00:17:56.420 --> 00:17:57.260
Oh, our JSON.


00:17:57.260 --> 00:17:59.160
I'm not super familiar with or JSON.


00:17:59.160 --> 00:17:59.940
Are you?


00:17:59.940 --> 00:18:00.440
Yeah.


00:18:00.440 --> 00:18:06.560
Or JSON is compatible ish with the standard lib JSON, except that it returns bytes rather than strengths.


00:18:06.560 --> 00:18:06.960
Got it.


00:18:06.960 --> 00:18:07.200
OK.


00:18:07.200 --> 00:18:10.380
There's also I JSON, I believe, which makes it streaming.


00:18:10.380 --> 00:18:11.520
So there's that.


00:18:11.520 --> 00:18:15.440
And then says, OK, well, how would this look if we're going to use message?


00:18:15.480 --> 00:18:19.200
Spec in in his example, he's using structured data.


00:18:19.200 --> 00:18:23.720
So the structs would like the pydantic version, but it doesn't have to be this way.


00:18:23.720 --> 00:18:24.900
But it is this way.


00:18:24.900 --> 00:18:25.320
Right.


00:18:25.320 --> 00:18:25.980
This is the one he chose.


00:18:25.980 --> 00:18:31.560
So maybe just talk us through, like, how would you solve this problem using message spec and classes?


00:18:31.560 --> 00:18:31.960
Yeah.


00:18:31.960 --> 00:18:38.880
So as he's done here in this blog post, he's defined a couple of struct types for the various levels of this message.


00:18:38.880 --> 00:18:45.460
So repose actors and interactions and then parses the message directly into those types.


00:18:45.460 --> 00:18:54.460
So the final call there is passing in the read message and then specifying the type as a list of interactions, which tree down into actors and repose.


00:18:54.460 --> 00:18:54.880
Exactly.


00:18:54.880 --> 00:18:58.340
So this is what you mentioned earlier about having more function based.


00:18:58.340 --> 00:19:02.120
So you just say decode, give it the string or the bytes.


00:19:02.120 --> 00:19:06.580
And you say type equals list of bracket up level class.


00:19:06.580 --> 00:19:09.200
And just like pydantic, these can be nested.


00:19:09.200 --> 00:19:10.960
So there's an interaction which has an actor.


00:19:10.960 --> 00:19:13.680
There's an actor class which has a login, which has a type.


00:19:13.680 --> 00:19:15.120
So you're pydantic.


00:19:15.340 --> 00:19:17.660
And then you have a little bit of a mental model for how those kind of fit together.


00:19:17.660 --> 00:19:19.040
It's pretty straightforward, right?


00:19:19.040 --> 00:19:19.720
Pretty similar.


00:19:19.720 --> 00:19:20.220
Yeah.


00:19:20.220 --> 00:19:21.620
And then you're just programming with classes.


00:19:21.620 --> 00:19:22.200
Awesome.


00:19:22.200 --> 00:19:22.420
Yep.


00:19:22.420 --> 00:19:27.140
And it'll all work well with like mypy or Pyrite or whatever you're using if you're doing static analysis tools.


00:19:27.140 --> 00:19:27.520
Yeah.


00:19:27.520 --> 00:19:34.840
So you've thought about making sure that not just does it work well from a usability perspective, but like the type checkers don't go crazy.


00:19:34.840 --> 00:19:35.480
Yeah.


00:19:35.480 --> 00:19:38.780
And any, you know, editor integration you have should just work.


00:19:38.780 --> 00:19:39.120
Nice.


00:19:39.120 --> 00:19:44.400
Because there's sometimes, oh gosh, I think maybe fast APIs changes.


00:19:44.400 --> 00:19:45.120
But you'll have things like...


00:19:45.120 --> 00:19:52.460
You would say the type of an argument being passed in, if it's say coming off the query string, you would say it's depend.


00:19:52.460 --> 00:19:56.160
It's a type depends, not an int, for example.


00:19:56.160 --> 00:19:58.600
Because it's being pulled out of the query string.


00:19:58.600 --> 00:19:59.680
I think that's fast API.


00:19:59.680 --> 00:20:09.060
And while it makes the runtime happy and the runtime says, oh, I see you want to get this int from the query string, the type checkers and stuff are like, depends.


00:20:09.060 --> 00:20:09.900
What is this?


00:20:09.900 --> 00:20:10.700
Like this is an int.


00:20:10.700 --> 00:20:12.540
Why are you trying to use this depends as an int?


00:20:12.540 --> 00:20:13.400
This doesn't make any sense.


00:20:13.400 --> 00:20:15.060
I think it's a bit of a challenge to have.


00:20:15.080 --> 00:20:19.540
The types drive the runtime, but still not freak it out, you know?


00:20:19.540 --> 00:20:19.860
Yeah.


00:20:19.860 --> 00:20:33.080
I think that the Python typing ecosystem, especially with the recent changes in new versions and the annotated wrapper, are moving towards a system where these kinds of APIs can be spelled natively in ways that the type checkers will understand.


00:20:33.080 --> 00:20:33.940
Right.


00:20:33.940 --> 00:20:41.380
But if you're a project that existed before these changes, you obviously had some pre-existing way to make those work that might not play as nicely.


00:20:41.380 --> 00:20:43.320
So there's the upgrade cost of the project.


00:20:43.320 --> 00:20:44.320
I'm not envious of...


00:20:45.040 --> 00:20:50.680
The work that Samuel Coven and team have had to do to upgrade Pydantic to erase some old warts in the API that they found.


00:20:50.680 --> 00:20:52.840
It's nice to see what they've done and it's impressive.


00:20:52.840 --> 00:20:57.700
But I have the benefit of starting this project after those changes in typing ecosystem existed.


00:20:57.700 --> 00:21:01.020
You know, can look at hindsight mistakes others have made and learn from them.


00:21:01.020 --> 00:21:01.960
Yeah, that's really excellent.


00:21:01.960 --> 00:21:03.200
They have done...


00:21:03.200 --> 00:21:04.440
Like I said, I'm a big fan of Pydantic.


00:21:04.440 --> 00:21:06.060
And it took them almost a year.


00:21:06.060 --> 00:21:09.760
I interviewed Samuel about that change and it was no joke.


00:21:09.760 --> 00:21:10.820
You know, it was a lot of work.


00:21:10.820 --> 00:21:13.680
But, you know, what they came up with, pretty compatible.


00:21:13.680 --> 00:21:14.920
Pretty much feels like...


00:21:14.920 --> 00:21:15.920
It feels like the same Pydantic.


00:21:15.920 --> 00:21:18.740
But, you know, if you peel back the covers, it's definitely not.


00:21:18.740 --> 00:21:19.260
All right.


00:21:19.260 --> 00:21:23.480
So the other interesting thing about Idmar's article here is the performance side.


00:21:23.480 --> 00:21:23.980
So it's okay.


00:21:23.980 --> 00:21:28.440
Do you get fixed memory usage or does it vary based on the size of the data?


00:21:28.440 --> 00:21:29.800
And do you get schema validation?


00:21:29.800 --> 00:21:30.420
Right.


00:21:30.420 --> 00:21:33.660
So standard lib, just straight JSON module.


00:21:33.660 --> 00:21:35.060
420 milliseconds.


00:21:35.060 --> 00:21:36.920
OR JSON, the fast one.


00:21:36.920 --> 00:21:38.920
A little less than twice as fast.


00:21:38.920 --> 00:21:39.860
280 milliseconds.


00:21:39.860 --> 00:21:42.740
IJSON for iterable JSON.


00:21:42.740 --> 00:21:44.880
300, so a little more than the...


00:21:44.880 --> 00:21:45.620
The fast one.


00:21:45.620 --> 00:21:47.760
Message spec, 90 milliseconds.


00:21:47.760 --> 00:21:48.640
That's awesome.


00:21:48.640 --> 00:21:51.400
That's like three times as fast as the better one.


00:21:51.400 --> 00:21:54.160
Over four times as fast as the built-in one.


00:21:54.160 --> 00:21:56.460
It also is doing, you know, quote-unquote more work.


00:21:56.460 --> 00:21:58.900
It's validating the responses it comes in.


00:21:58.900 --> 00:21:59.400
Exactly.


00:21:59.400 --> 00:22:01.140
So you're sure that it's correct then too.


00:22:01.140 --> 00:22:04.500
All those other ones are just giving you dictionaries and YOLO.


00:22:04.500 --> 00:22:05.460
Do what you want with them.


00:22:05.460 --> 00:22:06.080
Right?


00:22:06.080 --> 00:22:07.420
But here you're actually...


00:22:07.420 --> 00:22:09.000
All those types that you described, right?


00:22:09.000 --> 00:22:12.080
The interaction and the actors and the repos and the class structure.


00:22:12.080 --> 00:22:13.240
That's all validation.


00:22:13.240 --> 00:22:14.740
So in on top of that,


00:22:14.760 --> 00:22:18.320
you've created classes which are heavier weight than dictionaries


00:22:18.320 --> 00:22:21.020
because general classes are heavier weight than dictionaries


00:22:21.020 --> 00:22:23.440
because they have the dunder dict


00:22:23.440 --> 00:22:26.260
that has all the fields in there effectively anyway, right?


00:22:26.260 --> 00:22:28.240
That's not true for structs.


00:22:28.240 --> 00:22:29.540
Structs are slot classes.


00:22:29.540 --> 00:22:30.800
Yes, structs.


00:22:30.800 --> 00:22:34.180
They are a lighter weight to allocate than a dictionary or a standard class.


00:22:34.180 --> 00:22:35.220
That's one of the reasons they're faster.


00:22:35.220 --> 00:22:35.540
Yeah.


00:22:35.540 --> 00:22:36.500
Structs are awesome.


00:22:36.500 --> 00:22:38.620
And so the other thing I was pointing out is, you know,


00:22:38.620 --> 00:22:41.760
you've got 40 megabytes of memory usage versus 130,


00:22:41.760 --> 00:22:44.560
so almost four times less than the standard.


00:22:44.640 --> 00:22:47.740
And the only thing that beats you is the iterative one


00:22:47.740 --> 00:22:50.940
because it literally only has one in memory at a time, right?


00:22:50.940 --> 00:22:51.660
One element.


00:22:51.660 --> 00:22:52.020
Yeah.


00:22:52.020 --> 00:22:56.140
So this benchmark is kind of hiding two things together.


00:22:56.140 --> 00:22:59.180
So there is the output, what you're parsing.


00:22:59.180 --> 00:23:03.220
Everything here except for iJSON is going to parse the full input into something.


00:23:03.220 --> 00:23:04.560
One big batch.


00:23:04.560 --> 00:23:07.200
Message is more efficient than orJSON or the standard lib in this respect


00:23:07.200 --> 00:23:09.200
because we're only extracting the fields we care about,


00:23:09.200 --> 00:23:11.820
but you're still going to end up with a list of a bunch of objects.


00:23:11.820 --> 00:23:14.520
iJSON is only going to pull one into memory at a time.


00:23:14.520 --> 00:23:16.520
So it's going to have less in memory there.


00:23:16.520 --> 00:23:19.520
And then you have the memory usage of the parsers themselves,


00:23:19.520 --> 00:23:20.520
which can also vary.


00:23:20.520 --> 00:23:25.520
So orJSON's memory or usage in its parser is a lot higher than message specs,


00:23:25.520 --> 00:23:27.520
regardless of the output size.


00:23:27.520 --> 00:23:29.520
There's a little more internal state.


00:23:29.520 --> 00:23:32.520
So this is a pretty interesting distinction that you're calling out here.


00:23:32.520 --> 00:23:36.520
So for example, if people check out this article, which I'll link,


00:23:36.520 --> 00:23:40.520
there's like tons of stuff that people don't care about in the JSON,


00:23:40.520 --> 00:23:43.520
like the avatar URL, the gravatar ID,


00:23:43.520 --> 00:23:44.400
the data.


00:23:44.400 --> 00:23:47.400
You know, the reference type, whether it's a brand,


00:23:47.400 --> 00:23:49.400
like this stuff that you just don't care about.


00:23:49.400 --> 00:23:49.400
Right.


00:23:49.400 --> 00:23:51.400
But to parse it in, you got to read that.


00:23:51.400 --> 00:23:54.400
But what's pretty cool, you're saying is like in this case,


00:23:54.400 --> 00:23:59.400
the class that it Mark came up with is just repo driving from struct.


00:23:59.400 --> 00:24:00.400
It just has name.


00:24:00.400 --> 00:24:02.400
There's a bunch of other stuff in there, but you don't care about it.


00:24:02.400 --> 00:24:05.400
And so what you're saying is like, if you say that that's the decoder,


00:24:05.400 --> 00:24:07.400
it looks at that and goes, there's a bunch of stuff here.


00:24:07.400 --> 00:24:08.400
We're not loading that.


00:24:08.400 --> 00:24:12.400
We're just going to look for the things you've explicitly asked us to model.


00:24:12.400 --> 00:24:13.400
Right.


00:24:13.400 --> 00:24:14.280
That's awesome.


00:24:14.280 --> 00:24:15.280
It makes no sense in doing the work.


00:24:15.280 --> 00:24:16.280
If you're never going to look at it.


00:24:16.280 --> 00:24:18.280
A lot of different serialization frameworks.


00:24:18.280 --> 00:24:22.280
Can't remember how Pydantic responds when you do this, but it,


00:24:22.280 --> 00:24:24.280
you know, the comments beyond Pydantic,


00:24:24.280 --> 00:24:27.280
it doesn't really matter is they'll freak out to say, oh,


00:24:27.280 --> 00:24:28.280
there's extra stuff here.


00:24:28.280 --> 00:24:31.280
What am I supposed to, you know, for example, this repo, it just has name,


00:24:31.280 --> 00:24:35.280
but in the data model, it has way more in the JSON data.


00:24:35.280 --> 00:24:36.280
So you try to deserialize it.


00:24:36.280 --> 00:24:38.280
It'll go, well, I don't have room to put all this other stuff.


00:24:38.280 --> 00:24:40.280
Things are, you know, to freak out.


00:24:40.280 --> 00:24:41.280
And this one is just like, no,


00:24:41.280 --> 00:24:43.280
we're just going to filter down to what you asked for.


00:24:43.280 --> 00:24:44.160
I really,


00:24:44.160 --> 00:24:45.160
I think it's nice in a couple of ways.


00:24:45.160 --> 00:24:47.160
It's nice from performance, nice from clean code.


00:24:47.160 --> 00:24:50.160
I don't have to put all those other fields I don't care about,


00:24:50.160 --> 00:24:53.160
but also from you talked about the evolution friendliness, right?


00:24:53.160 --> 00:24:58.160
Because what's way more common is that things get added rather than taken


00:24:58.160 --> 00:24:59.160
away or change.


00:24:59.160 --> 00:25:01.160
It's like, well, the complexity grows.


00:25:01.160 --> 00:25:03.160
Now repos also have this, you know,


00:25:03.160 --> 00:25:06.160
related repos or sub repo or whatever the heck they have.


00:25:06.160 --> 00:25:07.160
Right.


00:25:07.160 --> 00:25:09.160
And this model here will just let you go, whatever.


00:25:09.160 --> 00:25:10.160
Don't care.


00:25:10.160 --> 00:25:11.160
Not.


00:25:11.160 --> 00:25:12.160
Yeah.


00:25:12.160 --> 00:25:14.040
If GitHub updates their API and adds new fields,


00:25:14.040 --> 00:25:15.040
you're not going to get an error.


00:25:15.040 --> 00:25:16.040
And if they remove a field,


00:25:16.040 --> 00:25:19.040
you should get a nice error that says expected,


00:25:19.040 --> 00:25:20.040
you know, field name.


00:25:20.040 --> 00:25:21.040
And now it's missing.


00:25:21.040 --> 00:25:24.040
You can track that down a lot easier than a random key error.


00:25:24.040 --> 00:25:25.040
I agree.


00:25:25.040 --> 00:25:26.040
I think, okay, let's,


00:25:26.040 --> 00:25:29.040
let's dive into the struct a little bit because that's where we're kind of on


00:25:29.040 --> 00:25:30.040
that now.


00:25:30.040 --> 00:25:33.040
And I think this is one of the highlights of what you built again.


00:25:33.040 --> 00:25:36.040
It's kind of the same mental model as people are familiar with some data


00:25:36.040 --> 00:25:39.040
classes with Pytantic and adders and so on.


00:25:39.040 --> 00:25:41.040
So when I saw your numbers,


00:25:41.040 --> 00:25:43.920
I won't come back and talk about benchmarks with numbers.


00:25:43.920 --> 00:25:45.920
But I just saw like, wow, this is fast.


00:25:45.920 --> 00:25:48.920
And while the memory usage is low, you must be doing something native.


00:25:48.920 --> 00:25:50.920
You must be doing something crazy in here.


00:25:50.920 --> 00:25:52.920
That's not just Dunder slots.


00:25:52.920 --> 00:25:54.920
Well, Dunder slots is awesome.


00:25:54.920 --> 00:25:56.920
It's there's more to it than that.


00:25:56.920 --> 00:25:57.920
Right.


00:25:57.920 --> 00:26:00.920
And so the written NC quite speedy and lightweight.


00:26:00.920 --> 00:26:02.920
So measurably faster than data classes,


00:26:02.920 --> 00:26:03.920
adders and Pytantic.


00:26:03.920 --> 00:26:05.920
Like tell us about these classes.


00:26:05.920 --> 00:26:07.920
Like this is, this is pretty interesting.


00:26:07.920 --> 00:26:08.920
It's mentioned earlier.


00:26:08.920 --> 00:26:10.920
They're not exactly, but they're, they're basically slots classes.


00:26:10.920 --> 00:26:13.800
So Python data model, actually CPython data model.


00:26:13.800 --> 00:26:18.800
Is either a class is a standard class where it stores its attributes in a dict.


00:26:18.800 --> 00:26:20.800
That's not exactly true.


00:26:20.800 --> 00:26:24.800
There's been some optimizations where the keys are stored separately alongside the class structure.


00:26:24.800 --> 00:26:26.800
And all of the values are stored on the object instances.


00:26:26.800 --> 00:26:30.800
But in model, there's dict classes and there's slots classes,


00:26:30.800 --> 00:26:34.800
which you pre declare your attributes to be in this, this Dunder slots,


00:26:34.800 --> 00:26:39.800
iterable and those get stored in line in the same allocation as the object instance.


00:26:39.800 --> 00:26:41.800
There's no pointer chasing.


00:26:41.800 --> 00:26:43.680
What that means is that you can't set extra attributes.


00:26:43.680 --> 00:26:48.560
On them that weren't pre-declared, but also things are a little bit more efficient.


00:26:48.560 --> 00:26:51.560
We create those automatically when you subclass from a struct type,


00:26:51.560 --> 00:26:55.560
and we do a bunch of other interesting things that are stored on the type.


00:26:55.560 --> 00:26:58.560
That is why we had to write a meta class and see.


00:26:58.560 --> 00:26:59.560
I went to read it.


00:26:59.560 --> 00:27:00.560
I'm like, whoa, okay.


00:27:00.560 --> 00:27:01.560
Well, maybe we'll come back to this.


00:27:01.560 --> 00:27:03.560
There's a lot of stuff going on in that type.


00:27:03.560 --> 00:27:08.560
This is what the problems with this, this hobby project is that I wrote this for fun and a little bit of work related,


00:27:08.560 --> 00:27:09.560
but mostly fun.


00:27:09.560 --> 00:27:12.560
And it's not the easiest code base for others to step into.


00:27:12.560 --> 00:27:13.560
It fits my method.


00:27:13.560 --> 00:27:14.440
It fits my mental model.


00:27:14.440 --> 00:27:15.440
Not necessarily everyone's.


00:27:15.440 --> 00:27:16.440
Yeah.


00:27:16.440 --> 00:27:19.440
I can tell you weren't looking for VC funding because you didn't write it in Rust.


00:27:19.440 --> 00:27:22.440
Seems to be the common denominator these days.


00:27:22.440 --> 00:27:23.440
Yeah.


00:27:23.440 --> 00:27:24.440
Why C?


00:27:24.440 --> 00:27:27.440
Just because CPython's already in C and that's the...


00:27:27.440 --> 00:27:28.440
And now you see.


00:27:28.440 --> 00:27:32.440
I do know Rust, but for what I wanted to do in the use case I had in mind, I wanted to


00:27:32.440 --> 00:27:35.440
be able to touch the C API directly.


00:27:35.440 --> 00:27:38.440
And that felt like the easiest way to go about doing it.


00:27:38.440 --> 00:27:43.440
This portion of Talk Python to me is brought to you by Posit, the makers of Shiny.


00:27:43.440 --> 00:27:48.320
Formerly RStudio and especially Shiny for Python.


00:27:48.320 --> 00:27:49.440
Let me ask you a question.


00:27:49.440 --> 00:27:51.320
Are you building awesome things?


00:27:51.320 --> 00:27:52.320
Of course you are.


00:27:52.320 --> 00:27:53.440
You're a developer or data scientist.


00:27:53.440 --> 00:27:54.440
That's what we do.


00:27:54.440 --> 00:27:57.320
And you should check out Posit Connect.


00:27:57.320 --> 00:28:04.320
Posit Connect is a way for you to publish, share and deploy all the data products that you're building using Python.


00:28:04.320 --> 00:28:07.320
People ask me the same question all the time.


00:28:07.320 --> 00:28:10.320
Michael, I have some cool data science project or notebook that I built.


00:28:10.320 --> 00:28:13.320
How do I share it with my users, stakeholders, teammates?


00:28:13.320 --> 00:28:18.200
Do I need to learn FastAPI or Flask or maybe Vue or ReactJS?


00:28:18.200 --> 00:28:19.200
Hold on now.


00:28:19.200 --> 00:28:24.200
Those are cool technologies and I'm sure you'd benefit from them, but maybe stay focused on the data project?


00:28:24.200 --> 00:28:27.200
Let Posit Connect handle that side of things.


00:28:27.200 --> 00:28:31.200
With Posit Connect you can rapidly and securely deploy the things you build in Python.


00:28:31.200 --> 00:28:38.200
Streamlet, Dash, Shiny, Bokeh, FastAPI, Flask, Quadro, Reports, Dashboards and APIs.


00:28:38.200 --> 00:28:40.200
Posit Connect supports all of them.


00:28:40.200 --> 00:28:43.200
And Posit Connect comes with all the bells and whistles.


00:28:43.200 --> 00:28:45.080
And it's a great way to build your own business.


00:28:45.080 --> 00:28:47.080
And it's a great way to build your own business.


00:29:41.080 --> 00:29:42.960
And it's a great way to build your own business.


00:29:42.960 --> 00:29:44.960
And it's a great way to build your own business.

