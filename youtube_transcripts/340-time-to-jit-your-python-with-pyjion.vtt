WEBVTT

00:00:00.000 --> 00:00:04.000
Anthony Shaw, welcome to Talk by The Enemy.


00:00:04.000 --> 00:00:06.000
Hi Michael, good to see you again.


00:00:06.000 --> 00:00:08.000
Yeah, it's great to have you back.


00:00:08.000 --> 00:00:10.000
Your at least yearly appearance here.


00:00:10.000 --> 00:00:15.000
If not by name, you know, you've at least appeared yourself once.


00:00:15.000 --> 00:00:18.000
But I think you get mentioned a bunch of times with all the stuff you're doing.


00:00:18.000 --> 00:00:21.000
Yeah, we were just trying to work out when was the last time.


00:00:21.000 --> 00:00:23.000
Is it like a year, over a year ago?


00:00:23.000 --> 00:00:27.000
Yeah, yeah, it was May 2020.


00:00:27.000 --> 00:00:30.000
That was when the whole COVID thing was about to end.


00:00:30.000 --> 00:00:33.000
Like, hey, it's just a couple of months, we'll be through this, it'll be fine.


00:00:33.000 --> 00:00:36.000
Everyone will wear a mask and get their shots and it'll be totally normal.


00:00:36.000 --> 00:00:39.000
I had to pause for a second, I was trying to work out what year it was.


00:00:39.000 --> 00:00:41.000
[Laughter]


00:00:41.000 --> 00:00:43.000
I know, I know.


00:00:43.000 --> 00:00:46.000
Well, you're in Australia, so it's probably the next year.


00:00:46.000 --> 00:00:47.000
2022, yeah.


00:00:47.000 --> 00:00:49.000
Yeah, you guys are always ahead by a little bit.


00:00:49.000 --> 00:00:51.000
Yeah, exactly.


00:00:51.000 --> 00:00:52.000
Awesome.


00:00:52.000 --> 00:00:55.000
Welcome to the show.


00:00:55.000 --> 00:00:58.000
A lot of times we have you on to talk about stuff that's going on,


00:00:58.000 --> 00:01:01.000
but this time we're here to talk about a project that you've been spearheading


00:01:01.000 --> 00:01:08.000
for the last year or so, Pidgin, which is a JIT compiler for Python,


00:01:08.000 --> 00:01:11.000
which is pretty awesome.


00:01:11.000 --> 00:01:16.000
Yeah, it was sitting on the shelf for a few years,


00:01:16.000 --> 00:01:18.000
and I decided to pick it up.


00:01:18.000 --> 00:01:21.000
It was related to a thread of things I'd been working on,


00:01:21.000 --> 00:01:26.000
looking at Python performance, and also when I kind of finished working


00:01:26.000 --> 00:01:29.000
on the book, so I published a book.


00:01:29.000 --> 00:01:31.000
CPython Internals book, yeah.


00:01:31.000 --> 00:01:33.000
CPython Internals book.


00:01:33.000 --> 00:01:36.000
Yeah, it was really interesting to dig into a compiler,


00:01:36.000 --> 00:01:41.000
and I really wanted to put some of that theory into practice


00:01:41.000 --> 00:01:43.000
and work on my own compiler.


00:01:43.000 --> 00:01:47.000
So, yeah, that's kind of what led into it.


00:01:47.000 --> 00:01:50.000
Yeah, it looks like no small feat, as people will see


00:01:50.000 --> 00:01:54.000
as we get into it, but how much did the diving into the C internals


00:01:54.000 --> 00:01:58.000
make you feel like, all right, I'm ready to actually start messing


00:01:58.000 --> 00:02:02.000
with this and messing with how it runs and compiling some instruction?


00:02:02.000 --> 00:02:04.000
Yeah, massively.


00:02:04.000 --> 00:02:05.000
Yeah?


00:02:05.000 --> 00:02:06.000
Yeah, massively.


00:02:06.000 --> 00:02:08.000
I don't know where I would have started otherwise.


00:02:08.000 --> 00:02:10.000
It's a pretty steep learning curve.


00:02:10.000 --> 00:02:13.000
If someone did that job, I'd be like, I have no idea how to do this.


00:02:13.000 --> 00:02:16.000
Yeah, I was one of those projects I got started on


00:02:16.000 --> 00:02:18.000
because it just had my curiosity.


00:02:18.000 --> 00:02:23.000
I didn't understand how it could work, and, yeah,


00:02:23.000 --> 00:02:26.000
I just really wanted to learn, and it just seemed like a really big challenge.


00:02:26.000 --> 00:02:29.000
So, yeah, I looked at it and thought, this is an interesting thing.


00:02:29.000 --> 00:02:32.000
I know that Brett and Dino were no longer working on it


00:02:32.000 --> 00:02:35.000
and just decided to pick it up and see how far I could take it.


00:02:35.000 --> 00:02:38.000
Yeah, absolutely.


00:02:38.000 --> 00:02:43.000
I think you've taken it pretty far, and it's about to go to 1.0.


00:02:43.000 --> 00:02:44.000
Is that right?


00:02:44.000 --> 00:02:51.000
Yeah, so it could be launching version 1.0 of Pidgin in a few days.


00:02:51.000 --> 00:02:54.000
So I'm waiting for .NET 6 to be released,


00:02:54.000 --> 00:02:57.000
and I'll explain why probably a bit later.


00:02:57.000 --> 00:02:59.000
Wait, wait, wait, wait, wait, wait, wait.


00:02:59.000 --> 00:03:01.000
Hold on, hold on, hold on.


00:03:01.000 --> 00:03:04.000
This is a Python project on a Python podcast,


00:03:04.000 --> 00:03:06.000
and you're waiting for .NET 6?


00:03:06.000 --> 00:03:08.000
Oh, my gosh, I don't understand.


00:03:08.000 --> 00:03:11.000
Yeah, this bit confuses people, and it did originally, I think,


00:03:11.000 --> 00:03:13.000
when the project was written.


00:03:13.000 --> 00:03:19.000
So it's a JIT compiler for Python written in C++,


00:03:19.000 --> 00:03:29.000
and you could write your own JIT compiler, which is no small feat.


00:03:29.000 --> 00:03:31.000
Yeah, and it could be done in, like, ten years.


00:03:31.000 --> 00:03:32.000
Exactly.


00:03:32.000 --> 00:03:35.000
Or you can take a JIT compiler off the shelf.


00:03:35.000 --> 00:03:40.000
So a JIT compiler compiles some sort of intermediary language


00:03:40.000 --> 00:03:44.000
into machine code, so assembly.


00:03:44.000 --> 00:03:49.000
And a lot of JIT compilers are working with basically, like,


00:03:49.000 --> 00:03:53.000
which registers to use, which operations and instructions


00:03:53.000 --> 00:03:57.000
are supported on different CPUs.


00:03:57.000 --> 00:04:00.000
Like, there's a whole bunch of stuff to work on.


00:04:00.000 --> 00:04:02.000
Very, very involved.


00:04:02.000 --> 00:04:08.000
And .NET Core, what was called .NET Core is now just .NET,


00:04:08.000 --> 00:04:10.000
and it has a JIT compiler in it.


00:04:10.000 --> 00:04:14.000
And, yeah, you can actually use just the JIT compiler.


00:04:14.000 --> 00:04:16.000
So that's what the project originally did,


00:04:16.000 --> 00:04:23.000
was to basically use the JIT compiler for .NET Core.


00:04:23.000 --> 00:04:28.000
Other JITs for Python, some of them use the LLVM JIT,


00:04:28.000 --> 00:04:32.000
and there's a few other JITs as well you can get off the shelf.


00:04:32.000 --> 00:04:34.000
So, yeah, started to use the .NET one.


00:04:34.000 --> 00:04:38.000
That was originally Dino and Brett, when they built this.


00:04:38.000 --> 00:04:40.000
It was actually before .NET Core was even released.


00:04:40.000 --> 00:04:43.000
It was still in beta back then, but, yeah, they used .NET Core's JIT.


00:04:43.000 --> 00:04:48.000
Yeah, I think it was a much earlier version of .NET Core back then, right?


00:04:48.000 --> 00:04:51.000
Like, it's come a long way.


00:04:51.000 --> 00:04:55.000
I think back then, you probably know this better than I do now,


00:04:55.000 --> 00:05:00.000
but back then I think there was, like, a fork in the road,


00:05:00.000 --> 00:05:02.000
two paths for the .NET world.


00:05:02.000 --> 00:05:05.000
You could do traditional .NET on Windows only,


00:05:05.000 --> 00:05:09.000
but that was like the 15-year polished version of .NET.


00:05:09.000 --> 00:05:15.000
And then there was this alternative, funky, open-source .NET Core thing


00:05:15.000 --> 00:05:19.000
that was sort of derived but was not the same thing as that.


00:05:19.000 --> 00:05:22.000
And so I think probably when Brett and Dino were working on it,


00:05:22.000 --> 00:05:26.000
it was really early days on that version of the JIT compiler.


00:05:26.000 --> 00:05:29.000
Yeah, it was version 0.9 of .NET Core.


00:05:29.000 --> 00:05:33.000
So, yeah, I did actually get involved back then,


00:05:33.000 --> 00:05:39.000
just helping out upgrading it from version 0.9 of .NET Core to version 1.


00:05:39.000 --> 00:05:43.000
So I did, like, help on the original Pigeon project


00:05:43.000 --> 00:05:45.000
with some of the builds and stuff.


00:05:45.000 --> 00:05:50.000
But that early version of Pigeon required a fork of CPython


00:05:50.000 --> 00:05:52.000
and a fork of .NET Core.


00:05:52.000 --> 00:05:57.000
So it required you to compile both projects from source with patches.


00:05:57.000 --> 00:06:02.000
And, like, stick a whole bunch of stuff together.


00:06:02.000 --> 00:06:05.000
And, yeah, very tricky to set up.


00:06:05.000 --> 00:06:08.000
And that's one of the things when I kind of came in a year ago


00:06:08.000 --> 00:06:11.000
to pick this project up again that I really wanted to tackle


00:06:11.000 --> 00:06:15.000
was let's make it easy to install this,


00:06:15.000 --> 00:06:18.000
which means it should just be pip installable.


00:06:18.000 --> 00:06:21.000
So you can just pip install Pigeon on Python.


00:06:21.000 --> 00:06:24.000
And that's the second thing I had to do,


00:06:24.000 --> 00:06:27.000
upgrade it to the latest versions of Python,


00:06:27.000 --> 00:06:30.000
the latest versions of .NET.


00:06:30.000 --> 00:06:35.000
So, yeah, it's running on .NET 6 and CPython 3.10.


00:06:35.000 --> 00:06:40.000
So, yeah, it's basically a JIT compiler for Python 3.10.


00:06:40.000 --> 00:06:44.000
Right. So now we have .NET as--


00:06:44.000 --> 00:06:46.000
I think they've closed that fork.


00:06:46.000 --> 00:06:49.000
It's a little bit like the 2-3 boundary that we've crossed.


00:06:49.000 --> 00:06:53.000
It's just back to this .NET thing, and it's open source, which is cool.


00:06:53.000 --> 00:06:59.000
So that closes the .NET JIT side of things from a beta thing.


00:06:59.000 --> 00:07:02.000
On the other hand, there's a pep,


00:07:02.000 --> 00:07:04.000
and I'm sure you know the number.


00:07:04.000 --> 00:07:06.000
I don't know the number off the top of my head,


00:07:06.000 --> 00:07:10.000
that allowed for extensions into standard CPython,


00:07:10.000 --> 00:07:15.000
so you don't have to fork it and reprogram C of L.C.


00:07:15.000 --> 00:07:20.000
There's an extensibility layer for this kind of stuff now, right?


00:07:20.000 --> 00:07:23.000
Yeah, so maybe to backtrack a little bit,


00:07:23.000 --> 00:07:29.000
but when you write Python code and then execute it in CPython,


00:07:29.000 --> 00:07:33.000
which is the most popular Python interpreter,


00:07:33.000 --> 00:07:35.000
the one you get from python.org,


00:07:35.000 --> 00:07:37.000
when you compile the--


00:07:37.000 --> 00:07:39.000
Well, you don't compile the Python code.


00:07:39.000 --> 00:07:41.000
Python does that for you.


00:07:41.000 --> 00:07:43.000
When you compile Python code,


00:07:43.000 --> 00:07:47.000
it compiles down into an abstract syntax tree,


00:07:47.000 --> 00:07:51.000
and then the next level down is bytecode sequence,


00:07:51.000 --> 00:07:54.000
which you can see if you import the disk module


00:07:54.000 --> 00:07:59.000
and you run the disk function on your code.


00:07:59.000 --> 00:08:02.000
I've got to talk about Pidgin,


00:08:02.000 --> 00:08:05.000
which I did at PyCon this year.


00:08:05.000 --> 00:08:07.000
I'll give some demos and stuff.


00:08:07.000 --> 00:08:09.000
Perfect.


00:08:09.000 --> 00:08:11.000
Yeah, so it gives some explanations and examples.


00:08:11.000 --> 00:08:13.000
So that's kind of the bytecode,


00:08:13.000 --> 00:08:19.000
and basically this looks at how the bytecode gets handed off


00:08:19.000 --> 00:08:23.000
onto an evaluation loop in Python,


00:08:23.000 --> 00:08:25.000
which is this--


00:08:25.000 --> 00:08:27.000
Is that one of the first things you looked at


00:08:27.000 --> 00:08:29.000
when you started diving into the C source code?


00:08:29.000 --> 00:08:32.000
Is that the first file you went to?


00:08:32.000 --> 00:08:35.000
It was one of, yeah. It's such a big one.


00:08:35.000 --> 00:08:38.000
I remember on Python Bytes last week,


00:08:38.000 --> 00:08:42.000
you mentioned that Lukasz had been analyzing bits of Python


00:08:42.000 --> 00:08:43.000
that changed the most,


00:08:43.000 --> 00:08:46.000
and that was the most changed bit of Python.


00:08:46.000 --> 00:08:49.000
It's kind of like the brain of Python, really.


00:08:49.000 --> 00:08:52.000
It's the loop that evaluates all the instructions


00:08:52.000 --> 00:08:55.000
and then calls all the different C APIs


00:08:55.000 --> 00:08:59.000
to actually make your code do things.


00:08:59.000 --> 00:09:01.000
And what you can do in this PEP,


00:09:01.000 --> 00:09:06.000
which Brett proposed originally when he was working on Pidgin,


00:09:06.000 --> 00:09:09.000
was that you can actually tell CPython


00:09:09.000 --> 00:09:12.000
to not use its own evaluation loop,


00:09:12.000 --> 00:09:14.000
but use a replacement one.


00:09:14.000 --> 00:09:18.000
So this PEP 523, it is.


00:09:18.000 --> 00:09:21.000
You can basically write an extension module for Python


00:09:21.000 --> 00:09:24.000
and then say, "Okay, from now on,


00:09:24.000 --> 00:09:28.000
I will evaluate all Python code."


00:09:28.000 --> 00:09:30.000
Well, Python compiles it for you


00:09:30.000 --> 00:09:34.000
and then just gives it to you as a bytecode object


00:09:34.000 --> 00:09:36.000
with bytecodes in it,


00:09:36.000 --> 00:09:38.000
and then you can write a custom function


00:09:38.000 --> 00:09:40.000
for evaluating those bytecodes.


00:09:40.000 --> 00:09:41.000
Right, exactly.


00:09:41.000 --> 00:09:43.000
Normally, there's just a switch statement.


00:09:43.000 --> 00:09:45.000
It says, "If I get this bytecode, here's what I do.


00:09:45.000 --> 00:09:48.000
If I get that bytecode, here's what I do."


00:09:48.000 --> 00:09:52.000
One of the drawbacks of that that makes it super hard to optimize,


00:09:52.000 --> 00:09:56.000
among other things, is it's one statement at a time.


00:09:56.000 --> 00:09:57.000
Right?


00:09:57.000 --> 00:10:01.000
Like the cofalc.c, that switch statement, that loop, doesn't go,


00:10:01.000 --> 00:10:06.000
"Here's a series of possibly related opcodes.


00:10:06.000 --> 00:10:07.000
Make that happen."


00:10:07.000 --> 00:10:10.000
It goes, "No, you need to load this variable.


00:10:10.000 --> 00:10:12.000
Now create this object."


00:10:12.000 --> 00:10:15.000
There's just not a lot of room for optimization there.


00:10:15.000 --> 00:10:17.000
You're not going to inline a function


00:10:17.000 --> 00:10:21.000
or do other types of things when it's instruction by instruction.


00:10:21.000 --> 00:10:23.000
Yeah, exactly.


00:10:23.000 --> 00:10:29.000
What Pigeon does, essentially, is it implements that API.


00:10:29.000 --> 00:10:32.000
When you install Pigeon and activate Pigeon,


00:10:32.000 --> 00:10:34.000
which you do by importing Pigeon


00:10:34.000 --> 00:10:37.000
and then just doing pigeon.enable,


00:10:37.000 --> 00:10:40.000
it will tell CPython that Pigeon will be the function


00:10:40.000 --> 00:10:43.000
to evaluate all Python code from now on.


00:10:43.000 --> 00:10:44.000
Yeah.


00:10:44.000 --> 00:10:48.000
When it sees a new function for the first time,


00:10:48.000 --> 00:10:51.000
instead of interpreting all the bytecode instructions


00:10:51.000 --> 00:10:53.000
when you execute the function,


00:10:53.000 --> 00:10:57.000
it will basically interpret those ahead of time


00:10:57.000 --> 00:11:01.000
and then compile them into machine code instructions


00:11:01.000 --> 00:11:04.000
and then store that machine code in memory


00:11:04.000 --> 00:11:07.000
and then re-execute it every time you run the function.


00:11:07.000 --> 00:11:14.000
It basically compiles the function down into assembly, essentially,


00:11:14.000 --> 00:11:17.000
and then puts that assembly object in memory.


00:11:17.000 --> 00:11:19.000
Then when you run the Python function,


00:11:19.000 --> 00:11:21.000
if it's already been compiled,


00:11:21.000 --> 00:11:24.000
it will then just run those instructions.


00:11:24.000 --> 00:11:27.000
Right. As standard JIT stuff, it has to do it once.


00:11:27.000 --> 00:11:29.000
But then once it's hit one method, it's like,


00:11:29.000 --> 00:11:32.000
"Okay, this one, here's the machine instructions for it.


00:11:32.000 --> 00:11:34.000
We're just going to reuse that," right?


00:11:34.000 --> 00:11:41.000
Yeah, because the computer needs machine code to do anything.


00:11:41.000 --> 00:11:44.000
So something has to have compiled it down into machine code.


00:11:44.000 --> 00:11:49.000
In the case of normal CPython, CPython is written in C,


00:11:49.000 --> 00:11:53.000
and the C compiler has compiled that down into machine code.


00:11:53.000 --> 00:11:58.000
But it's a loop that it runs through for each bytecode instruction


00:11:58.000 --> 00:12:02.000
to go, "Okay, this is an add operator.


00:12:02.000 --> 00:12:06.000
So I'm going to take two objects off the stack,


00:12:06.000 --> 00:12:09.000
the left-hand side and the right-hand side,


00:12:09.000 --> 00:12:13.000
and then I'm going to call the add function in the C API."


00:12:13.000 --> 00:12:18.000
Exactly. Now, I kind of got you diving down deep a little too quick.


00:12:18.000 --> 00:12:21.000
I do want to set the stage just a moment


00:12:21.000 --> 00:12:23.000
before we get into how all of this works,


00:12:23.000 --> 00:12:27.000
because I think understanding where you're coming from


00:12:27.000 --> 00:12:30.000
and understanding some of the problems you're trying to solve


00:12:30.000 --> 00:12:33.000
are really going to be helpful to seeing the value here.


00:12:33.000 --> 00:12:38.000
So back in, what was it, April of 2020,


00:12:38.000 --> 00:12:43.000
whatever PyCon was, that virtual PyCon, the first virtual PyCon,


00:12:43.000 --> 00:12:46.000
you had that talk called "Why Python is Slow,"


00:12:46.000 --> 00:12:49.000
and you talked about some interesting things that really set the stage for,


00:12:49.000 --> 00:12:54.000
well, if you had a JIT and you had all sorts of control over it, as you do,


00:12:54.000 --> 00:12:57.000
how could it be faster? What could we do?


00:12:57.000 --> 00:13:00.000
So one of the things you talked about was this in-body problem,


00:13:00.000 --> 00:13:05.000
how C++ relative to, say, Python, there was a bit of a difference there,


00:13:05.000 --> 00:13:07.000
but also .NET Core was a lot faster,


00:13:07.000 --> 00:13:11.000
and really importantly, JavaScript was faster.


00:13:11.000 --> 00:13:15.000
Yeah, so that was 2019.


00:13:15.000 --> 00:13:17.000
- Gosh. - Okay.


00:13:17.000 --> 00:13:20.000
Yeah, this is part of this lovely pandemic.


00:13:20.000 --> 00:13:23.000
So yeah, I covered the in-body problem, which is interesting


00:13:23.000 --> 00:13:27.000
because it's not a--


00:13:27.000 --> 00:13:30.000
the in-body problem is a mathematical formula


00:13:30.000 --> 00:13:38.000
that calculates the position of the jovial planets,


00:13:38.000 --> 00:13:40.000
and the difference in time--


00:13:40.000 --> 00:13:43.000
It starts to get super complicated, right?


00:13:43.000 --> 00:13:46.000
Yeah, it's basically like a big mathematical formula,


00:13:46.000 --> 00:13:48.000
and it just loops through the iterations


00:13:48.000 --> 00:13:51.000
to work out the position of different planets.


00:13:51.000 --> 00:13:54.000
So it's kind of--


00:13:54.000 --> 00:13:59.000
The difference between C is seven seconds it takes to run the algorithm in C,


00:13:59.000 --> 00:14:02.000
and 14 minutes it takes to run it in Python.


00:14:02.000 --> 00:14:05.000
Python's even slower than Perl, which is embarrassing.


00:14:05.000 --> 00:14:10.000
Yeah, it's actually pretty much the worst-case scenario


00:14:10.000 --> 00:14:13.000
for all the reasonable languages, yeah.


00:14:13.000 --> 00:14:17.000
So yeah, in that talk, I dug into the details about why--


00:14:17.000 --> 00:14:20.000
some of the reasons why that is,


00:14:20.000 --> 00:14:25.000
and kind of the core of the in-body algorithm is this.


00:14:25.000 --> 00:14:28.000
It's a few lines of code which basically calculate--


00:14:28.000 --> 00:14:31.000
look at floating-point numbers, and it calculates--


00:14:31.000 --> 00:14:32.000
does the big calculations.


00:14:32.000 --> 00:14:35.000
So there's a lot of mathematical operations.


00:14:35.000 --> 00:14:40.000
There's minus, divide, power, add, which is great,


00:14:40.000 --> 00:14:42.000
and can all be done in line.


00:14:42.000 --> 00:14:45.000
CPUs are very efficient at doing this


00:14:45.000 --> 00:14:50.000
because CPUs natively understand floating-point numbers.


00:14:50.000 --> 00:14:53.000
A number in C and a number in Python, these are not equivalent, right?


00:14:53.000 --> 00:14:58.000
A floating-point number in C is probably eight bytes on the stack.


00:14:58.000 --> 00:15:01.000
A floating-point number in Python is--


00:15:01.000 --> 00:15:06.000
what is that, a pyFloat object that's 50 bytes and is out on the heap,


00:15:06.000 --> 00:15:09.000
probably separated in space from the other numbers


00:15:09.000 --> 00:15:13.000
in terms of it'll cause more cache misses and flushes


00:15:13.000 --> 00:15:15.000
and all sorts of stuff, right?


00:15:15.000 --> 00:15:20.000
Yeah, so a floating-point number in Python is an immutable object,


00:15:20.000 --> 00:15:25.000
and it's basically a wrapper around a double.


00:15:25.000 --> 00:15:30.000
So basically you have to create a Python object


00:15:30.000 --> 00:15:33.000
to store the floating-point number,


00:15:33.000 --> 00:15:36.000
and then if the value changes, you have to create a new one.


00:15:36.000 --> 00:15:40.000
So the issue in in-body is that you have to create--


00:15:40.000 --> 00:15:43.000
for one line of Python that just does a whole bunch of work


00:15:43.000 --> 00:15:47.000
to get a single answer, like a single floating-point number,


00:15:47.000 --> 00:15:51.000
all the interim values in that calculation create 18 objects,


00:15:51.000 --> 00:15:54.000
which are immediately discarded.


00:15:54.000 --> 00:15:55.000
Right, right, right.


00:15:55.000 --> 00:15:59.000
So the memory management kicks in just constantly, yeah?


00:15:59.000 --> 00:16:05.000
Yeah, and Python is pretty efficient at allocating small objects.


00:16:05.000 --> 00:16:09.000
But when you magnify that to the level that is seen in the in-body problem,


00:16:09.000 --> 00:16:12.000
then, yeah, that's why it's so slow effectively,


00:16:12.000 --> 00:16:15.000
because it's creating all these temporary objects


00:16:15.000 --> 00:16:19.000
and then destroying them in the next operation.


00:16:19.000 --> 00:16:22.000
Yeah, so one of the things you can do


00:16:22.000 --> 00:16:27.000
is maybe understand that there are numbers there


00:16:27.000 --> 00:16:29.000
and treat them--


00:16:29.000 --> 00:16:32.000
keep, say, the intermediate values as floating points


00:16:32.000 --> 00:16:35.000
and only return the result to Python, right?


00:16:35.000 --> 00:16:40.000
Like, okay, this Python runtime is going to need a pyint or a pylong


00:16:40.000 --> 00:16:43.000
or a pyfloat or whatever,


00:16:43.000 --> 00:16:46.000
but we don't need to do all the intermediate steps that way, right?


00:16:46.000 --> 00:16:48.000
We could compute those in a lower-level thing


00:16:48.000 --> 00:16:51.000
because we, again, understand the whole function,


00:16:51.000 --> 00:16:56.000
not just understand multiply two numbers, multiply two numbers,


00:16:56.000 --> 00:17:00.000
add two numbers, but that whole thing as a group, right?


00:17:00.000 --> 00:17:01.000
Yeah, exactly.


00:17:01.000 --> 00:17:06.000
So the principle behind some of the design ideas in Pigeon


00:17:06.000 --> 00:17:09.000
is that--and in lots of other compilers.


00:17:09.000 --> 00:17:12.000
This is not something I came up with.


00:17:12.000 --> 00:17:16.000
But the idea is to try and keep things as efficient as possible


00:17:16.000 --> 00:17:20.000
by just carrying values on the CPU registers


00:17:20.000 --> 00:17:24.000
and then not allocating memory in the heap.


00:17:24.000 --> 00:17:27.000
And a floating-point number fits in a CPU register.


00:17:27.000 --> 00:17:33.000
So a 64-bit integer or a floating-point number fit in a CPU register.


00:17:33.000 --> 00:17:35.000
So let's just carry those values on the registers


00:17:35.000 --> 00:17:42.000
and then do low-level instructions to do addition and minus


00:17:42.000 --> 00:17:47.000
and multiplication as well, but not divide


00:17:47.000 --> 00:17:50.000
because I found out Python has a whole bunch of, like,


00:17:50.000 --> 00:17:52.000
custom rules for division.


00:17:52.000 --> 00:17:57.000
So I couldn't rely on the CPU instructions to do that.


00:17:57.000 --> 00:17:59.000
So these are the types of things that, like,


00:17:59.000 --> 00:18:06.000
well, maybe we could use this pep523 and some kind of JIT compiler


00:18:06.000 --> 00:18:09.000
and turn it loose on this.


00:18:09.000 --> 00:18:15.000
I just earlier this week interviewed Guido and Mark Shannon


00:18:15.000 --> 00:18:17.000
about just general Python performance.


00:18:17.000 --> 00:18:21.000
They're working on sort of a parallel branch of making Python faster,


00:18:21.000 --> 00:18:23.000
which is great.


00:18:23.000 --> 00:18:27.000
So out of the livestream, Josh Peek asks,


00:18:27.000 --> 00:18:34.000
"Mark and Guido tease the potential of addition of a JIT to CPython 3.13.14.


00:18:34.000 --> 00:18:37.000
Would this potentially intersect with that project?


00:18:37.000 --> 00:18:39.000
Is this totally separate?


00:18:39.000 --> 00:18:41.000
Do you have any visibility there?"


00:18:41.000 --> 00:18:44.000
Yeah, I haven't asked to be involved in that yet.


00:18:44.000 --> 00:18:48.000
I don't know if--


00:18:48.000 --> 00:18:52.000
I mean, Mark Shannon's experience with compilers is, like,


00:18:52.000 --> 00:18:56.000
miles ahead of mine, to be frank.


00:18:56.000 --> 00:18:58.000
And, you know, Guido has invented the language,


00:18:58.000 --> 00:19:04.000
so their knowledge surpasses quite substantially.


00:19:04.000 --> 00:19:10.000
I hope that the work done in this project will be insightful


00:19:10.000 --> 00:19:12.000
when they're designing the JIT.


00:19:12.000 --> 00:19:16.000
And I've already spoken to both of them about this project


00:19:16.000 --> 00:19:20.000
and walk through, like, what's working and what isn't.


00:19:20.000 --> 00:19:22.000
And because it's, I guess, quite a bit ahead


00:19:22.000 --> 00:19:24.000
and it's dealing with some challenges,


00:19:24.000 --> 00:19:27.000
which they're probably going to hit when they come to this,


00:19:27.000 --> 00:19:30.000
then, yeah, it will steer them in that direction.


00:19:30.000 --> 00:19:33.000
Cool. Let's talk about compiling just for a bit.


00:19:33.000 --> 00:19:36.000
Because I did a lot of C++,


00:19:36.000 --> 00:19:40.000
and I remember pressing compile, the build button,


00:19:40.000 --> 00:19:42.000
or the run, which would build and run,


00:19:42.000 --> 00:19:43.000
and you would see it grind.


00:19:43.000 --> 00:19:45.000
And actually, thinking back,


00:19:45.000 --> 00:19:47.000
computers actually made noises.


00:19:47.000 --> 00:19:49.000
They would, like, grr, grr, grr, you know,


00:19:49.000 --> 00:19:51.000
like their hard drive would, like, make noises.


00:19:51.000 --> 00:19:54.000
You would hear it compiling, even.


00:19:54.000 --> 00:19:56.000
Yep.


00:19:56.000 --> 00:20:00.000
Also in C#, .NET, compile, but less and much faster.


00:20:00.000 --> 00:20:02.000
But in Python, it's just, it runs.


00:20:02.000 --> 00:20:03.000
It feels like it just runs.


00:20:03.000 --> 00:20:06.000
And I don't remember this compile step.


00:20:06.000 --> 00:20:10.000
And yet, there is an aspect of compiling, right?


00:20:10.000 --> 00:20:13.000
Yeah, it happens. You just don't see it.


00:20:13.000 --> 00:20:15.000
So, yeah, it happens behind the scenes.


00:20:15.000 --> 00:20:18.000
It compiles it, but it doesn't compile it into machine code.


00:20:18.000 --> 00:20:20.000
It compiles it into bytecode.


00:20:20.000 --> 00:20:22.000
Right, which is the same as .NET and Java,


00:20:22.000 --> 00:20:26.000
but the difference is what happens to that bytecode next, right?


00:20:26.000 --> 00:20:29.000
Yeah, it is similar.


00:20:29.000 --> 00:20:34.000
But the Python bytecode is much higher level.


00:20:34.000 --> 00:20:36.000
So there's, like, single operations


00:20:36.000 --> 00:20:39.000
for just add two objects, for example.


00:20:39.000 --> 00:20:41.000
Right, put this thing in a list.


00:20:41.000 --> 00:20:44.000
Yeah, like add this thing to a list or merge two dictionaries.


00:20:44.000 --> 00:20:50.000
It's like dict merge is a single bytecode instruction.


00:20:50.000 --> 00:20:54.000
Whereas .NET uses a specification.


00:20:54.000 --> 00:20:58.000
It's an open specification called ECMA335.


00:20:58.000 --> 00:21:04.000
And this specification describes different stack types.


00:21:04.000 --> 00:21:10.000
So it says, you know, there's like a 32-bit integer,


00:21:10.000 --> 00:21:13.000
64-bit integer, 16-bit, et cetera.


00:21:13.000 --> 00:21:15.000
There's floating point numbers,


00:21:15.000 --> 00:21:24.000
which come in the form of four or eight byte floating point numbers.


00:21:24.000 --> 00:21:27.000
And there's also things like booleans


00:21:27.000 --> 00:21:31.000
and then how branches and evaluations work.


00:21:31.000 --> 00:21:35.000
So it's closer to assembly.


00:21:35.000 --> 00:21:37.000
But the reason you don't want to write things in assembly


00:21:37.000 --> 00:21:41.000
is because assembly is specific to a CPU.


00:21:41.000 --> 00:21:45.000
And you often find yourself writing instructions


00:21:45.000 --> 00:21:48.000
which would only work on that particular CPU.


00:21:48.000 --> 00:21:50.000
And then when you ship it to the real world,


00:21:50.000 --> 00:21:52.000
like that doesn't work.


00:21:52.000 --> 00:21:54.000
One of the big benefits of JIT


00:21:54.000 --> 00:21:57.000
is it can look exactly at what you're running on and say,


00:21:57.000 --> 00:22:00.000
oh, this has this vectorized hardware thing.


00:22:00.000 --> 00:22:04.000
So let's use that version here, or this has this type of threading.


00:22:04.000 --> 00:22:08.000
So we're going to do some sort of memory management around that.


00:22:08.000 --> 00:22:12.000
Yeah, so C and C++ are ahead of time compilers.


00:22:12.000 --> 00:22:15.000
They will interpret your code, parse it,


00:22:15.000 --> 00:22:18.000
and compile it down into machine code instructions


00:22:18.000 --> 00:22:20.000
and then put it in a binary format,


00:22:20.000 --> 00:22:24.000
like a shared library or a standalone executable.


00:22:24.000 --> 00:22:29.000
.NET Java and other languages


00:22:29.000 --> 00:22:32.000
that have a JIT,


00:22:32.000 --> 00:22:35.000
they have both a compiled VM,


00:22:35.000 --> 00:22:38.000
which is something which has actually been compiled


00:22:38.000 --> 00:22:41.000
into a standalone executable, which is the framework.


00:22:41.000 --> 00:22:45.000
So the Java.exe, for example.


00:22:45.000 --> 00:22:48.000
And then it could compile down the code


00:22:48.000 --> 00:22:53.000
into an intermediary language and then evaluate that just in time


00:22:53.000 --> 00:22:56.000
and then typically cache the machine code


00:22:56.000 --> 00:22:59.000
onto a disk or into memory.


00:22:59.000 --> 00:23:02.000
And it does that using a JIT.


00:23:02.000 --> 00:23:10.000
And CPython interprets everything at runtime, essentially.


00:23:10.000 --> 00:23:13.000
So it does cache the bytecode,


00:23:13.000 --> 00:23:15.000
but it doesn't cache the machine code


00:23:15.000 --> 00:23:17.000
because it doesn't compile to machine code.


00:23:17.000 --> 00:23:19.000
And that's what Pigeon does.


00:23:19.000 --> 00:23:22.000
If you've seen PYC files with the DunderPi cache,


00:23:22.000 --> 00:23:26.000
down in theirs, that's the compiled output of Python.


00:23:26.000 --> 00:23:28.000
But like you said, it's much higher level


00:23:28.000 --> 00:23:30.000
and it gets interpreted after that.


00:23:30.000 --> 00:23:32.000
Yeah.


00:23:32.000 --> 00:23:35.000
So part of the insight of Pigeon is like,


00:23:35.000 --> 00:23:38.000
well, let's take that compile step


00:23:38.000 --> 00:23:42.000
and instead of outputting Python bytecode,


00:23:42.000 --> 00:23:45.000
what if we output intermediate language bytecode?


00:23:45.000 --> 00:23:49.000
Because there's a nice compiler hanging around that can compile that


00:23:49.000 --> 00:23:54.000
if you could somehow feed it that IL instead of PYC content, right?


00:23:54.000 --> 00:23:57.000
Yeah. So the steps are--


00:23:57.000 --> 00:23:59.000
[laughter]


00:23:59.000 --> 00:24:01.000
It's quite involved.


00:24:01.000 --> 00:24:04.000
The steps are-- and I do go to this in the talk--


00:24:04.000 --> 00:24:09.000
but Python code, abstract syntax tree,


00:24:09.000 --> 00:24:13.000
code object which has Python bytecode,


00:24:13.000 --> 00:24:18.000
and then Pigeon will basically compile Python bytecode


00:24:18.000 --> 00:24:22.000
into .NET intermediary bytecode,


00:24:22.000 --> 00:24:25.000
and then .NET will compile the intermediary bytecode


00:24:25.000 --> 00:24:28.000
into assembly, into a machine code.


00:24:28.000 --> 00:24:31.000
Then you attach that to, say, the function object


00:24:31.000 --> 00:24:33.000
or a class or something like that, right?


00:24:33.000 --> 00:24:35.000
Yeah, and then that bytecode is--


00:24:35.000 --> 00:24:39.000
that machine code, sorry, is essentially an executable


00:24:39.000 --> 00:24:42.000
which lives in memory.


00:24:42.000 --> 00:24:45.000
And then when you want to call it, you just call that memory address


00:24:45.000 --> 00:24:47.000
and it runs the function.


00:24:47.000 --> 00:24:50.000
Just in the same way that you would load a shared library


00:24:50.000 --> 00:24:53.000
and just call the address.


00:24:53.000 --> 00:24:56.000
Right. You might have a .SO file,


00:24:56.000 --> 00:24:59.000
and you import it and run it, and as far as you're concerned,


00:24:59.000 --> 00:25:01.000
magically it just runs, right?


00:25:01.000 --> 00:25:04.000
- Exactly. - Okay.


00:25:04.000 --> 00:25:07.000
Is it slow? The compilation step in particular?


00:25:07.000 --> 00:25:10.000
Not necessarily-- we'll get to the performance of the overall system,


00:25:10.000 --> 00:25:13.000
but is this JIT step-- is this a big deal?


00:25:13.000 --> 00:25:16.000
Does it take a lot of memory? What's it like?


00:25:16.000 --> 00:25:20.000
I haven't actually focused too hard on the performance of the compilation step


00:25:20.000 --> 00:25:23.000
because a lot of the problems I'm looking at are


00:25:23.000 --> 00:25:27.000
compile once, execute 50,000 times,


00:25:27.000 --> 00:25:32.000
and the overhead doesn't really matter that much.


00:25:32.000 --> 00:25:36.000
Although it's pretty fast.


00:25:36.000 --> 00:25:39.000
I've been really impressed.


00:25:39.000 --> 00:25:42.000
Pigeon is written in C++,


00:25:42.000 --> 00:25:45.000
and the compilation step is actually pretty quick.


00:25:45.000 --> 00:25:48.000
The overhead is 10-15%


00:25:48.000 --> 00:25:51.000
of the execution time on the first pass,


00:25:51.000 --> 00:25:54.000
depending on the complexity of the function,


00:25:54.000 --> 00:25:58.000
but if the function takes a second to run,


00:25:58.000 --> 00:26:04.000
then .15 of a second is around how much it'll take to compile it.


00:26:04.000 --> 00:26:07.000
- Okay. - Roughly.


00:26:07.000 --> 00:26:10.000
Yeah, that's not bad. And then it goes faster.


00:26:10.000 --> 00:26:14.000
Yeah, and then once it's done it once, that's it.


00:26:14.000 --> 00:26:18.000
With the exception that Pigeon has a feature called


00:26:18.000 --> 00:26:22.000
profile-guided compilation, which is something


00:26:22.000 --> 00:26:27.000
that I designed to get around how dynamic Python is.


00:26:27.000 --> 00:26:33.000
So JIT compilers are brilliant when you've got statically typed languages.


00:26:33.000 --> 00:26:36.000
So if you know that this variable is an integer, and this variable is a string,


00:26:36.000 --> 00:26:39.000
and this variable is an object,


00:26:39.000 --> 00:26:42.000
then you can compile all the correct instructions.


00:26:42.000 --> 00:26:48.000
In Python, variable A could be assigned as a string,


00:26:48.000 --> 00:26:51.000
and then changed to an integer,


00:26:51.000 --> 00:26:54.000
and then you can assign it to the return of a function,


00:26:54.000 --> 00:26:57.000
which could be anything.


00:26:57.000 --> 00:27:01.000
So one of the challenges I looked at was how do you actually make--


00:27:01.000 --> 00:27:04.000
a JIT is only going to be faster if you've got optimizations,


00:27:04.000 --> 00:27:08.000
and you can't make optimizations if you have to generalize everything.


00:27:08.000 --> 00:27:14.000
So what it does is a feature called PGC,


00:27:14.000 --> 00:27:18.000
which it will compile a profiling function.


00:27:18.000 --> 00:27:21.000
So the first time it runs the Python code,


00:27:21.000 --> 00:27:27.000
it's basically going to look at what variables are.


00:27:27.000 --> 00:27:32.000
It's almost like you're doing a C profile on itself.


00:27:32.000 --> 00:27:36.000
Yeah, so basically it compiles a function that runs,


00:27:36.000 --> 00:27:39.000
and then when that function is running,


00:27:39.000 --> 00:27:42.000
it captures a whole bunch of information about what's actually happening,


00:27:42.000 --> 00:27:45.000
and then it makes some assumptions and says,


00:27:45.000 --> 00:27:48.000
"Oh, when you were adding these three variables last time,


00:27:48.000 --> 00:27:53.000
they were all integers, so let's optimize that for integers next time."


00:27:53.000 --> 00:27:58.000
And if they do change, then it depends.


00:27:58.000 --> 00:28:01.000
What happens if they change? Okay, crashing is an option.


00:28:01.000 --> 00:28:04.000
You probably don't totally want to go with the crashing part,


00:28:04.000 --> 00:28:07.000
but that might be an intermediate, like we're building it,


00:28:07.000 --> 00:28:10.000
and it's getting dialed in.


00:28:10.000 --> 00:28:16.000
Some options that come to mind is you could have an alternate compiled version


00:28:16.000 --> 00:28:20.000
that says, "Okay, we've also seen this come as a string, int, int,


00:28:20.000 --> 00:28:22.000
and so we're going to compile a separate one


00:28:22.000 --> 00:28:26.000
and then do a lookup on the arguments and go from there."


00:28:26.000 --> 00:28:29.000
Yes, they're called specializations,


00:28:29.000 --> 00:28:32.000
and that's something that Mark Shannon talked about.


00:28:32.000 --> 00:28:38.000
I think when CPython does its own JIT, they will definitely have specializations.


00:28:38.000 --> 00:28:45.000
The downside is that you have a lot of memory overhead


00:28:45.000 --> 00:28:47.000
if there are lots of specializations.


00:28:47.000 --> 00:28:51.000
And a good example would be in the unit test module,


00:28:51.000 --> 00:28:54.000
the assertEqual function.


00:28:54.000 --> 00:28:59.000
This is pretty much the first one I kind of slammed into.


00:28:59.000 --> 00:29:03.000
Pidgin tried to optimize the assertEqual function,


00:29:03.000 --> 00:29:05.000
which could take anything.


00:29:05.000 --> 00:29:08.000
It could take two strings, a string and a number.


00:29:08.000 --> 00:29:10.000
The first question is, are they the same type,


00:29:10.000 --> 00:29:13.000
or can they be coerced in the same type?


00:29:13.000 --> 00:29:16.000
And then just keep going down these different cases.


00:29:16.000 --> 00:29:18.000
It can't be simple.


00:29:18.000 --> 00:29:21.000
It was actually a conversation with Guido.


00:29:21.000 --> 00:29:24.000
He suggested looking at type guards.


00:29:24.000 --> 00:29:31.000
So a type guard is--so before I go into the optimized code,


00:29:31.000 --> 00:29:35.000
it will check to see, has the variable changed


00:29:35.000 --> 00:29:38.000
from what it was last time it got profiled?


00:29:38.000 --> 00:29:40.000
And then if it has changed type,


00:29:40.000 --> 00:29:44.000
then it will default back into a generic path.


00:29:44.000 --> 00:29:49.000
So that's essentially how it deals with different types.


00:29:49.000 --> 00:29:51.000
Yeah, one of the fall-through paths could be just,


00:29:51.000 --> 00:29:54.000
well, let Python have it.


00:29:54.000 --> 00:29:57.000
Let Python just run the byte code.


00:29:57.000 --> 00:30:00.000
Yeah, there are some things that Pidgin doesn't support.


00:30:00.000 --> 00:30:03.000
Async and await is one major feature.


00:30:03.000 --> 00:30:07.000
If it comes across asynchronous generators,


00:30:07.000 --> 00:30:09.000
then it will just hand them back to Python,


00:30:09.000 --> 00:30:11.000
and Python executes them.


00:30:11.000 --> 00:30:13.000
So one of the big things--


00:30:13.000 --> 00:30:15.000
It should be in there, though, right?


00:30:15.000 --> 00:30:18.000
C# and .NET also have async and await.


00:30:18.000 --> 00:30:20.000
I know that means quite a bit differently,


00:30:20.000 --> 00:30:22.000
but theoretically, you're down the road


00:30:22.000 --> 00:30:24.000
when you have more time, maybe.


00:30:24.000 --> 00:30:26.000
It's not completely out of the world.


00:30:26.000 --> 00:30:29.000
Yeah, I actually kind of started implementing it


00:30:29.000 --> 00:30:32.000
and put most of it together, only to realize that


00:30:32.000 --> 00:30:36.000
the APIs for asynchronous generators


00:30:36.000 --> 00:30:40.000
are all private in CPython, so I can't import them,


00:30:40.000 --> 00:30:44.000
which makes it technically impossible to implement,


00:30:44.000 --> 00:30:47.000
which is a bit of a shame.


00:30:47.000 --> 00:30:50.000
But yeah, that's one of the drawbacks at the moment,


00:30:50.000 --> 00:30:53.000
is you can't do async and await.


00:30:53.000 --> 00:30:56.000
Right, but if this were super successful,


00:30:56.000 --> 00:30:58.000
I can see that that's like, "Okay, well, let's go ahead


00:30:58.000 --> 00:31:02.000
and expose that, because Anthony's so close."


00:31:02.000 --> 00:31:04.000
[laughs]


00:31:04.000 --> 00:31:06.000
Yeah, they could probably maybe be coerced.


00:31:06.000 --> 00:31:09.000
It's like a one-line code change, I think.


00:31:09.000 --> 00:31:13.000
This doesn't apply to the profile-guided optimizations,


00:31:13.000 --> 00:31:18.000
but one of the things that these frameworks have--


00:31:18.000 --> 00:31:20.000
I know that .NET has had it at several levels.


00:31:20.000 --> 00:31:24.000
They've got this ngen utility that will take


00:31:24.000 --> 00:31:27.000
a .NET assembly in IL, and you can pre-compile it,


00:31:27.000 --> 00:31:29.000
like ahead of time compile it,


00:31:29.000 --> 00:31:32.000
and generate a native image on your machine.


00:31:32.000 --> 00:31:35.000
And then Xamarin had that, because they had to have


00:31:35.000 --> 00:31:37.000
something like this to get onto iOS,


00:31:37.000 --> 00:31:42.000
where they ran the JIT compiler in advance and saved it.


00:31:42.000 --> 00:31:44.000
Is that something that could potentially be done here,


00:31:44.000 --> 00:31:47.000
or is it too much?


00:31:47.000 --> 00:31:49.000
I watched this space.


00:31:49.000 --> 00:31:52.000
I've been researching that.


00:31:52.000 --> 00:31:54.000
That's kind of one of the things I've been looking into,


00:31:54.000 --> 00:32:00.000
is can you compile it down into a format


00:32:00.000 --> 00:32:04.000
which can be stored and then loaded or marshaled,


00:32:04.000 --> 00:32:08.000
or can it be stored into a portable executable format


00:32:08.000 --> 00:32:12.000
or some other binary format?


00:32:12.000 --> 00:32:14.000
Lots of security implications there as well,


00:32:14.000 --> 00:32:18.000
so that's one thing I'm cautious of.


00:32:18.000 --> 00:32:23.000
I hadn't even thought about all the challenges you got there.


00:32:23.000 --> 00:32:26.000
Yeah, that could be interesting.


00:32:26.000 --> 00:32:30.000
But if it comes along that, yeah, this is pretty good,


00:32:30.000 --> 00:32:32.000
but there's this slower startup, and I know something


00:32:32.000 --> 00:32:36.000
that the core devs and Gio have been very protective of


00:32:36.000 --> 00:32:39.000
is the startup speed of Python, right?


00:32:39.000 --> 00:32:42.000
That they don't want it to start super slow,


00:32:42.000 --> 00:32:46.000
because often it's run on a little tiny bit of


00:32:46.000 --> 00:32:48.000
"do this tiny thing, and then we're going to drop back


00:32:48.000 --> 00:32:50.000
and then maybe run Python again on this tiny thing,"


00:32:50.000 --> 00:32:53.000
or even multi-processing, you know,


00:32:53.000 --> 00:32:56.000
fork it, run these things, drop out of it.


00:32:56.000 --> 00:32:58.000
So I'm just thinking of how do you protect,


00:32:58.000 --> 00:33:03.000
how do you still achieve that goal and gain these advantages?


00:33:03.000 --> 00:33:05.000
Yeah, I think there probably could be work done


00:33:05.000 --> 00:33:08.000
to make the compiler more efficient.


00:33:08.000 --> 00:33:11.000
Also, you can set the threshold of how many times


00:33:11.000 --> 00:33:15.000
should a function be called before you JIT compile it.


00:33:15.000 --> 00:33:17.000
So that's the threshold setting.


00:33:17.000 --> 00:33:19.000
So if you call a function once,


00:33:19.000 --> 00:33:21.000
there's probably no need to JIT compile it.


00:33:21.000 --> 00:33:24.000
Well, there is no need to JIT compile it,


00:33:24.000 --> 00:33:27.000
because you're compiling it and then just running it


00:33:27.000 --> 00:33:30.000
straight afterwards, whereas if it gets called a lot,


00:33:30.000 --> 00:33:32.000
then you would want to call it a lot.


00:33:32.000 --> 00:33:34.000
And that's kind of where you get these things


00:33:34.000 --> 00:33:38.000
called hot functions, which is a function which is run a lot.


00:33:38.000 --> 00:33:43.000
You want to specialize and make more efficient, essentially.


00:33:43.000 --> 00:33:48.000
So yeah, if you're, like, sorting a list, for example,


00:33:48.000 --> 00:33:53.000
then doing comparisons between two different types,


00:33:53.000 --> 00:33:56.000
you'd want to make that as efficient as possible,


00:33:56.000 --> 00:34:01.000
and that would inherently make sorting algorithms quicker.


00:34:01.000 --> 00:34:04.000
For sure. Yeah, so there's multiple stages here, right?


00:34:04.000 --> 00:34:08.000
There's the uncompiled code or letting Python run the code.


00:34:08.000 --> 00:34:10.000
Then there's compiling it with those hooks


00:34:10.000 --> 00:34:13.000
to understand what types come in for the specialization.


00:34:13.000 --> 00:34:17.000
And then there's generating the optimized version.


00:34:17.000 --> 00:34:22.000
So if it's run once, at best you'll get the unoptimized compiled version.


00:34:22.000 --> 00:34:27.000
And unoptimized compiled code is probably not that much better, right?


00:34:27.000 --> 00:34:29.000
Yeah, there are some things that have been,


00:34:29.000 --> 00:34:33.000
that it can do to optimize, for example.


00:34:33.000 --> 00:34:36.000
There's a list of all the built-ins,


00:34:36.000 --> 00:34:39.000
and it knows what return types the built-ins have.


00:34:39.000 --> 00:34:47.000
So for sure, like, it knows if you run list as a built-in function,


00:34:47.000 --> 00:34:51.000
then it will return a list.


00:34:51.000 --> 00:34:54.000
And I have even put in a check


00:34:54.000 --> 00:34:59.000
if somebody's overridden the list built-in, which is possible.


00:34:59.000 --> 00:35:03.000
And you have to test that as well, which is interesting.


00:35:03.000 --> 00:35:06.000
But yeah, it does make a whole bunch of assumptions like that,


00:35:06.000 --> 00:35:11.000
which is generic and works in most code.


00:35:11.000 --> 00:35:16.000
And for example, if you're accessing the fourth item in a list,


00:35:16.000 --> 00:35:20.000
so you've got a list called names,


00:35:20.000 --> 00:35:25.000
and in square brackets you put names, square bracket, the number three,


00:35:25.000 --> 00:35:28.000
then three is a constant, so it can't change.


00:35:28.000 --> 00:35:31.000
It's compiled into the function.


00:35:31.000 --> 00:35:35.000
If the code knows for sure that names is a list,


00:35:35.000 --> 00:35:40.000
then instead of calling a C API to see what it is


00:35:40.000 --> 00:35:44.000
and get the index, et cetera, et cetera, et cetera,


00:35:44.000 --> 00:35:48.000
the JIT compiler can go, "Oh, I already know this is a list.


00:35:48.000 --> 00:35:51.000
I know the index you want is the fourth number."


00:35:51.000 --> 00:35:54.000
So instead of calling all this stuff,


00:35:54.000 --> 00:35:59.000
just calculate the memory address of the fourth item in the list


00:35:59.000 --> 00:36:02.000
and then put in a little check to make sure


00:36:02.000 --> 00:36:05.000
that there are four items in that list.


00:36:05.000 --> 00:36:07.000
And then just compile that into the function,


00:36:07.000 --> 00:36:10.000
and it's immediately significantly quicker.


00:36:10.000 --> 00:36:13.000
Go to where the data is stored in the list,


00:36:13.000 --> 00:36:16.000
go over by the size of four pointers,


00:36:16.000 --> 00:36:18.000
so eight times four or something like that,


00:36:18.000 --> 00:36:21.000
and just read it right there, something like that.


00:36:21.000 --> 00:36:24.000
- Yeah, exactly. - Okay.


00:36:24.000 --> 00:36:27.000
Assuming for sure that that's what it is, right?


00:36:27.000 --> 00:36:29.000
- Otherwise-- - It sounds dangerous.


00:36:29.000 --> 00:36:32.000
Yeah, exactly. This is some of the security things, right?


00:36:32.000 --> 00:36:35.000
Go over some part in memory and read it, and then do something.


00:36:35.000 --> 00:36:38.000
That sounds like buffer overflow when done wrong,


00:36:38.000 --> 00:36:41.000
so I can see why you'd be nervous.


00:36:41.000 --> 00:36:45.000
Yeah, exactly. But that's how compilers work.


00:36:45.000 --> 00:36:48.000
You're dealing with memory addresses, essentially,


00:36:48.000 --> 00:36:51.000
and low-level instructions.


00:36:51.000 --> 00:36:54.000
Something we thankfully don't have to do a ton of in Python,


00:36:54.000 --> 00:36:58.000
but in CPython, you're in C, right? That's a C thing.


00:36:58.000 --> 00:37:01.000
Yeah, definitely. And when you're working with tuples,


00:37:01.000 --> 00:37:03.000
you do that as well.


00:37:03.000 --> 00:37:06.000
So you work out the address of the nth element


00:37:06.000 --> 00:37:09.000
and then just use that address.


00:37:09.000 --> 00:37:12.000
And increment the reference counter.


00:37:12.000 --> 00:37:15.000
Also, don't forget that. Memory management breaks.


00:37:15.000 --> 00:37:17.000
[laughs]


00:37:17.000 --> 00:37:20.000
How interesting.


00:37:20.000 --> 00:37:22.000
So where are you with this?


00:37:22.000 --> 00:37:25.000
You said it's going to go to 1.0, which sounds like


00:37:25.000 --> 00:37:29.000
I could install this and I could run it and--


00:37:29.000 --> 00:37:32.000
- Yeah, so it's going to-- - It's magic, right?


00:37:32.000 --> 00:37:35.000
It's going to 1.0.


00:37:35.000 --> 00:37:38.000
Works only on Python 3.10.


00:37:38.000 --> 00:37:41.000
That's one big thing.


00:37:41.000 --> 00:37:44.000
Upgraded it from 3.9 to 3.10.


00:37:44.000 --> 00:37:47.000
When 3.10 was released, actually,


00:37:47.000 --> 00:37:50.000
and I won't be backporting it,


00:37:50.000 --> 00:37:54.000
it's just so much has changed in Python and the APIs.


00:37:54.000 --> 00:37:58.000
You can pip install it on Python 3.10.


00:37:58.000 --> 00:38:01.000
You need to have .NET 6 installed


00:38:01.000 --> 00:38:04.000
when that is released.


00:38:04.000 --> 00:38:07.000
Or you can install release candidate 2, which is already out.


00:38:07.000 --> 00:38:10.000
- And yeah, you can enable that. - That sounds like it's pretty close to done, right?


00:38:10.000 --> 00:38:13.000
I don't know when it's actually, but they've got their .NET conference in--


00:38:13.000 --> 00:38:16.000
what is that, six days? Surely.


00:38:16.000 --> 00:38:19.000
Yeah, they say it launches then.


00:38:19.000 --> 00:38:23.000
By the time this episode is out, it's very likely very close to just out.


00:38:23.000 --> 00:38:26.000
So, okay, that's a pretty easy thing.


00:38:26.000 --> 00:38:29.000
Can I brew install .NET? Do you know? I've not tried.


00:38:29.000 --> 00:38:32.000
I don't know. That's a good question.


00:38:32.000 --> 00:38:35.000
There is an installer for Mac.


00:38:35.000 --> 00:38:38.000
Pigeon also works on ARM 64, which is worth noting.


00:38:38.000 --> 00:38:42.000
And it's a very complicated detail of JIT compilers.


00:38:42.000 --> 00:38:46.000
So, yeah, ARM support was no small feat.


00:38:46.000 --> 00:38:49.000
But it's something that people just expected to be there.


00:38:49.000 --> 00:38:53.000
Yeah. Well, there's obviously the M1s, right?


00:38:53.000 --> 00:38:56.000
Everyone with an M1 would like--


00:38:56.000 --> 00:38:59.000
who wants to do this would really like it to work on ARM.


00:38:59.000 --> 00:39:03.000
But there's also Raspberry Pis and other places that Python shows up.


00:39:03.000 --> 00:39:07.000
I don't know, helicopters on Mars. I don't know if that's ARM or not. Probably.


00:39:07.000 --> 00:39:14.000
Yeah. So, I tested Linux ARM 64, which will be the Raspberry Pis and other.


00:39:14.000 --> 00:39:18.000
And also Mac ARM 64.


00:39:18.000 --> 00:39:26.000
I have not tested Windows ARM 64 because there is no Python for ARM 64 on Windows.


00:39:26.000 --> 00:39:28.000
Okay.


00:39:28.000 --> 00:39:35.000
Steve Dower has released a preview package of the libraries,


00:39:35.000 --> 00:39:37.000
but not a standalone executable.


00:39:37.000 --> 00:39:41.000
But it may come out in the future.


00:39:41.000 --> 00:39:43.000
Yeah. That whole story--


00:39:43.000 --> 00:39:46.000
No, but that whole story of Windows on ARM is--


00:39:46.000 --> 00:39:50.000
I would love to see it better handled.


00:39:50.000 --> 00:39:53.000
But it's like you can't even buy it, right?


00:39:53.000 --> 00:39:57.000
Is it supported? It's provided to OEMs, but kind of, sort of.


00:39:57.000 --> 00:40:00.000
I don't know. It's in a weird state, right?


00:40:00.000 --> 00:40:03.000
It's not normal Windows. It's not super supported.


00:40:03.000 --> 00:40:06.000
Yeah. I think, who knows?


00:40:06.000 --> 00:40:10.000
I can't speak-- I do work for Microsoft, so I'm definitely not going to give my opinion.


00:40:10.000 --> 00:40:14.000
Yeah. I'm not asking for your-- this is more me just making a proclamation.


00:40:14.000 --> 00:40:18.000
I have Windows 11 running on my Mac Mini M1.


00:40:18.000 --> 00:40:20.000
And it is running ARM.


00:40:20.000 --> 00:40:24.000
But to get it, I had to go join the Insiders program and then install it.


00:40:24.000 --> 00:40:29.000
And it's permanently got this, like, watermark that it's a tainted version,


00:40:29.000 --> 00:40:30.000
but you can try to use it.


00:40:30.000 --> 00:40:33.000
And, yeah, it works fine, but it's kind of sluggish and whatnot.


00:40:33.000 --> 00:40:37.000
So, anyway, hopefully that comes along better.


00:40:37.000 --> 00:40:41.000
So it sounds like it's supported on the various things.


00:40:41.000 --> 00:40:45.000
I have .NET 6 installed and Python 3.10 installed.


00:40:45.000 --> 00:40:48.000
Neither of those have to be messed with, right?


00:40:48.000 --> 00:40:52.000
You've got the PEP for Python, and you've got just the legit--


00:40:52.000 --> 00:40:54.000
Vanilla installations, yeah.


00:40:54.000 --> 00:40:55.000
Yeah, that's beautiful.


00:40:55.000 --> 00:40:58.000
And so give us a little walkthrough on, like, how we might use this.


00:40:58.000 --> 00:41:04.000
What do I have to do to change my code to get these compilation steps?


00:41:04.000 --> 00:41:08.000
So wherever your code starts running, you need to import Pidgin


00:41:08.000 --> 00:41:12.000
and then call the enable function on Pidgin.


00:41:12.000 --> 00:41:17.000
There's also a config function which configures different settings


00:41:17.000 --> 00:41:18.000
in terms of how Pidgin runs.


00:41:18.000 --> 00:41:20.000
Thresholds, for example, like how many times--


00:41:20.000 --> 00:41:25.000
Yeah, the hot code threshold optimization level,


00:41:25.000 --> 00:41:28.000
which is a level between 0 and 2,


00:41:28.000 --> 00:41:32.000
which is how aggressive the optimizer is.


00:41:32.000 --> 00:41:35.000
And you can also enable or disable the profiler.


00:41:35.000 --> 00:41:40.000
Yeah. I remember in C, way back when I was doing C for projects,


00:41:40.000 --> 00:41:43.000
there were these different optimization levels,


00:41:43.000 --> 00:41:47.000
and it was like, "Well, you can go to 1 or 2,


00:41:47.000 --> 00:41:48.000
and it'll probably still work.


00:41:48.000 --> 00:41:50.000
If you go too far, it'll just crash."


00:41:50.000 --> 00:41:51.000
Yeah.


00:41:51.000 --> 00:41:53.000
It's like, "What's going on? I don't understand.


00:41:53.000 --> 00:41:56.000
Okay, we'll dial it back until it's stable,


00:41:56.000 --> 00:41:58.000
and that's as fast as we can make it go."


00:41:58.000 --> 00:42:01.000
Yeah, this is my recommendation.


00:42:01.000 --> 00:42:04.000
Go as high as you can without it catching fire.


00:42:04.000 --> 00:42:05.000
[laughs]


00:42:05.000 --> 00:42:07.000
Go with that.


00:42:07.000 --> 00:42:09.000
So maybe start at 0.


00:42:09.000 --> 00:42:11.000
No, it defaults to 1.


00:42:11.000 --> 00:42:12.000
Yeah.


00:42:12.000 --> 00:42:14.000
So yeah, don't turn it up to 11.


00:42:14.000 --> 00:42:19.000
But yeah, and then the profiler is on by default,


00:42:19.000 --> 00:42:23.000
which I may disable in the future


00:42:23.000 --> 00:42:27.000
because the profiler probably causes the most issues


00:42:27.000 --> 00:42:33.000
where you've got a function which ran with integers a thousand times,


00:42:33.000 --> 00:42:37.000
and then all of a sudden somebody gave it some floating-point numbers.


00:42:37.000 --> 00:42:39.000
It won't crash.


00:42:39.000 --> 00:42:41.000
It will either fall back to default path


00:42:41.000 --> 00:42:44.000
or it will raise an exception to say that it got some values


00:42:44.000 --> 00:42:45.000
which it didn't expect.


00:42:45.000 --> 00:42:48.000
And if you do see that, it'll tell you in the error message.


00:42:48.000 --> 00:42:51.000
And it will suggest that you turn the profiler off


00:42:51.000 --> 00:42:54.000
and then rerun the code.


00:42:54.000 --> 00:42:57.000
For me, I feel like that would suggest to me


00:42:57.000 --> 00:42:59.000
that maybe I should go check my code.


00:42:59.000 --> 00:43:00.000
Yeah.


00:43:00.000 --> 00:43:03.000
Not always, but often if I got something like,


00:43:03.000 --> 00:43:05.000
"I'm trying to take these things and add them


00:43:05.000 --> 00:43:07.000
and get what I think is the result,


00:43:07.000 --> 00:43:10.000
and I'm trying to do math, not string concatenation,


00:43:10.000 --> 00:43:11.000
and I get a string,"


00:43:11.000 --> 00:43:14.000
chances are that's actually a mistake,


00:43:14.000 --> 00:43:18.000
not something that I want to take account for.


00:43:18.000 --> 00:43:20.000
It could be, but probably not.


00:43:20.000 --> 00:43:23.000
Yeah, I actually saw a useful example of this yesterday on Twitter.


00:43:23.000 --> 00:43:28.000
Somebody shared, "Adding two floating-point numbers in Python,


00:43:28.000 --> 00:43:33.000
a and b, a plus b is not the same as b plus a."


00:43:33.000 --> 00:43:37.000
They actually give different results, which is crazy.


00:43:37.000 --> 00:43:40.000
But yeah, when you work with floating-point numbers and integers,


00:43:40.000 --> 00:43:43.000
and you don't mean to, but you end up with different types,


00:43:43.000 --> 00:43:46.000
you will get some weird results anyway.


00:43:46.000 --> 00:43:47.000
Yeah.


00:43:47.000 --> 00:43:50.000
So yeah, in terms of whether this will work,


00:43:50.000 --> 00:43:54.000
I've compiled some pretty big libraries, and they've worked fine.


00:43:54.000 --> 00:43:58.000
Pandas, Flask, Django,


00:43:58.000 --> 00:44:01.000
chucked a lot of the CPython's test suite.


00:44:01.000 --> 00:44:04.000
Yeah, this as well.


00:44:04.000 --> 00:44:10.000
So yeah, it will run about 50,000 tests or something, I think.


00:44:10.000 --> 00:44:11.000
That's pretty good.


00:44:11.000 --> 00:44:17.000
Yeah, a lot of the CPython tests are testing specific internal things in CPython.


00:44:17.000 --> 00:44:22.000
So some of them do fail, but it's not anything that Pigeon's done.


00:44:22.000 --> 00:44:24.000
And pytest works as well.


00:44:24.000 --> 00:44:28.000
So yeah, there's a lot of big libraries.


00:44:28.000 --> 00:44:31.000
NumPy works fine.


00:44:31.000 --> 00:44:35.000
There's tests for NumPy, tests for Pandas, tests for Flask, Django.


00:44:35.000 --> 00:44:40.000
All the stuff that I'd expect people to try is in there.


00:44:40.000 --> 00:44:44.000
If you're working with a lot of C extension modules, they also do work.


00:44:44.000 --> 00:44:46.000
Cython extensions work.


00:44:46.000 --> 00:44:51.000
So in terms of compatibility, that was one of the main things I wanted to focus on,


00:44:51.000 --> 00:44:54.000
was instead of going super aggressive with the optimizations,


00:44:54.000 --> 00:44:57.000
I just want to make sure this works with existing code,


00:44:57.000 --> 00:45:02.000
because there are lots of other projects which--


00:45:02.000 --> 00:45:07.000
We have PyPy already, PYPY, which is also a JIT compiler,


00:45:07.000 --> 00:45:10.000
and it works not with the .NET backing the JIT,


00:45:10.000 --> 00:45:15.000
but some of the hot functions getting compiled versus just running in Python.


00:45:15.000 --> 00:45:19.000
That kind of stuff is pretty similar now, but they made the big tradeoff,


00:45:19.000 --> 00:45:22.000
like we're going to just go all in on compiling,


00:45:22.000 --> 00:45:25.000
and we're going to not necessarily integrate with the C APIs in the same way,


00:45:25.000 --> 00:45:27.000
which means breaking with some of these things,


00:45:27.000 --> 00:45:30.000
like NumPy or Pandas that people sometimes care about.


00:45:30.000 --> 00:45:34.000
Yeah, and they also have to play catch up on the language features.


00:45:34.000 --> 00:45:39.000
So if there's new features in 3.9, 3.10 in the language,


00:45:39.000 --> 00:45:42.000
like new operators or whatever,


00:45:42.000 --> 00:45:46.000
then PyPy has to then go and implement that, which is hard.


00:45:46.000 --> 00:45:49.000
But Pidgin, you load it into CPython,


00:45:49.000 --> 00:45:54.000
so in terms of language, it would be exactly the same.


00:45:54.000 --> 00:46:01.000
Often a lot of those language features are just syntactic sugar over existing things, right?


00:46:01.000 --> 00:46:04.000
Yeah, exactly.


00:46:04.000 --> 00:46:07.000
And then if there's anything which is not compatible, like I mentioned,


00:46:07.000 --> 00:46:10.000
async and await, then it will default back to CPython,


00:46:10.000 --> 00:46:13.000
and that transition is seamless, and you won't notice.


00:46:13.000 --> 00:46:17.000
It will just run the code regardless.


00:46:17.000 --> 00:46:21.000
Awesome. So it looks like it works for the most part.


00:46:21.000 --> 00:46:25.000
I haven't totally tried it, but it sounds like it works quite extensively.


00:46:25.000 --> 00:46:27.000
The way you use it is you pip install Pidgin,


00:46:27.000 --> 00:46:30.000
and then just import Pidgin, pidgin.enable is option one,


00:46:30.000 --> 00:46:33.000
and then that's it, right? There's nothing else that you have to do?


00:46:33.000 --> 00:46:35.000
Nothing else you have to do.


00:46:35.000 --> 00:46:40.000
You just run the Python code, and it will just automatically spot stuff


00:46:40.000 --> 00:46:42.000
that it should compile and compile it for you.


00:46:42.000 --> 00:46:47.000
Fantastic. And then another option I see on the page here is I can say pidgin,


00:46:47.000 --> 00:46:52.000
some Python file, and not necessarily modify the file, but tell it to execute.


00:46:52.000 --> 00:46:57.000
What does it do? Import pidgin, pidgin.enable, eval?


00:46:57.000 --> 00:47:01.000
Basically, yeah.


00:47:01.000 --> 00:47:05.000
Yeah, basically, it's a very small script.


00:47:05.000 --> 00:47:09.000
So yeah, Pidgin is a standalone command that you can run.


00:47:09.000 --> 00:47:14.000
So instead of running Python, you run Pidgin against a script or a module,


00:47:14.000 --> 00:47:18.000
and all the arguments should work as normal.


00:47:18.000 --> 00:47:21.000
You also have the -m for built-in stuff, right?


00:47:21.000 --> 00:47:25.000
Yeah, so if you want to run a script,


00:47:25.000 --> 00:47:27.000
then you'd run Pidgin and then the name of the script.


00:47:27.000 --> 00:47:30.000
If you want to run a module like pytest, for example,


00:47:30.000 --> 00:47:34.000
then you would do pidgin -m pytest,


00:47:34.000 --> 00:47:38.000
and it would run pytest with the JIT enabled.


00:47:38.000 --> 00:47:42.000
Yeah, fantastic. Or Flask or something like that, right?


00:47:42.000 --> 00:47:44.000
Yeah, exactly.


00:47:44.000 --> 00:47:46.000
So I guess -m would work with external libraries, right,


00:47:46.000 --> 00:47:49.000
as long as Python can see them.


00:47:49.000 --> 00:47:54.000
Yeah, and I've shipped a Whiskey extension as well so that you can--


00:47:54.000 --> 00:47:56.000
Yes.


00:47:56.000 --> 00:47:58.000
--use it in Whiskey apps.


00:47:58.000 --> 00:48:01.000
I think that that's an interesting use case, actually.


00:48:01.000 --> 00:48:09.000
So when I run my regular Python code, it just loads up and runs.


00:48:09.000 --> 00:48:14.000
But when I run Flask or FastAPI or Django or Pyramid or whatever,


00:48:14.000 --> 00:48:17.000
there's all sorts of layers of indirection


00:48:17.000 --> 00:48:21.000
or layers of not directly running it, right?


00:48:21.000 --> 00:48:25.000
In production, you would say, "Hey, I want microWhiskey or gUnicorn to run this."


00:48:25.000 --> 00:48:28.000
Like for FastAPI, it would be, "I want gUnicorn to run this,


00:48:28.000 --> 00:48:31.000
but with uVehicorn workers and run five of them."


00:48:31.000 --> 00:48:36.000
And like, boom, boom, boom, now you've described this chain of events, right?


00:48:36.000 --> 00:48:38.000
Yeah.


00:48:38.000 --> 00:48:42.000
But it sounds like there's, what, middleware to make this work still?


00:48:42.000 --> 00:48:47.000
Yeah, it's a Whiskey middleware that is for Pidgin,


00:48:47.000 --> 00:48:50.000
which will do the enabling and disabling.


00:48:50.000 --> 00:48:51.000
Fantastic.


00:48:51.000 --> 00:48:52.000
Required.


00:48:52.000 --> 00:48:56.000
So that sounds like it works for any Whiskey app, Flask, Django, Pyramid, etc.


00:48:56.000 --> 00:48:59.000
What about ASGI apps?


00:48:59.000 --> 00:49:02.000
Due to the lack of async and await support, then no.


00:49:02.000 --> 00:49:04.000
It doesn't really make much sense, right?


00:49:04.000 --> 00:49:09.000
Because the big thing that it does is not the thing that's supported, right?


00:49:09.000 --> 00:49:11.000
Yeah, I mean, if it's an async function,


00:49:11.000 --> 00:49:15.000
then it will just give it back to CPython.


00:49:15.000 --> 00:49:19.000
I'm sure there's a lot of synchronous things happening


00:49:19.000 --> 00:49:22.000
in those various places, right?


00:49:22.000 --> 00:49:25.000
Maybe the view method itself is async, but it might call a whole bunch of,


00:49:25.000 --> 00:49:28.000
you know, "Get me the headers and the cookies," synchronously.


00:49:28.000 --> 00:49:29.000
Who knows?


00:49:29.000 --> 00:49:31.000
Yeah, exactly.


00:49:31.000 --> 00:49:34.000
It also depends on the nature of the program


00:49:34.000 --> 00:49:38.000
as to whether Pidgin's actually going to make a difference to the performance.


00:49:38.000 --> 00:49:39.000
Yeah.


00:49:39.000 --> 00:49:45.000
So that's kind of where I'm up to at the moment is different benchmarks


00:49:45.000 --> 00:49:50.000
and running Pidgin against some standard benchmarks.


00:49:50.000 --> 00:49:54.000
I showed the nbody execution time at my PyCon talk,


00:49:54.000 --> 00:49:57.000
and that was 33% faster.


00:49:57.000 --> 00:50:00.000
It's now 65% faster, so I've doubled that--


00:50:00.000 --> 00:50:02.000
Oh, nice.


00:50:02.000 --> 00:50:04.000
--gain.


00:50:04.000 --> 00:50:09.000
So, however, most people aren't calculating the position of planets.


00:50:09.000 --> 00:50:11.000
[laughs]


00:50:11.000 --> 00:50:13.000
For the few who are, they're going to be super thrilled.


00:50:13.000 --> 00:50:16.000
Yeah, for the few people who are, and are doing it in Python,


00:50:16.000 --> 00:50:20.000
the system doing it in Python, yeah, then they'll be delighted.


00:50:20.000 --> 00:50:29.000
So code which is doing a lot of math and is in pure Python would be faster.


00:50:29.000 --> 00:50:36.000
Up to 20% fast-- 20 times-- not 20%, 20 times faster.


00:50:36.000 --> 00:50:42.000
I've got some microbenchmarks that do simple calculus and stuff like that,


00:50:42.000 --> 00:50:46.000
and they're 20 times faster with floating-point numbers.


00:50:46.000 --> 00:50:52.000
And for, I'll say, small integers, because an integer in Python,


00:50:52.000 --> 00:50:55.000
an int in Python is a--


00:50:55.000 --> 00:50:57.000
It's an unbounded thing.


00:50:57.000 --> 00:50:59.000
It's bounded by your memory, right?


00:50:59.000 --> 00:51:02.000
Yeah, it's actually a list of digits.


00:51:02.000 --> 00:51:07.000
So it can have an almost infinitely large number inside it,


00:51:07.000 --> 00:51:13.000
whereas CPUs work with 32-bit or 64-bit numbers.


00:51:13.000 --> 00:51:16.000
And the other languages, instead of keep growing, they just go,


00:51:16.000 --> 00:51:21.000
"We broke, so instead of going one more, it goes to negative 2 billion."


00:51:21.000 --> 00:51:23.000
Yeah. [laughs]


00:51:23.000 --> 00:51:25.000
Yeah, you get funny overflows and stuff.


00:51:25.000 --> 00:51:32.000
So one of the challenges I've had with Pigeon is trying to optimize integers,


00:51:32.000 --> 00:51:37.000
but trying to understand where it potentially could be a very big number


00:51:37.000 --> 00:51:41.000
and where the number is like 5.


00:51:41.000 --> 00:51:42.000
What's 5 times 5?


00:51:42.000 --> 00:51:48.000
You don't need to allocate half a meg of memory to do 5 times 5.


00:51:48.000 --> 00:51:51.000
Yeah.


00:51:51.000 --> 00:51:53.000
Yeah, so that's one of the challenges.


00:51:53.000 --> 00:51:56.000
If you're working with integers and you're working with floating-point numbers


00:51:56.000 --> 00:52:01.000
and you're doing a lot of math, then Pigeon will make a dramatic difference.


00:52:01.000 --> 00:52:06.000
There's also a feature called the graph,


00:52:06.000 --> 00:52:15.000
which will create .graphviz files for the functions that it's compiled.


00:52:15.000 --> 00:52:17.000
And you can see this on the website.


00:52:17.000 --> 00:52:20.000
So if you go to live.trypigeon.com--


00:52:20.000 --> 00:52:24.000
Yeah, you've got this interactive live website, right?


00:52:24.000 --> 00:52:30.000
Yeah, so I've made a live demo site where you can type Python code in


00:52:30.000 --> 00:52:36.000
and click compile, and then it will show you--


00:52:36.000 --> 00:52:38.000
Oh, don't change it, Michael. You'll break it.


00:52:38.000 --> 00:52:39.000
[laughs]


00:52:39.000 --> 00:52:40.000
Fine.


00:52:40.000 --> 00:52:43.000
And then do compile.


00:52:43.000 --> 00:52:46.000
Fine, I've got faith in you.


00:52:46.000 --> 00:52:47.000
If not, I can delete it.


00:52:47.000 --> 00:52:48.000
Look it!


00:52:48.000 --> 00:52:49.000
It catches fire. Okay.


00:52:49.000 --> 00:52:54.000
So that's the assembly that it has compiled that Python code into.


00:52:54.000 --> 00:52:55.000
Okay.


00:52:55.000 --> 00:52:59.000
And a fun thing I actually added was there's a comment in an assembly


00:52:59.000 --> 00:53:06.000
which says which bytecode this is for, which is fun.


00:53:06.000 --> 00:53:13.000
If you scroll down on the page, you see this graph.


00:53:13.000 --> 00:53:14.000
I've got to do much scrolling.


00:53:14.000 --> 00:53:17.000
That's the IR, and then keep going down.


00:53:17.000 --> 00:53:18.000
Okay.


00:53:18.000 --> 00:53:20.000
I think--there we go.


00:53:20.000 --> 00:53:21.000
There we go.


00:53:21.000 --> 00:53:23.000
I don't have a big enough screen there.


00:53:23.000 --> 00:53:24.000
Here we go.


00:53:24.000 --> 00:53:25.000
[laughs]


00:53:25.000 --> 00:53:31.000
Okay, so this instruction graph gets generated if you enable graphing,


00:53:31.000 --> 00:53:32.000
which is on the documentation.


00:53:32.000 --> 00:53:36.000
But when you enable graphing, it will show you all the Python bytecodes


00:53:36.000 --> 00:53:40.000
and then what values are being sent between those bytecodes.


00:53:40.000 --> 00:53:44.000
So this is basically the output of the profiler.


00:53:44.000 --> 00:53:48.000
It can see here that you've got A and B.


00:53:48.000 --> 00:53:50.000
B was a float.


00:53:50.000 --> 00:53:51.000
A is an integer.


00:53:51.000 --> 00:53:54.000
And then it's doing a multiplication operation,


00:53:54.000 --> 00:53:56.000
and it knows that if you multiply a float by an integer,


00:53:56.000 --> 00:53:58.000
then the output is a float.


00:53:58.000 --> 00:54:01.000
So it carries that value through the graph.


00:54:01.000 --> 00:54:05.000
PyPy actually does things quite similar to this.


00:54:05.000 --> 00:54:09.000
And then once the profiler has run, it will look at the graph


00:54:09.000 --> 00:54:15.000
and then make some decisions about which values don't need to be Python objects.


00:54:15.000 --> 00:54:19.000
So, for example, A times B--


00:54:19.000 --> 00:54:22.000
These intermediate binaries here and stuff, right?


00:54:22.000 --> 00:54:25.000
This in-place add, all those, yeah?


00:54:25.000 --> 00:54:26.000
So, yeah, exactly.


00:54:26.000 --> 00:54:30.000
So all of those values do not need to be Python objects.


00:54:30.000 --> 00:54:33.000
So what it will do on the next pass is it will compile all of that--


00:54:33.000 --> 00:54:36.000
recompile that, and then it will what's called unbox them.


00:54:36.000 --> 00:54:42.000
So it basically just carries them in CPU registers as integers and floats.


00:54:42.000 --> 00:54:45.000
And then instead of running the C function to add two numbers together,


00:54:45.000 --> 00:54:52.000
it will just emit the assembly instruction to add two numbers on the register.


00:54:52.000 --> 00:54:53.000
Yeah, that's fantastic.


00:54:53.000 --> 00:54:55.000
That's what you're talking about where you don't have to drop back


00:54:55.000 --> 00:55:02.000
into allocating Python numbers if you know for sure that no one's going to look at it.


00:55:02.000 --> 00:55:04.000
It's just an intermediate value.


00:55:04.000 --> 00:55:06.000
And this is where it gets tricky with integers, right?


00:55:06.000 --> 00:55:12.000
Because A and B might be small, but A to the power of B might be larger.


00:55:12.000 --> 00:55:14.000
Exactly.


00:55:14.000 --> 00:55:20.000
And then it goes one step beyond as well if you have code that uses fast values.


00:55:20.000 --> 00:55:23.000
It's tricky because when you do eval in the website,


00:55:23.000 --> 00:55:27.000
it will never use fast locals.


00:55:27.000 --> 00:55:31.000
But if you do have a function that has fast locals,


00:55:31.000 --> 00:55:39.000
if it detects that that local is only ever used in places where it can be unboxed,


00:55:39.000 --> 00:55:44.000
then it won't actually store the variable as a Python object either.


00:55:44.000 --> 00:55:47.000
It will store it as a native stack value.


00:55:47.000 --> 00:55:49.000
So that's something it even does.


00:55:49.000 --> 00:55:54.000
Like if you have a variable called A and you assign it to the number two,


00:55:54.000 --> 00:56:02.000
then it will actually just reserve an area in memory just to store that stack value.


00:56:02.000 --> 00:56:04.000
And it will be an offset.


00:56:04.000 --> 00:56:06.000
It's way more efficient.


00:56:06.000 --> 00:56:09.000
Enormous, like thousands of times more efficient.


00:56:09.000 --> 00:56:13.000
And when you refer to that variable in your function,


00:56:13.000 --> 00:56:18.000
it will basically just access that point in memory to get the actual value.


00:56:18.000 --> 00:56:20.000
Yeah, yeah, awesome.


00:56:20.000 --> 00:56:21.000
This is really neat.


00:56:21.000 --> 00:56:26.000
One of the things that stands out to me here is I wrote name equals Anthony plus Shaw as two strings.


00:56:26.000 --> 00:56:29.000
And you're like, "Don't do it."


00:56:29.000 --> 00:56:35.000
And yet what I see in the graph here is that it loads the string Anthony Shaw.


00:56:35.000 --> 00:56:39.000
So did Python look at that and then decide that that's actually--


00:56:39.000 --> 00:56:42.000
those are two constants, so we'll just make it one constant?


00:56:42.000 --> 00:56:44.000
Or was that .NET?


00:56:44.000 --> 00:56:45.000
Or what happened there?


00:56:45.000 --> 00:56:47.000
Yeah, that's constant folding.


00:56:47.000 --> 00:56:49.000
It's a feature of Python.


00:56:49.000 --> 00:56:51.000
That's what I thought.


00:56:51.000 --> 00:56:57.000
If you do two strings and a plus, it will actually compile those into one string.


00:56:57.000 --> 00:56:59.000
You'd never see it.


00:56:59.000 --> 00:57:01.000
Interesting.


00:57:01.000 --> 00:57:03.000
Because they're statics, right?


00:57:03.000 --> 00:57:05.000
Like it knows both of them.


00:57:05.000 --> 00:57:08.000
Okay, very interesting.


00:57:08.000 --> 00:57:12.000
So it sounds like for numerical stuff, this is quite a bit faster.


00:57:12.000 --> 00:57:14.000
Did you do any tests on the web frameworks?


00:57:14.000 --> 00:57:19.000
I mean, it's kind of appealing to say, "What if I could get Flask to kind of run natively?"


00:57:19.000 --> 00:57:21.000
Yeah, I have.


00:57:21.000 --> 00:57:27.000
Because when you look at what-- when you think about, "I'm writing this code to make this website go,"


00:57:27.000 --> 00:57:32.000
most of what you're doing is you're doing like a little tiny bit of code on top of a big framework


00:57:32.000 --> 00:57:34.000
that's doing most of the heavy lifting, right?


00:57:34.000 --> 00:57:40.000
So if you could make Flask do that magic faster, or Django or whatever, that'd be cool?


00:57:40.000 --> 00:57:47.000
Yeah, so the areas where Python is faster is numerical work.


00:57:47.000 --> 00:57:52.000
Similar to PyPy, PyPy is a lot faster with numerical work.


00:57:52.000 --> 00:57:57.000
It can make clear and simple assumptions and optimize based on the CPU.


00:57:57.000 --> 00:57:59.000
So that's brilliant.


00:57:59.000 --> 00:58:06.000
Areas where it's not faster or sometimes even slower is code,


00:58:06.000 --> 00:58:12.000
which just uses a lot of classes and very small functions.


00:58:12.000 --> 00:58:19.000
Partly just because of the way the path is designed, it will JIT compile functions.


00:58:19.000 --> 00:58:25.000
And if your functions are just working with custom classes and you're passing things around,


00:58:25.000 --> 00:58:30.000
then trying to decide what type things are and then how it can optimize types,


00:58:30.000 --> 00:58:35.000
if everything is a Python-- custom Python object, custom Python class,


00:58:35.000 --> 00:58:39.000
there's very little it can actually do to optimize.


00:58:39.000 --> 00:58:42.000
Yeah, when you were talking about the specializations earlier,


00:58:42.000 --> 00:58:46.000
it's one thing to say, well, I'm passing a customer and an order object,


00:58:46.000 --> 00:58:50.000
but then they have fields themselves, each of which have potential types, right?


00:58:50.000 --> 00:58:56.000
Like it's this object graph, this closure of all the object graphs,


00:58:56.000 --> 00:58:58.000
and you've got to look at all those types you might touch, right?


00:58:58.000 --> 00:59:04.000
Yeah, and then you've also got to check that that field exists, it's been set, it's not none.


00:59:04.000 --> 00:59:14.000
By the time you've done all of that, you've basically just written what CPython would have done anyway.


00:59:14.000 --> 00:59:19.000
But the difference is that if you JIT compile it, you've got to omit all those instructions.


00:59:19.000 --> 00:59:27.000
And the JIT compiled function ends up being bigger because if it's compiled in C,


00:59:27.000 --> 00:59:31.000
it just has one function that does that, that's shared by all libraries.


00:59:31.000 --> 00:59:37.000
Whereas in the JIT, you have to make it so that it's their standalone functions.


00:59:37.000 --> 00:59:41.000
So that's one downside is that if you're working with stuff,


00:59:41.000 --> 00:59:46.000
which is similar to Django and Flask, I guess, like lots of classes,


00:59:46.000 --> 00:59:49.000
lots of variables, which are all custom types,


00:59:49.000 --> 00:59:55.000
probably not going to see a performance improvement or potentially it could even be slower.


00:59:55.000 --> 00:59:57.000
And then the other one is...


00:59:57.000 --> 01:00:02.000
Is it any transitive if I write code that runs in Flask, let's just pick one of them,


01:00:02.000 --> 01:00:10.000
and I run Flask with Pidgin, will that then make all my code that Flask is executing also run in Pidgin?


01:00:10.000 --> 01:00:11.000
Yeah.


01:00:11.000 --> 01:00:16.000
Okay, so maybe if I was doing like highly computational stuff in my Flask app,


01:00:16.000 --> 01:00:19.000
having to do that might be worthwhile.


01:00:19.000 --> 01:00:25.000
Yeah, definitely. And in that case, you can just enable Pidgin before those functions,


01:00:25.000 --> 01:00:28.000
or you can set the threshold to be higher.


01:00:28.000 --> 01:00:31.000
That's sort of what makes more sense, I think.


01:00:31.000 --> 01:00:32.000
Yeah. Okay.


01:00:32.000 --> 01:00:34.000
The other area is strings.


01:00:34.000 --> 01:00:40.000
So if you're doing a lot of work with strings, I haven't done any work on optimizing strings.


01:00:40.000 --> 01:00:45.000
And I'm not particularly sure what you would optimize either,


01:00:45.000 --> 01:00:48.000
because they're so complicated.


01:00:48.000 --> 01:00:49.000
They are.


01:00:49.000 --> 01:00:56.000
Because you're dealing all with Unicode, different encodings, different byte lengths.


01:00:56.000 --> 01:01:03.000
Yeah, I don't even know how you would improve upon CPython's string implementation, to be honest.


01:01:03.000 --> 01:01:09.000
Yeah, there's a lot of nuances to strings in all the languages, but especially in Python,


01:01:09.000 --> 01:01:10.000
because you don't have to think about it, right?


01:01:10.000 --> 01:01:14.000
The fact that you don't know how complicated Unicode is,


01:01:14.000 --> 01:01:21.000
and word alignment and null characters and so on and so on.


01:01:21.000 --> 01:01:28.000
Yeah, if you want a glimpse of how complicated it is, look at the Unicode object source file in CPython.


01:01:28.000 --> 01:01:29.000
Is it big?


01:01:29.000 --> 01:01:31.000
It's an absolute monster.


01:01:31.000 --> 01:01:32.000
It is.


01:01:32.000 --> 01:01:35.000
It's probably more complicated in C, actually.


01:01:35.000 --> 01:01:37.000
Oh, my goodness.


01:01:37.000 --> 01:01:40.000
All of that for emojis.


01:01:40.000 --> 01:01:43.000
Okay, I understand there's other languages.


01:01:43.000 --> 01:01:45.000
Oh, interesting.


01:01:45.000 --> 01:01:50.000
So one thing I wanted to ask you about here, I was hunting around on the screen for it,


01:01:50.000 --> 01:01:55.000
is it's cool that you can compile these things down and run them as native machine instructions


01:01:55.000 --> 01:01:59.000
instead of piping them through C of L.C. as single line operations.


01:01:59.000 --> 01:02:01.000
That's great.


01:02:01.000 --> 01:02:07.000
But when I think of the stuff that compilers can do and JIT compilers,


01:02:07.000 --> 01:02:09.000
it's a lot about the optimizations.


01:02:09.000 --> 01:02:13.000
It's like I saw this function and this function, actually we're going to inline that one.


01:02:13.000 --> 01:02:18.000
And this one we're going to rewrite this as some other thing that's going to be more efficient


01:02:18.000 --> 01:02:20.000
because we're seeing that.


01:02:20.000 --> 01:02:22.000
And so you do have some optimizations, right?


01:02:22.000 --> 01:02:24.000
Like that's part of the magic?


01:02:24.000 --> 01:02:29.000
Yeah, so I've kind of documented them as best I can on the Pigeon documentation.


01:02:29.000 --> 01:02:34.000
There's a section called built-in optimizations, and I've given them all numbers.


01:02:34.000 --> 01:02:39.000
And if it uses that optimization, it will flag the function to say,


01:02:39.000 --> 01:02:43.000
oh, I'd use this optimization on this function.


01:02:43.000 --> 01:02:48.000
And then in the documentation I'll explain what's the background, what was the idea,


01:02:48.000 --> 01:02:51.000
what difference does it make.


01:02:51.000 --> 01:02:57.000
You want to give some examples from some of these, like the is one, for example?


01:02:57.000 --> 01:03:09.000
Yeah, so if you're using the is operator in Python, so if something is false,


01:03:09.000 --> 01:03:11.000
actually you should probably use it.


01:03:11.000 --> 01:03:13.000
Is none or something like that, yeah.


01:03:13.000 --> 01:03:15.000
Yeah, is none.


01:03:15.000 --> 01:03:19.000
Then it won't run the pyis function.


01:03:19.000 --> 01:03:21.000
It won't run the CAPI to do an is comparison.


01:03:21.000 --> 01:03:25.000
It will just look at the address of both objects and see if they're the same.


01:03:25.000 --> 01:03:30.000
Because is is actually asking, are these objects the same, not are they equivalent, right?


01:03:30.000 --> 01:03:35.000
So the same in CPython is the pointer addresses are equal.


01:03:35.000 --> 01:03:37.000
Yeah, exactly.


01:03:37.000 --> 01:03:41.000
So it will just compile that down to a simple pointer comparison.


01:03:41.000 --> 01:03:46.000
That's actually one of the first ones I wrote, and it was good to learn.


01:03:46.000 --> 01:03:50.000
Also, when it's doing comparisons for small numbers,


01:03:50.000 --> 01:03:59.000
so Python inter, it kind of immortalizes numbers between, I can't remember.


01:03:59.000 --> 01:04:01.000
Negative 5 and 256.


01:04:01.000 --> 01:04:03.000
Yeah, that's it.


01:04:03.000 --> 01:04:05.000
Because they use so much that --


01:04:05.000 --> 01:04:07.000
Maybe 255, basically.


01:04:07.000 --> 01:04:10.000
Yeah, it's around that many.


01:04:10.000 --> 01:04:17.000
It immortalizes them and keeps them as constant objects so that they're just reused.


01:04:17.000 --> 01:04:20.000
So if you create a new integer with the number 1,


01:04:20.000 --> 01:04:22.000
it will just reuse the same number 1 that it used before.


01:04:22.000 --> 01:04:24.000
Because they're not created on the stack.


01:04:24.000 --> 01:04:26.000
They're complicated things on the heap.


01:04:26.000 --> 01:04:28.000
So, yeah.


01:04:28.000 --> 01:04:30.000
Exactly.


01:04:30.000 --> 01:04:33.000
So if you do if something equals equals 25,


01:04:33.000 --> 01:04:37.000
Pidgin will go, oh, well, I know 25 is an intern number.


01:04:37.000 --> 01:04:41.000
So I'm actually just going to do a pointer comparison instead of a value comparison.


01:04:41.000 --> 01:04:43.000
If the left-hand side is a number.


01:04:43.000 --> 01:04:46.000
So there's little things like this.


01:04:46.000 --> 01:04:48.000
Which makes small differences.


01:04:48.000 --> 01:04:50.000
But when you add it up --


01:04:50.000 --> 01:04:52.000
Yeah.


01:04:52.000 --> 01:04:57.000
So I felt like -- I don't know where you are now from where you were when you spoke at PyCon.


01:04:57.000 --> 01:05:01.000
But I feel like this is an area that people could contribute to.


01:05:01.000 --> 01:05:06.000
This is an area for growth that doesn't require a lot of changes.


01:05:06.000 --> 01:05:08.000
It could be super focused.


01:05:08.000 --> 01:05:12.000
But if you see this situation, here's one more way to make it faster.


01:05:12.000 --> 01:05:14.000
Absolutely.


01:05:14.000 --> 01:05:19.000
So, yeah, this is one area where I was hoping that the research that I was doing


01:05:19.000 --> 01:05:23.000
whilst writing Pidgin could contribute to other projects.


01:05:23.000 --> 01:05:30.000
And I'm going to -- I've been talking to Carl Friedrich-Rosch as well, who works on PyPy.


01:05:30.000 --> 01:05:36.000
And we're going to do some pair programming at some point.


01:05:36.000 --> 01:05:40.000
To see kind of like how different projects work and stuff like that.


01:05:40.000 --> 01:05:49.000
But kind of hopefully these optimizations can be learned from and then used when CPython gets to implementing its JIT.


01:05:49.000 --> 01:05:51.000
Yeah.


01:05:51.000 --> 01:05:56.000
Surely the .NET compiler has all sorts of optimizations in it.


01:05:56.000 --> 01:06:01.000
Are you already taking advantage of those to some degree?


01:06:01.000 --> 01:06:03.000
Yeah, some of, yeah.


01:06:03.000 --> 01:06:05.000
By nature of letting it run, basically.


01:06:05.000 --> 01:06:07.000
Yeah, some of those optimizers.


01:06:07.000 --> 01:06:09.000
It does a lot of them already.


01:06:09.000 --> 01:06:15.000
And I've been working with the compiler team on the .NET project as well.


01:06:15.000 --> 01:06:21.000
Pidgin is one of the only projects to use the compiler directly.


01:06:21.000 --> 01:06:30.000
Even though it can be used in that way, it's -- it wasn't -- I think it was designed to be run directly.


01:06:30.000 --> 01:06:35.000
But it's not like advertised as an off-the-shelf JIT.


01:06:35.000 --> 01:06:38.000
So, yeah, there aren't many projects that are using it in that way.


01:06:38.000 --> 01:06:44.000
And I do work with the compiler team on specific test cases and stuff as well.


01:06:44.000 --> 01:06:47.000
You have that advantage of being on the inside at Microsoft.


01:06:47.000 --> 01:06:54.000
Even if you're half a world away, you still can get direct access remotely.


01:06:54.000 --> 01:06:56.000
Which is like being down the street these days.


01:06:56.000 --> 01:06:57.000
Yeah, I've said everything.


01:06:57.000 --> 01:06:58.000
It's all been via GitHub, though.


01:06:58.000 --> 01:07:04.000
So I think, as far as they're concerned, I'm just another name on GitHub.


01:07:04.000 --> 01:07:06.000
But I don't -- it doesn't --


01:07:06.000 --> 01:07:08.000
You might not even know, right?


01:07:08.000 --> 01:07:10.000
I probably don't even know, yeah.


01:07:10.000 --> 01:07:14.000
That I work there anyway.


01:07:14.000 --> 01:07:18.000
Let's see. What else?


01:07:18.000 --> 01:07:23.000
I think we pretty much have covered it, given the time that we got.


01:07:23.000 --> 01:07:34.000
I think one -- another area that's interesting is, how does it compare to the other things that have been done before it?


01:07:34.000 --> 01:07:36.000
Going along a parallel.


01:07:36.000 --> 01:07:39.000
You do have a whole section on the readme on the GitHub page.


01:07:39.000 --> 01:07:47.000
How does this compare to XYZ, PyPy, Piston, Numba, IronPython, and so on?


01:07:47.000 --> 01:07:51.000
Do you want to maybe just have a quick statement about that?


01:07:51.000 --> 01:07:56.000
Yeah, I think it's really hard to compare them.


01:07:56.000 --> 01:08:02.000
So probably the most obvious ones to compare it with would be Cython, Numba, and PyPy.


01:08:02.000 --> 01:08:07.000
So PyPy is a Python interpreter that has a JIT.


01:08:07.000 --> 01:08:13.000
So it interprets, compiles, and runs Python code written in Python.


01:08:13.000 --> 01:08:15.000
PyPy has been around --


01:08:15.000 --> 01:08:19.000
It's like a form of Python that was rewritten to behave differently, rather than PEP 523, right?


01:08:19.000 --> 01:08:21.000
Yeah, exactly.


01:08:21.000 --> 01:08:24.000
So it's not -- CPython is written in C. PyPy is written in Python.


01:08:24.000 --> 01:08:31.000
And probably significantly faster in many cases.


01:08:31.000 --> 01:08:33.000
It's a very mature project.


01:08:33.000 --> 01:08:42.000
But obviously there's limitations around C APIs, and some things don't work in PyPy.


01:08:42.000 --> 01:08:49.000
Numba is a JIT-specific for NumPy.


01:08:49.000 --> 01:08:56.000
So if you're using a lot of -- if you're using NumPy, then if you use Numba,


01:08:56.000 --> 01:09:02.000
Numba can JIT-compile NumPy data arrays and stuff like that.


01:09:02.000 --> 01:09:06.000
That's actually a very specific use case.


01:09:06.000 --> 01:09:07.000
Right. That's great.


01:09:07.000 --> 01:09:10.000
But if you're not doing NumPy, then not so great.


01:09:10.000 --> 01:09:15.000
Yeah, in any other use case, it would make very little, if any, difference at all.


01:09:15.000 --> 01:09:21.000
And then Cython is not a JIT.


01:09:21.000 --> 01:09:23.000
It's an AOT compiler.


01:09:23.000 --> 01:09:28.000
And it's a way of annotating Python code with concrete types.


01:09:28.000 --> 01:09:32.000
And then it compiles them into C -- concrete compiles them into C extensions.


01:09:32.000 --> 01:09:36.000
It's a little bit like what you're talking about, trying to understand what are these types,


01:09:36.000 --> 01:09:38.000
and then can we create a specialization.


01:09:38.000 --> 01:09:41.000
But it's the developer who just says, "No, these are integers.


01:09:41.000 --> 01:09:45.000
This is a list. For sure. Go with it."


01:09:45.000 --> 01:09:48.000
Yeah, down to the point where you actually specify the length of the integer as well.


01:09:48.000 --> 01:09:52.000
So in Cython, you would say, "This is a 64-bit integer."


01:09:52.000 --> 01:10:02.000
So that it knows that it can be converted into a 64-bit integer in C.


01:10:02.000 --> 01:10:05.000
Pigeon is probably closest to Cython.


01:10:05.000 --> 01:10:09.000
But obviously with Cython, you have to compile it to a C extension ahead of time.


01:10:09.000 --> 01:10:13.000
Whereas with Pigeon, you just import it into Python and just turn it on,


01:10:13.000 --> 01:10:16.000
and it just runs and compiles live.


01:10:16.000 --> 01:10:21.000
Yeah, you don't have to have different compiled versions of your app or your library.


01:10:21.000 --> 01:10:24.000
Not necessarily because of this, anyway, for the different platforms, right?


01:10:24.000 --> 01:10:29.000
Yeah, and you don't have to annotate the code in this special syntax either.


01:10:29.000 --> 01:10:34.000
Yeah. Well, let's close this out with a question on that.


01:10:34.000 --> 01:10:41.000
So in Python, we've been able to say, optionally, that this thing is an integer,


01:10:41.000 --> 01:10:46.000
you know, x colon int, or it's an optional integer, or it's a customer,


01:10:46.000 --> 01:10:48.000
or whatever the heck it is.


01:10:48.000 --> 01:10:53.000
We've had these type annotations, and traditionally they've meant nothing,


01:10:53.000 --> 01:10:55.000
except for if you run tools against them.


01:10:55.000 --> 01:11:00.000
On the other hand, we've had things come along like Pydantic, like FastAPI,


01:11:00.000 --> 01:11:02.000
that look at that and go, "You know what? I'm going to do something with that,


01:11:02.000 --> 01:11:05.000
because I got a string, because this is the web, and that's all I usually get.


01:11:05.000 --> 01:11:08.000
I'm going to make that into an int, because you said it's an int."


01:11:08.000 --> 01:11:17.000
Is there a scenario where type annotations play into this to enhance it somehow?


01:11:17.000 --> 01:11:22.000
I'm against that idea, potentially.


01:11:22.000 --> 01:11:27.000
I mean, that's how Cython works.


01:11:27.000 --> 01:11:31.000
I think, and with type annotations as well, having a type checker is great


01:11:31.000 --> 01:11:38.000
until the types are wrong, and it's not a fault of your own.


01:11:38.000 --> 01:11:46.000
And having worked on strongly typed languages, like C#, C# is brilliant,


01:11:46.000 --> 01:11:50.000
except when you need to do things like reflection.


01:11:50.000 --> 01:11:58.000
So let's say you're working with JSON, like JSON data or YAML, for example.


01:11:58.000 --> 01:12:05.000
And working with JSON and YAML in C# is incredibly hard, because you're like,


01:12:05.000 --> 01:12:12.000
"Oh, I've had to do parsing YAML files in Java."


01:12:12.000 --> 01:12:17.000
It's incredibly difficult, because you're like, "Oh, well, this could be a list


01:12:17.000 --> 01:12:23.000
of strings, or it could be a dictionary where the key is a string,


01:12:23.000 --> 01:12:26.000
but sometimes it's a number."


01:12:26.000 --> 01:12:29.000
YAML is like that sometimes, and JSON is like that.


01:12:29.000 --> 01:12:30.000
It's completely free.


01:12:30.000 --> 01:12:34.000
So when you're working with dynamic content, using strongly typed languages


01:12:34.000 --> 01:12:37.000
is extremely difficult.


01:12:37.000 --> 01:12:40.000
It just gets in the way and just makes your life harder,


01:12:40.000 --> 01:12:42.000
and Compilers just complains and just won't let you parse,


01:12:42.000 --> 01:12:48.000
because it's saying, "Oh, well, that's not compliant with my view on the world."


01:12:48.000 --> 01:12:53.000
With Python, I think it's cool to say, "Okay, if I just tag this as an integer,


01:12:53.000 --> 01:12:55.000
then it should be able to optimize it for integers."


01:12:55.000 --> 01:12:59.000
And I think that's what Mark was suggesting.


01:12:59.000 --> 01:13:01.000
If it stops there, that's fine.


01:13:01.000 --> 01:13:03.000
I think if it goes beyond that, then that's where things get


01:13:03.000 --> 01:13:08.000
very, very complicated, and it just becomes a thing that's in the way,


01:13:08.000 --> 01:13:11.000
being noisy, and it slows you down.


01:13:11.000 --> 01:13:13.000
That's where I have a strong disagreement with it,


01:13:13.000 --> 01:13:19.000
is that we use Python because it's fast to develop in,


01:13:19.000 --> 01:13:23.000
and it's fast to develop in because if you know what you're trying


01:13:23.000 --> 01:13:29.000
to get it to do, then the compiler doesn't really give you any grief.


01:13:29.000 --> 01:13:32.000
It's as syntactic as, "Okay, I'll just try and run it."


01:13:32.000 --> 01:13:37.000
Yeah, and I think the thing that's most similar to this is TypeScript.


01:13:37.000 --> 01:13:43.000
My experiences with TypeScript have been often met with frustration.


01:13:43.000 --> 01:13:45.000
I think it's really cool that you can write--


01:13:45.000 --> 01:13:48.000
the language specification is really neat, but I want to use this library


01:13:48.000 --> 01:13:50.000
and that thing and pull them together.


01:13:50.000 --> 01:13:54.000
If that thing doesn't have the type specified just right,


01:13:54.000 --> 01:13:56.000
I can't get JavaScript to pop out the other side


01:13:56.000 --> 01:13:58.000
because the transpiler gives you a compiler error,


01:13:58.000 --> 01:14:00.000
like, "This doesn't work right."


01:14:00.000 --> 01:14:02.000
Well, no, it's going to work right.


01:14:02.000 --> 01:14:04.000
Just let this little part go through.


01:14:04.000 --> 01:14:08.000
I don't want to re-- I know there's ways to say this is just any and stuff,


01:14:08.000 --> 01:14:13.000
but still, I feel like my experience was bumping up against that stuff,


01:14:13.000 --> 01:14:18.000
even though it's kind of the same as Python type annotations in a lot of ways.


01:14:18.000 --> 01:14:21.000
Yeah, and under the hood, it's still dynamic.


01:14:21.000 --> 01:14:23.000
Yeah, exactly.


01:14:23.000 --> 01:14:25.000
At runtime, it would still be the same thing,


01:14:25.000 --> 01:14:28.000
but you won't get to the runtime because you can't get the stuff compiled.


01:14:28.000 --> 01:14:33.000
Yeah, or it does really weird things at runtime that at compile time


01:14:33.000 --> 01:14:35.000
you might have made assumptions that wouldn't happen.


01:14:35.000 --> 01:14:39.000
All right, let me throw one quick thing out there before you pass final judgment


01:14:39.000 --> 01:14:43.000
on this type thing, because you're right.


01:14:43.000 --> 01:14:48.000
I could write a thing that says, "My function takes an int and a string,"


01:14:48.000 --> 01:14:50.000
and I could run mypy against my code,


01:14:50.000 --> 01:14:54.000
and sure enough, it only takes ints and strings in these situations.


01:14:54.000 --> 01:14:56.000
But if it's a library, all bets are off.


01:14:56.000 --> 01:15:00.000
There's nothing that says people who use your library are going to run mypy


01:15:00.000 --> 01:15:02.000
and listen to that or do anything.


01:15:02.000 --> 01:15:07.000
They could write Notepad if they had no self-respect.


01:15:07.000 --> 01:15:10.000
But you could write whatever you want, and then you could just beat it on,


01:15:10.000 --> 01:15:13.000
and then you'd have these problems.


01:15:13.000 --> 01:15:19.000
That said, over on the Pydantic world, there is a validator,


01:15:19.000 --> 01:15:24.000
a decorator called @validatearguments that will make sure at runtime


01:15:24.000 --> 01:15:28.000
they really are a string and an int.


01:15:28.000 --> 01:15:29.000
Yes.


01:15:29.000 --> 01:15:32.000
Make you feeling better?


01:15:32.000 --> 01:15:35.000
Probably not, because the transitive closure of objects is too complicated


01:15:35.000 --> 01:15:36.000
to check.


01:15:36.000 --> 01:15:41.000
I think the validate arguments is a convenience function.


01:15:41.000 --> 01:15:47.000
It's there because you often have to validate user-provided data


01:15:47.000 --> 01:15:51.000
that's coming in from an interface, like a web interface,


01:15:51.000 --> 01:15:56.000
or an API of some sort.


01:15:56.000 --> 01:15:59.000
So if people are submitting user-provided data,


01:15:59.000 --> 01:16:02.000
then you want to have to validate the types,


01:16:02.000 --> 01:16:05.000
and that is just a lot of boilerplate code, and it's annoying to write.


01:16:05.000 --> 01:16:08.000
So let's just, as a convenience function, let's write this.


01:16:08.000 --> 01:16:11.000
Right, probably because we're going to immediately try to convert it


01:16:11.000 --> 01:16:13.000
in the next thing, right?


01:16:13.000 --> 01:16:14.000
Yeah, exactly.


01:16:14.000 --> 01:16:22.000
So I think it's quite different to using it internally


01:16:22.000 --> 01:16:27.000
to make changes in terms of how the code is compiled.


01:16:27.000 --> 01:16:31.000
For numbers, like I said, numbers and strings and base types,


01:16:31.000 --> 01:16:33.000
I think is cool.


01:16:33.000 --> 01:16:37.000
But for objects, like which fields do you assume exist?


01:16:37.000 --> 01:16:38.000
Yes, exactly.


01:16:38.000 --> 01:16:40.000
And then do they all have to match the types,


01:16:40.000 --> 01:16:41.000
or just the two that you touch?


01:16:41.000 --> 01:16:42.000
Yeah.


01:16:42.000 --> 01:16:44.000
Like you've got an attribute there.


01:16:44.000 --> 01:16:46.000
Sometimes it has a getter and a setter.


01:16:46.000 --> 01:16:49.000
Sometimes it's just an attribute.


01:16:49.000 --> 01:16:53.000
Sometimes it's a descriptor that inside the descriptor


01:16:53.000 --> 01:16:54.000
is the thing you actually want.


01:16:54.000 --> 01:16:55.000
Is that the right type?


01:16:55.000 --> 01:16:56.000
Yeah, you're right.


01:16:56.000 --> 01:16:57.000
It's insane.


01:16:57.000 --> 01:17:02.000
Once you open custom types,


01:17:02.000 --> 01:17:05.000
then it just kind of mushrooms into this.


01:17:05.000 --> 01:17:06.000
Sure.


01:17:06.000 --> 01:17:09.000
And that's why you see things like Cython and stuff


01:17:09.000 --> 01:17:13.000
having little fragments of here's some limited code


01:17:13.000 --> 01:17:16.000
that we're going to use, often fundamental types.


01:17:16.000 --> 01:17:17.000
Yeah.


01:17:17.000 --> 01:17:19.000
Cool.


01:17:19.000 --> 01:17:21.000
All right, Anthony, this is really awesome.


01:17:21.000 --> 01:17:23.000
I can tell you've done a massive amount of work on it.


01:17:23.000 --> 01:17:25.000
There's more stuff I want to talk to you about,


01:17:25.000 --> 01:17:28.000
but I think we're out of time.


01:17:28.000 --> 01:17:31.000
Like calling into .NET, stuff like that.


01:17:31.000 --> 01:17:35.000
But we'll save that for some other time, huh?


01:17:35.000 --> 01:17:36.000
Yeah.


01:17:36.000 --> 01:17:40.000
Until you have a little more progress.


01:17:40.000 --> 01:17:43.000
Now, you know there's always the two questions


01:17:43.000 --> 01:17:44.000
at the end of the show.


01:17:44.000 --> 01:17:47.000
So if you're going to write some code,


01:17:47.000 --> 01:17:49.000
what editor are you using these days?


01:17:49.000 --> 01:17:50.000
VS Code.


01:17:50.000 --> 01:17:51.000
Right on.


01:17:51.000 --> 01:17:54.000
And notable PyPI library.


01:17:54.000 --> 01:17:56.000
I mean, it could be Pigeon.


01:17:56.000 --> 01:17:58.000
Anything else you come across?


01:17:58.000 --> 01:18:00.000
Like, wow, this is awesome.


01:18:00.000 --> 01:18:01.000
Yeah, I think I mentioned it before.


01:18:01.000 --> 01:18:04.000
Tortoise, I'm a big fan of at the moment.


01:18:04.000 --> 01:18:05.000
Yeah, Tortoise ORM.


01:18:05.000 --> 01:18:06.000
Yeah, it's a nice async.


01:18:06.000 --> 01:18:07.000
Tortoise.


01:18:07.000 --> 01:18:09.000
ORM, yeah, very nice.


01:18:09.000 --> 01:18:11.000
Yeah, and Beanie as well.


01:18:11.000 --> 01:18:13.000
I'm really enjoying playing with Beanie as an ODM.


01:18:13.000 --> 01:18:14.000
Yeah.


01:18:14.000 --> 01:18:17.000
Async ODM on top of Mongo.


01:18:17.000 --> 01:18:18.000
Yep.


01:18:18.000 --> 01:18:19.000
Beanie is very cool.


01:18:19.000 --> 01:18:21.000
I'm actually having Roman Wright on the show


01:18:21.000 --> 01:18:23.000
to talk about Beanie not too far out as well.


01:18:23.000 --> 01:18:25.000
And Beanie is cool because it's basically


01:18:25.000 --> 01:18:28.000
Pydantic plus async and await on top of MongoDB,


01:18:28.000 --> 01:18:29.000
which is cool.


01:18:29.000 --> 01:18:32.000
Hmm.


01:18:32.000 --> 01:18:33.000
And can I have three?


01:18:33.000 --> 01:18:36.000
You can have three.


01:18:36.000 --> 01:18:39.000
Yeah, I released like a small package called Hathi,


01:18:39.000 --> 01:18:46.000
which is a SQL attack tool for Postgres, MySQL,


01:18:46.000 --> 01:18:47.000
and SQL Server.


01:18:47.000 --> 01:18:53.000
I'm looking at your GitHub profile here.


01:18:53.000 --> 01:18:55.000
You've got one of these fancy profiles


01:18:55.000 --> 01:18:57.000
with the new readme that shows up and all of your stars.


01:18:57.000 --> 01:18:58.000
Look at this.


01:18:58.000 --> 01:19:00.000
Yeah, like I made a custom graphic for everything.


01:19:00.000 --> 01:19:01.000
Yeah, you did.


01:19:01.000 --> 01:19:03.000
That's fantastic.


01:19:03.000 --> 01:19:05.000
OK, what is this one called?


01:19:05.000 --> 01:19:06.000
Hathi.


01:19:06.000 --> 01:19:10.000
H-A-T-H-I.


01:19:10.000 --> 01:19:12.000
I have too many repositories in GitHub.


01:19:12.000 --> 01:19:13.000
I think I know.


01:19:13.000 --> 01:19:18.000
It is a dictionary attack tool for Postgres, MySQL,


01:19:18.000 --> 01:19:23.000
and MSSQL, Microsoft SQL Server, designed


01:19:23.000 --> 01:19:25.000
for internal testing, of course.


01:19:25.000 --> 01:19:27.000
Won't be bad.


01:19:27.000 --> 01:19:31.000
Yeah, so don't break the law.


01:19:31.000 --> 01:19:34.000
And yeah, I've been using it to test like internal--


01:19:34.000 --> 01:19:37.000
well, not internal stuff, but test environments


01:19:37.000 --> 01:19:40.000
and look at like bad passwords.


01:19:40.000 --> 01:19:44.000
See if like an admin has a login, like password, password1,


01:19:44.000 --> 01:19:47.000
or admin, or super user has a login, or whatever.


01:19:47.000 --> 01:19:53.000
Yeah, and it was also a test of like async and await networking


01:19:53.000 --> 01:19:55.000
and how fast I could make it.


01:19:55.000 --> 01:19:59.000
It can do up to 120 login attempts a second.


01:20:02.000 --> 01:20:06.000
So yeah, on my machine, but if you maybe--


01:20:06.000 --> 01:20:09.000
this is a four core Mac, but yeah,


01:20:09.000 --> 01:20:11.000
if you had a few more CPUs, you could probably


01:20:11.000 --> 01:20:12.000
get a bit more than that.


01:20:12.000 --> 01:20:14.000
But yeah, it'll go through a few thousand passwords.


01:20:14.000 --> 01:20:20.000
And there's a password list in there as well of about 10,000


01:20:20.000 --> 01:20:22.000
common database passwords.


01:20:22.000 --> 01:20:23.000
Yeah, nice.


01:20:23.000 --> 01:20:26.000
So yeah, just make sure your password is not on that list.


01:20:26.000 --> 01:20:30.000
And if it is, you can raise a pull request to remove it.


01:20:30.000 --> 01:20:32.000
Yeah, yeah, yeah.


01:20:32.000 --> 01:20:35.000
You don't want--you still want to have your database open.


01:20:35.000 --> 01:20:41.000
Like it doesn't get much worse than I just have read/write access


01:20:41.000 --> 01:20:44.000
to your database, but that's what this would test for, right?


01:20:44.000 --> 01:20:45.000
Yeah, yeah.


01:20:45.000 --> 01:20:49.000
So you can scan a cluster or a machine and see if it can predict


01:20:49.000 --> 01:20:51.000
what the username password is.


01:20:51.000 --> 01:20:53.000
Yeah, cool.


01:20:53.000 --> 01:20:55.000
All right, well, those are three great recommendations.


01:20:55.000 --> 01:20:58.000
It's awesome to have you back on the show.


01:20:58.000 --> 01:21:00.000
And congratulations on the work here.


01:21:00.000 --> 01:21:03.000
Final call to action, you want people maybe to try Pidgin,


01:21:03.000 --> 01:21:06.000
you want them to contribute, got other ideas.


01:21:06.000 --> 01:21:08.000
What do you say?


01:21:08.000 --> 01:21:10.000
Yeah, go to trypidgin.com.


01:21:10.000 --> 01:21:15.000
And yeah, on trypidgin.com, you'll see at the top,


01:21:15.000 --> 01:21:20.000
you can try it out live, link to documentation, link to download.


01:21:20.000 --> 01:21:23.000
Yeah, I'd love more contributions or discussion, I think,


01:21:23.000 --> 01:21:26.000
around what optimizations you could have and people using it


01:21:26.000 --> 01:21:28.000
and checking it out.


01:21:28.000 --> 01:21:30.000
And if you have any issues, you just raise them on GitHub


01:21:30.000 --> 01:21:32.000
and I'll check them out.


01:21:32.000 --> 01:21:34.000
All right, fantastic.


01:21:34.000 --> 01:21:36.000
Well done, I can tell this is a ton of work.


01:21:36.000 --> 01:21:39.000
So you've come really a long ways.


01:21:39.000 --> 01:21:42.000
And congrats on 1.0 when it comes out in a few days.


01:21:42.000 --> 01:21:43.000
Thanks, Michael.


01:21:43.000 --> 01:21:44.000
Yeah, you bet.


01:21:44.000 --> 01:21:45.000
See you.

