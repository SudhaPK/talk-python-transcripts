WEBVTT

00:00:00.000 --> 00:00:02.000
Hey YouTube, hey Brent.


00:00:02.000 --> 00:00:03.000
- Hello.


00:00:03.000 --> 00:00:05.000
- Hey, I'm excited to have you on the show.


00:00:05.000 --> 00:00:07.000
We're gonna have a lot of fun.


00:00:07.000 --> 00:00:09.000
Before we get to the official podcast,


00:00:09.000 --> 00:00:11.000
I just want to tell people listening,


00:00:11.000 --> 00:00:13.000
if you have questions or thoughts for us,


00:00:13.000 --> 00:00:15.000
please throw them in the live chat,


00:00:15.000 --> 00:00:17.000
and we'll try to make them part of the show.


00:00:17.000 --> 00:00:19.000
If you're watching this afterwards,


00:00:19.000 --> 00:00:21.000
well, there's no live chat,


00:00:21.000 --> 00:00:23.000
but we still appreciate you watching the show.


00:00:23.000 --> 00:00:25.000
All right, ready to kick this off?


00:00:25.000 --> 00:00:27.000
- Yes, I am. Thanks for having me.


00:00:27.000 --> 00:00:29.000
- All right, yeah.


00:00:29.000 --> 00:00:32.000
Thank you for having me. I'm excited to talk about some of this stuff.


00:00:32.000 --> 00:00:35.000
I am absolutely excited about it as well.


00:00:35.000 --> 00:00:38.000
I feel there's a huge renaissance coming,


00:00:38.000 --> 00:00:41.000
happening right now or has been happening


00:00:41.000 --> 00:00:44.000
for a little while now around Python performance.


00:00:44.000 --> 00:00:47.000
Yeah, no, it's exciting to see,


00:00:47.000 --> 00:00:50.000
especially in just the last couple of years.


00:00:50.000 --> 00:00:53.000
You definitely see these different focuses, whether it's,


00:00:53.000 --> 00:00:56.000
you know, improving single threaded Python performance,


00:00:56.000 --> 00:00:58.100
multi-threaded Python performance,


00:00:58.100 --> 00:01:00.480
you know, Python in the browser.


00:01:00.480 --> 00:01:03.040
There's a lot of really cool stuff happening right now.


00:01:03.040 --> 00:01:04.080
- Absolutely.


00:01:04.080 --> 00:01:08.140
Yeah, if we could talk WebAssembly and PyScript


00:01:08.140 --> 00:01:11.000
and all that, that is a very exciting thing.


00:01:11.000 --> 00:01:13.400
There's probably some performance side around it,


00:01:13.400 --> 00:01:15.400
and I think it'll be, you know,


00:01:15.400 --> 00:01:16.760
maybe something we could touch on,


00:01:16.760 --> 00:01:18.480
but that's not the main topic for today.


00:01:18.480 --> 00:01:21.400
We're gonna talk about just the core CPython


00:01:21.400 --> 00:01:23.320
and how it works, which is gonna be awesome.


00:01:23.320 --> 00:01:26.180
some work you've done with the team there at Microsoft


00:01:26.180 --> 00:01:27.920
and your contributions there.


00:01:27.920 --> 00:01:29.800
Before we get into all that stuff though,


00:01:29.800 --> 00:01:30.940
let's start with your story.


00:01:30.940 --> 00:01:33.480
How'd you get into programming in Python?


00:01:33.480 --> 00:01:37.360
- Yeah, so I originally studied computer engineering,


00:01:37.360 --> 00:01:40.240
so like hardware stuff at UC Irvine.


00:01:40.240 --> 00:01:46.240
And around my third or fourth year, so like 2017,


00:01:46.240 --> 00:01:51.600
I encountered Python really for the first time


00:01:51.600 --> 00:01:53.020
in a project setting.


00:01:53.020 --> 00:01:55.020
Basically, it was a senior design project.


00:01:55.020 --> 00:01:57.020
We get to make whatever we want.


00:01:57.020 --> 00:02:01.700
And so we made this cool system that basically,


00:02:01.700 --> 00:02:03.700
you point cameras at a blackjack table


00:02:03.700 --> 00:02:05.700
and it detects card counters.


00:02:05.700 --> 00:02:07.700
And if you want to do something like that in four months


00:02:07.700 --> 00:02:09.700
or whatever, Python is kind of the way to go.


00:02:09.700 --> 00:02:13.100
Yeah, the CV stuff there is really good, right?


00:02:13.100 --> 00:02:15.100
Yeah, so it was NumPy and OpenCV


00:02:15.100 --> 00:02:17.100
and that was kind of my first exposure to this stuff.


00:02:17.100 --> 00:02:20.740
And so I learned that I like developing software


00:02:20.740 --> 00:02:22.740
a lot more than developing hardware.


00:02:22.740 --> 00:02:27.240
So I kind of never looked back and just went full in.


00:02:27.240 --> 00:02:33.740
About a year later, so like 2018, I opened my first PR to the CPython repo,


00:02:33.740 --> 00:02:37.740
and it was merged, and a year after that, one night...


00:02:37.740 --> 00:02:43.740
Oh, there's this standard library module called "Module Finder".


00:02:43.740 --> 00:02:48.740
Basically, it's one of those ones that's kind of just a historical oddity,


00:02:48.740 --> 00:02:50.400
and it's still in there.


00:02:50.400 --> 00:02:53.800
Basically, you can run it over any Python script.


00:02:53.800 --> 00:02:55.880
It detects all the imports, and so you can use it


00:02:55.880 --> 00:02:58.120
to build an import graph.


00:02:58.120 --> 00:03:00.040
And I forget exactly what I was using it for.


00:03:00.040 --> 00:03:02.640
I think it was for work.


00:03:02.640 --> 00:03:06.200
And I ran into some bugs that had been just kind of lingering


00:03:06.200 --> 00:03:09.520
there for years, and so I submitted patches


00:03:09.520 --> 00:03:10.760
for a bunch of them.


00:03:10.760 --> 00:03:14.720
And so that was kind of my first experience contributing


00:03:14.720 --> 00:03:17.240
to open source in general.


00:03:17.240 --> 00:03:20.080
that PR was actually open for a while.


00:03:20.080 --> 00:03:23.920
It was open for like, I think it was like a month or two


00:03:23.920 --> 00:03:24.760
or something like that.


00:03:24.760 --> 00:03:27.660
So in the meantime, I contributed other things


00:03:27.660 --> 00:03:29.840
to like mypy and typeshed,


00:03:29.840 --> 00:03:33.080
but that's still my first open source contribution.


00:03:33.080 --> 00:03:34.640
If you count the data was open.


00:03:34.640 --> 00:03:37.840
- Yeah, does it count as a beginning


00:03:37.840 --> 00:03:39.560
or the end of the PR, right?


00:03:39.560 --> 00:03:40.480
- Yeah, exactly.


00:03:40.480 --> 00:03:42.320
'Cause those can be very different things sometimes.


00:03:42.320 --> 00:03:43.760
- They can be very different.


00:03:43.760 --> 00:03:45.360
You know, we have now in CPython,


00:03:45.360 --> 00:03:48.840
we have the, just in Python I guess,


00:03:48.840 --> 00:03:52.440
we have the developer in residence with Lukas Schlinge


00:03:52.440 --> 00:03:55.200
and he's there to sort of facilitate


00:03:55.200 --> 00:03:56.040
making that a lot faster.


00:03:56.040 --> 00:03:59.280
I feel like people's experience there might be


00:03:59.280 --> 00:04:01.440
picking up speed and improving.


00:04:01.440 --> 00:04:03.820
- Yeah, no, I think that's a great thing.


00:04:03.820 --> 00:04:06.140
And in general, just seeing this kind of shift


00:04:06.140 --> 00:04:08.680
towards full-time Python core development,


00:04:08.680 --> 00:04:11.560
being funded by these big companies


00:04:11.560 --> 00:04:12.880
is really exciting to see.


00:04:12.880 --> 00:04:15.540
and I think it improves the end contributor experience,


00:04:15.540 --> 00:04:20.380
the user experience, and just gets things done, which is nice.


00:04:20.380 --> 00:04:24.080
I don't have any numbers, but I imagine there are fewer


00:04:24.080 --> 00:04:28.380
of those lingering months-old PRs than there were


00:04:28.380 --> 00:04:30.380
back when I first started.


00:04:30.380 --> 00:04:32.380
Way, way long ago, four years ago.


00:04:32.380 --> 00:04:34.380
[laughter]


00:04:34.380 --> 00:04:36.380
[SAM] So far back in the past. [ADAM] So long, so long.


00:04:38.380 --> 00:04:40.780
So yeah, so that was like 2018.


00:04:40.780 --> 00:04:46.140
2019, I became a member of the Triage team,


00:04:46.140 --> 00:04:50.260
which is basically a team for people who are


00:04:50.260 --> 00:04:54.340
kind of more involved in Python than just your average Drive by contributor.


00:04:54.340 --> 00:04:57.540
So while they're not full core developers with...


00:04:57.540 --> 00:05:00.660
they basically can do anything a core developer can


00:05:00.660 --> 00:05:03.820
except vote and actually, you know, press the merge button.


00:05:03.820 --> 00:05:07.740
So that was really nice because it made doing things like reviewing PRs easier,


00:05:07.740 --> 00:05:10.980
tagging issues, closing issues, that sort of thing.


00:05:10.980 --> 00:05:15.140
And then a year later, I became--


00:05:15.140 --> 00:05:16.460
- How did you get the experience for that?


00:05:16.460 --> 00:05:19.300
Like how do you, you know, it's one thing to say,


00:05:19.300 --> 00:05:22.020
well, I've focused on this module and here's this fix,


00:05:22.020 --> 00:05:23.500
and it's another to say,


00:05:23.500 --> 00:05:26.620
you give me anything from CPython and I'll assess it.


00:05:26.620 --> 00:05:28.580
- Well, it wasn't give me anything from CPython,


00:05:28.580 --> 00:05:32.140
it was, you know, it made it part of my morning routine


00:05:32.140 --> 00:05:35.780
to, you know, wake up, go to a coffee shop, order a coffee,


00:05:35.780 --> 00:05:39.460
and just for a half hour look at newly opened issues.


00:05:39.460 --> 00:05:46.220
And I see, yeah, yeah, well, I focus mostly on PR review for new contributors.


00:05:46.220 --> 00:05:54.340
So basically, I had filters set up that said, you know, show me all the PRs open the last 48 hours


00:05:54.340 --> 00:05:58.020
from a new contributor, because I thought, okay, my first contribution experience wasn't that great.


00:05:58.020 --> 00:06:02.660
It'd be great if, you know, these people who have never opened a PR to see Python before,


00:06:02.660 --> 00:06:05.420
can get a response within 48 hours.


00:06:05.420 --> 00:06:12.820
whether that's telling them to sign the contributor license agreement or formatting fixes or pinging the relevant core dev or whatever.


00:06:12.820 --> 00:06:15.820
So that was kind of how I dove into that.


00:06:15.820 --> 00:06:21.820
All this terminology that you're using, PR and stuff. No, this is great.


00:06:21.820 --> 00:06:26.620
What I was going to say is that this is new to Python, right?


00:06:26.620 --> 00:06:31.620
It wasn't that long ago that Python was on Mercurial or before then Subversion.


00:06:31.620 --> 00:06:34.240
It's, you know, it's coming over to GitHub


00:06:34.240 --> 00:06:36.000
is kind of a big deal and I feel like


00:06:36.000 --> 00:06:37.680
it's really opened the door for more people


00:06:37.680 --> 00:06:39.840
to be willing to contribute.


00:06:39.840 --> 00:06:41.080
What do you think?


00:06:41.080 --> 00:06:43.040
- Oh, it absolutely lowered the barrier to entry


00:06:43.040 --> 00:06:44.400
for people like me.


00:06:44.400 --> 00:06:48.900
Like using the old bugs.python.org was tough at first,


00:06:48.900 --> 00:06:50.760
but I eventually kind of got used to it


00:06:50.760 --> 00:06:53.320
just in time for it to be replaced with GitHub issues,


00:06:53.320 --> 00:06:54.800
which I much prefer.


00:06:54.800 --> 00:06:58.000
But I have a hard time seeing myself, you know,


00:06:58.000 --> 00:07:00.240
emailing patches around or, you know,


00:07:00.240 --> 00:07:06.680
I have a lot of respect for people where that was the development flow, you know, and a


00:07:06.680 --> 00:07:07.680
number of years ago.


00:07:07.680 --> 00:07:09.680
Yeah, yeah, cool.


00:07:09.680 --> 00:07:10.880
Yeah.


00:07:10.880 --> 00:07:15.280
So I became a core developer in 2020.


00:07:15.280 --> 00:07:21.400
And a, I guess it was about exactly a year ago, almost exactly a year ago, I joined the


00:07:21.400 --> 00:07:24.440
Python performance team here at Microsoft.


00:07:24.440 --> 00:07:26.320
Were you at Microsoft before then?


00:07:26.320 --> 00:07:27.880
No, I was not.


00:07:27.880 --> 00:07:30.760
I work for a company called Research Affiliates


00:07:30.760 --> 00:07:32.160
in New York Beach.


00:07:32.160 --> 00:07:35.100
And I think you actually had my old manager,


00:07:35.100 --> 00:07:36.440
Chris Arisa on the show.


00:07:36.440 --> 00:07:37.760
- I have had Chris on the show.


00:07:37.760 --> 00:07:38.600
That's fantastic.


00:07:38.600 --> 00:07:41.400
Small world, huh?


00:07:41.400 --> 00:07:42.600
- Yep.


00:07:42.600 --> 00:07:44.080
Small Python world.


00:07:44.080 --> 00:07:45.160
- Yeah, small Python world.


00:07:45.160 --> 00:07:46.920
Just a couple of million of us.


00:07:46.920 --> 00:07:48.720
No, that's great.


00:07:48.720 --> 00:07:53.340
So this brings us to our main topic.


00:07:53.340 --> 00:07:59.540
And let's start at the top, I guess.


00:07:59.540 --> 00:08:03.580
There's the Faster Python team, I guess.


00:08:03.580 --> 00:08:04.140
I don't know.


00:08:04.140 --> 00:08:07.300
How do you all refer to yourself?


00:08:07.300 --> 00:08:10.340
- Yeah, we refer to ourselves as the Faster CPython team.


00:08:10.340 --> 00:08:12.220
I think internally, our distribution list


00:08:12.220 --> 00:08:15.620
is the CPython Performance Engineering team, which


00:08:15.620 --> 00:08:20.340
sounds a little gnarlier, but it's a lot wordier.


00:08:20.340 --> 00:08:22.900
- That's a cool title to have on a resume, isn't it?


00:08:22.900 --> 00:08:24.900
Yeah, yeah, I think I'll use that one.


00:08:24.900 --> 00:08:25.740
(laughing)


00:08:25.740 --> 00:08:26.580
- There you go.


00:08:26.580 --> 00:08:29.660
There's been a ton of progress.


00:08:29.660 --> 00:08:33.020
Some of this work was done in 3.10,


00:08:33.020 --> 00:08:35.140
but there's this article here


00:08:35.140 --> 00:08:36.740
that I got pulled up on the screen.


00:08:36.740 --> 00:08:39.700
So it says Python 3.11 performance benchmarks


00:08:39.700 --> 00:08:41.480
are looking fantastic.


00:08:41.480 --> 00:08:44.480
That's gotta make you feel good, huh?


00:08:44.480 --> 00:08:47.660
- I mean, they were looking fantastic back in what, June?


00:08:47.660 --> 00:08:50.420
They're a small bit more fantastic now.


00:08:50.420 --> 00:08:51.620
So yeah. - Yeah, exactly.


00:08:51.620 --> 00:08:56.620
This article's from June, so it's only better from there.


00:08:56.620 --> 00:08:57.740
- Yep, yep.


00:08:57.740 --> 00:09:00.260
Yeah, and no, it's really exciting.


00:09:00.260 --> 00:09:04.940
And like I said, this is a performance jump


00:09:04.940 --> 00:09:07.180
that at least since I've been involved in Python,


00:09:07.180 --> 00:09:09.980
we haven't seen this in a point release,


00:09:09.980 --> 00:09:12.300
where we're seeing 25, 30%,


00:09:12.300 --> 00:09:14.980
sometimes more improvements for pure Python code


00:09:14.980 --> 00:09:19.280
rather than kind of the five, 10, 15% range


00:09:19.280 --> 00:09:20.980
that might be more typical.


00:09:20.980 --> 00:09:26.980
And again, I think that's kind of a product of this very conscious effort,


00:09:26.980 --> 00:09:30.980
whether it's my team or a lot of people that we interact with.


00:09:30.980 --> 00:09:34.980
So for example, Pablo, Release Manager, Strength Council Member at Bloomberg,


00:09:34.980 --> 00:09:37.980
has been working a lot on this stuff with us.


00:09:37.980 --> 00:09:42.980
Outside contributors, two that come to mind are Dennis Sweeney and Ken Jin.


00:09:42.980 --> 00:09:47.980
There's definitely been a focus on this, and it's paying off,


00:09:47.980 --> 00:09:49.980
which is really exciting, like you said.


00:09:49.980 --> 00:09:53.100
- Yeah, and maybe a little bit more in parallel


00:09:53.100 --> 00:09:55.020
instead of a cooperative effort,


00:09:55.020 --> 00:09:59.400
but there's also the Cinder folks over at Meta Facebook.


00:09:59.400 --> 00:10:02.420
- That's absolutely a cooperative effort.


00:10:02.420 --> 00:10:07.660
You know, even though Cinder isn't necessarily,


00:10:07.660 --> 00:10:11.480
we're not merging all of Cinder back into CPython,


00:10:11.480 --> 00:10:14.420
several of the changes are being upstreamed into CPython.


00:10:14.420 --> 00:10:17.780
And in fact, just earlier this week on Tuesday,


00:10:17.780 --> 00:10:19.880
we had, I think like a two hour meeting


00:10:19.880 --> 00:10:22.020
where the sender team walked our team through


00:10:22.020 --> 00:10:23.280
how their JIT works.


00:10:23.280 --> 00:10:26.120
So it's, yeah.


00:10:26.120 --> 00:10:28.200
So it's, even though, yeah, it can be seen


00:10:28.200 --> 00:10:30.900
as a parallel effort, I think it's very collaborative.


00:10:30.900 --> 00:10:36.200
- I think also, I, like you, am very much blown away


00:10:36.200 --> 00:10:40.520
at the step size of the performance improvements.


00:10:40.520 --> 00:10:43.280
It's just super surprising to me


00:10:43.280 --> 00:10:46.240
that a 30-year-old language and a 30-year-old runtime


00:10:47.480 --> 00:10:51.040
can get that much better in that short of a time.


00:10:51.040 --> 00:10:53.800
Yeah, and I think, again, I feel like I'm


00:10:53.800 --> 00:10:55.260
going to keep coming back to this,


00:10:55.260 --> 00:10:58.780
but having full-time people dedicated to this,


00:10:58.780 --> 00:11:01.560
having teams of people dedicated to this,


00:11:01.560 --> 00:11:03.800
I think that's a big part of unlocking this.


00:11:03.800 --> 00:11:06.120
Because some of the things that are


00:11:06.120 --> 00:11:09.720
required for those big jumps are larger architectural changes.


00:11:09.720 --> 00:11:16.080
That a single volunteer who's doing this on their free time


00:11:16.080 --> 00:11:17.800
probably wouldn't have been able to do


00:11:17.800 --> 00:11:19.400
without coordinating with others


00:11:19.400 --> 00:11:22.600
and without throwing a significant amount of effort at it.


00:11:22.600 --> 00:11:24.280
- Yeah, I mean, there are people out there,


00:11:24.280 --> 00:11:26.800
core devs who have done amazing stuff.


00:11:26.800 --> 00:11:28.040
Shout out to Victor Stinner.


00:11:28.040 --> 00:11:30.060
I feel like a lot of the performance stuff


00:11:30.060 --> 00:11:31.960
that I've seen in the last couple of years,


00:11:31.960 --> 00:11:35.680
he is somehow associated with some major change,


00:11:35.680 --> 00:11:39.620
but the changes that are being undertaken here,


00:11:39.620 --> 00:11:43.860
they're much more holistic and far reaching.


00:11:43.860 --> 00:11:45.760
And it really does take a team,


00:11:45.760 --> 00:11:48.600
I think to make it reasonable, right?


00:11:48.600 --> 00:11:49.520
- Yeah, yeah.


00:11:49.520 --> 00:11:52.240
And what's cool about the 3.11 effort is


00:11:52.240 --> 00:11:54.980
it's a combination of kind of both sorts of changes.


00:11:54.980 --> 00:11:58.240
So we have a bunch of kind of one-off,


00:11:58.240 --> 00:11:59.820
very targeted changes,


00:11:59.820 --> 00:12:04.520
probably five or six or 10 of those.


00:12:04.520 --> 00:12:08.720
And then we have one or two of these kind of larger changes


00:12:08.720 --> 00:12:11.320
that we can build upon in the future


00:12:11.320 --> 00:12:13.380
and they're never really done.


00:12:15.080 --> 00:12:17.040
which, you know, that's exciting


00:12:17.040 --> 00:12:19.680
'cause it means we get to keep making Python faster.


00:12:19.680 --> 00:12:20.520
- It is exciting.


00:12:20.520 --> 00:12:23.000
I think another area to just highlight real quick


00:12:23.000 --> 00:12:25.720
before we get into too much detail is,


00:12:25.720 --> 00:12:27.600
correct me if I'm wrong,


00:12:27.600 --> 00:12:30.120
but none of this is particularly focused


00:12:30.120 --> 00:12:34.980
on multi-core parallelism, right?


00:12:34.980 --> 00:12:37.840
- No, so one member of our team, Eric Snow,


00:12:37.840 --> 00:12:40.640
he's basically the sub-interpreter guy.


00:12:40.640 --> 00:12:41.480
- Exactly.


00:12:41.480 --> 00:12:45.420
- Yeah, so he is focusing most of his time


00:12:45.420 --> 00:12:50.420
on a per interpreter kill and all that sort of stuff.


00:12:50.420 --> 00:12:53.660
But I mean, all the numbers that you're looking at here


00:12:53.660 --> 00:12:55.100
and all of our benchmarks,


00:12:55.100 --> 00:12:57.780
it's all single threaded, single process.


00:12:57.780 --> 00:13:00.220
If you're running Python code,


00:13:00.220 --> 00:13:02.360
it will get faster without you changing your code,


00:13:02.360 --> 00:13:04.380
which is awesome.


00:13:04.380 --> 00:13:06.000
- Yeah, it's super awesome.


00:13:06.000 --> 00:13:11.300
I wanna highlight that because if Eric manages to unlock


00:13:11.300 --> 00:13:16.300
multi-core performance without much contention or trade-offs.


00:13:16.300 --> 00:13:18.780
Or if you've got an eight-core machine


00:13:18.780 --> 00:13:22.300
and you get 7x performance by using all the cores,


00:13:22.300 --> 00:13:23.600
that would be amazing.


00:13:23.600 --> 00:13:28.180
But all of this work you're doing applies to everyone,


00:13:28.180 --> 00:13:29.740
even if they're trying to do that stuff.


00:13:29.740 --> 00:13:32.300
So even if somehow we get this multi-core stuff,


00:13:32.300 --> 00:13:35.420
the computational multi-core stuff working super well,


00:13:35.420 --> 00:13:37.860
the work that you're doing and the team is doing


00:13:37.860 --> 00:13:40.620
is gonna make it faster on every one of those cores.


00:13:40.620 --> 00:13:45.620
So they're kind of multiplicative initiatives.


00:13:45.620 --> 00:13:48.340
So if we could get a big improvements


00:13:48.340 --> 00:13:49.300
in the parallel stuff,


00:13:49.300 --> 00:13:51.660
it's only gonna just multiply how much better


00:13:51.660 --> 00:13:54.940
this aspect of it's gonna be for people who use that.


00:13:54.940 --> 00:13:56.580
- Yeah, no, absolutely.


00:13:56.580 --> 00:13:59.800
It's great to be kind of pursuing


00:13:59.800 --> 00:14:00.900
all these different avenues


00:14:00.900 --> 00:14:03.460
because they pay off in different timeframes.


00:14:03.460 --> 00:14:04.980
Some of these are longer efforts.


00:14:04.980 --> 00:14:06.920
In Eric's case, the seven term per effort


00:14:06.920 --> 00:14:08.020
is a very long effort.


00:14:08.020 --> 00:14:12.220
and I think he's done a great job of sticking with it and seeing it through.


00:14:12.220 --> 00:14:18.420
And some of these we're seeing in point releases, and so they absolutely build on each other.


00:14:18.420 --> 00:14:22.420
Like you said, if you can get a 7x increase from subinterpreter just to throw out a number,


00:14:22.420 --> 00:14:28.740
but Python as a whole got 25 or 30% faster, then you're seeing much more than a 7x increase.


00:14:28.740 --> 00:14:33.380
Right, absolutely. So very, very exciting times.


00:14:33.380 --> 00:14:41.780
Two things before we get into the details of the particular interpreter and stuff.


00:14:41.780 --> 00:14:42.980
Tell me a bit about this team.


00:14:42.980 --> 00:14:47.460
I interviewed Guido and Mark Shannon a while ago.


00:14:47.460 --> 00:14:48.460
When was that?


00:14:48.460 --> 00:14:54.940
That was about a year ago, I suppose, about this plan when they were kicking it off.


00:14:54.940 --> 00:14:58.700
We didn't have these numbers or anything, but we did talk about what we were doing,


00:14:58.700 --> 00:15:01.700
and he talked about the team that he's working with there.


00:15:01.700 --> 00:15:04.700
Certainly, it's just more than the two of us.


00:15:04.700 --> 00:15:06.700
Tell us about the team.


00:15:06.700 --> 00:15:10.700
Yeah, so I think there are seven people.


00:15:10.700 --> 00:15:12.700
So there's Guido and Mark,


00:15:12.700 --> 00:15:15.700
Eric and me, as we mentioned,


00:15:15.700 --> 00:15:18.700
another core developer, Irit,


00:15:18.700 --> 00:15:22.700
and then one other engineer, El,


00:15:22.700 --> 00:15:25.700
and a manager for the team


00:15:25.700 --> 00:15:27.700
who also does some engineering effort as well,


00:15:27.700 --> 00:15:30.700
and is a member of the triage team, Mike Trappo.


00:15:30.700 --> 00:15:31.540
- Yeah.


00:15:31.540 --> 00:15:32.360
- Nice.


00:15:32.360 --> 00:15:33.200
Yeah, yeah.


00:15:33.200 --> 00:15:35.700
He's, he worked on PyOxidizer.


00:15:35.700 --> 00:15:36.540
- Piedide.


00:15:36.540 --> 00:15:37.360
Piedide.


00:15:37.360 --> 00:15:38.200
- Piedide, yeah.


00:15:38.200 --> 00:15:39.040
I don't know why.


00:15:39.040 --> 00:15:39.860
(laughing)


00:15:39.860 --> 00:15:41.700
- There's so many pi something or something.


00:15:41.700 --> 00:15:42.540
- Molecule on the end.


00:15:42.540 --> 00:15:44.000
Exactly, exactly.


00:15:44.000 --> 00:15:44.840
- Yeah, yeah.


00:15:44.840 --> 00:15:45.660
- That's right.


00:15:45.660 --> 00:15:47.900
That's the foundation for PyScript actually,


00:15:47.900 --> 00:15:49.740
which is quite cool.


00:15:49.740 --> 00:15:50.580
- Yeah.


00:15:50.580 --> 00:15:51.400
- The other question.


00:15:51.400 --> 00:15:52.240
- Yeah.


00:15:52.240 --> 00:15:53.080
- Yeah, yeah, yeah.


00:15:53.080 --> 00:15:55.380
The other thing that I want to ask you about is,


00:15:55.380 --> 00:15:57.660
so we have these numbers,


00:15:57.660 --> 00:16:02.060
to ask you about is, so we have these numbers and visibility


00:16:02.060 --> 00:16:06.380
into Python 3.11 that's got a lot of conversations going,


00:16:06.380 --> 00:16:08.540
people are saying they're looking amazing and fantastic


00:16:08.540 --> 00:16:14.980
and other nice adjectives, but this is in beta,


00:16:14.980 --> 00:16:17.020
maybe soon to be RC, I'm not sure what,


00:16:17.020 --> 00:16:20.420
what is Python 3.11 status these days?


00:16:20.420 --> 00:16:24.340
>> 3.11, we just released our last release candidate,


00:16:24.340 --> 00:16:26.740
I think this week.


00:16:26.740 --> 00:16:28.740
So this...


00:16:28.740 --> 00:16:32.680
Basically, the idea is this, the final release candidate


00:16:32.680 --> 00:16:37.560
and the actual 3.11.0 release should be the exact same thing.


00:16:37.560 --> 00:16:45.320
So unless we find any serious bugs that merit fixing before 3.11.1,


00:16:45.320 --> 00:16:49.160
the release candidate is going to be 3.11.


00:16:49.160 --> 00:16:54.080
So this is as close to stable as any of the pre-releases get.


00:16:54.080 --> 00:16:57.120
Okay, cool. So the reason I ask that is


00:16:57.120 --> 00:17:00.960
a lot of the work you've been doing recently is probably on 3.12, right?


00:17:00.960 --> 00:17:07.120
Yes, so beta freeze, which is basically when we go from alphas into betas,


00:17:07.120 --> 00:17:11.920
and there's no more, basically, new features allowed at that point.


00:17:11.920 --> 00:17:13.920
That happens every May.


00:17:13.920 --> 00:17:17.920
And so everything that we've been working on since May goes into 3.12.


00:17:17.920 --> 00:17:20.880
Are you excited about the progress you've made?


00:17:20.880 --> 00:17:23.520
Yeah, very excited.


00:17:23.520 --> 00:17:25.560
- So it's still coming along well?


00:17:25.560 --> 00:17:26.680
- Yes, yeah.


00:17:26.680 --> 00:17:28.600
And it's nice we still have a lot of time


00:17:28.600 --> 00:17:30.200
before the next beta freeze too.


00:17:30.200 --> 00:17:33.000
- All right, yeah, awesome.


00:17:33.000 --> 00:17:37.160
Let's talk really quickly about the faster-cpython


00:17:37.160 --> 00:17:39.040
thing put together by Mark Shannon.


00:17:39.040 --> 00:17:41.920
Guido called it the Shannon plan.


00:17:41.920 --> 00:17:45.280
And the idea is how can we make Python five times faster?


00:17:45.280 --> 00:17:47.560
If we could take Python and make it five times faster,


00:17:47.560 --> 00:17:49.680
that would be a really huge deal.


00:17:49.680 --> 00:17:51.880
And again, none of that is multi-core.


00:17:51.880 --> 00:17:54.940
If you could somehow unlock all the cores and you've got eight,


00:17:54.940 --> 00:17:59.280
that's 35 or 40 or something like that.


00:17:59.280 --> 00:18:01.760
So this is an ambitious plan.


00:18:01.760 --> 00:18:06.360
It started out with a little bit of work with 3.10.


00:18:06.360 --> 00:18:09.840
Is that when the adaptive specializing interpreter first appeared?


00:18:09.840 --> 00:18:12.680
Or did it actually wait until 3.11 to show up?


00:18:12.680 --> 00:18:16.240
No, I don't believe we-- we don't have it in 3.10.


00:18:16.240 --> 00:18:17.200
Yeah, I didn't think so either.


00:18:17.200 --> 00:18:18.400
Unless I'm missing something.


00:18:18.400 --> 00:18:20.160
Yeah.


00:18:20.160 --> 00:18:21.840
Yeah, so that's in 3.11.


00:18:21.840 --> 00:18:24.180
The rest of it looks accurate though.


00:18:24.180 --> 00:18:25.020
- Yeah, cool.


00:18:25.020 --> 00:18:28.580
So some stuff, yeah.


00:18:28.580 --> 00:18:30.360
So then basically that was stage one.


00:18:30.360 --> 00:18:33.220
Stage two is 3.11 where there's a bunch of things


00:18:33.220 --> 00:18:35.980
including kicking over the interpreter.


00:18:35.980 --> 00:18:39.060
We're gonna talk about the specializing interpreter.


00:18:39.060 --> 00:18:39.900
- Yep.


00:18:39.900 --> 00:18:41.540
- But bunch of small changes here.


00:18:41.540 --> 00:18:45.620
And then stage three for 3.12 is JIT.


00:18:45.620 --> 00:18:48.220
Have you guys done any work on any of the JIT stuff?


00:18:49.540 --> 00:18:53.340
Right now, it's not looking like 3.12 will ship with a JIT.


00:18:53.340 --> 00:18:56.980
We think there are other changes that we can make


00:18:56.980 --> 00:19:00.140
that don't require a JIT that will still pay off.


00:19:00.140 --> 00:19:04.380
We're probably planning on at least experimenting


00:19:04.380 --> 00:19:05.780
with what a JIT would look like.


00:19:05.780 --> 00:19:08.220
Like I said, we already have gotten kind of a guided tour


00:19:08.220 --> 00:19:11.260
of Cinder's JIT, and so we're talking kind of high-level


00:19:11.260 --> 00:19:13.740
architecture and prototyping and that sort of thing.


00:19:13.740 --> 00:19:17.860
But I would be surprised if 3.12 shipped with a JIT.


00:19:18.700 --> 00:19:21.860
But it's a long effort.


00:19:21.860 --> 00:19:24.620
So starting now is a big part of that.


00:19:24.620 --> 00:19:27.060
Yes, actively.


00:19:27.060 --> 00:19:28.140
>>Yeah, cool.


00:19:28.140 --> 00:19:30.980
All right, well, this was put together quite a while ago,


00:19:30.980 --> 00:19:33.780
back in 2020, as a here's our plan.


00:19:33.780 --> 00:19:36.660
And of course, plans are meant to evolve, right?


00:19:36.660 --> 00:19:40.940
But still, looks like this plan is working out quite well


00:19:40.940 --> 00:19:42.580
because of the changes in performance


00:19:42.580 --> 00:19:48.180
that we saw already in 3.11 beta, and pretty fantastic.


00:19:48.180 --> 00:19:51.340
There are a bunch of changes here about, you know,


00:19:51.340 --> 00:19:54.820
things like zero overhead exception handling.


00:19:54.820 --> 00:19:55.940
I believe it used to,


00:19:55.940 --> 00:20:00.040
there was an overhead for entering the try block.


00:20:00.040 --> 00:20:00.880
Even if it was anywhere--


00:20:00.880 --> 00:20:03.340
- Every time you went in or out of a try except block.


00:20:03.340 --> 00:20:06.980
So even if I did try pass, accept pass,


00:20:06.980 --> 00:20:09.700
there was overhead associated with that.


00:20:09.700 --> 00:20:10.980
- Right.


00:20:10.980 --> 00:20:13.260
- So basically we would, you know,


00:20:13.260 --> 00:20:16.160
push a block that says, oh, if an exception happens,


00:20:16.160 --> 00:20:17.420
jump to this location.


00:20:17.420 --> 00:20:25.780
And now what we do is we realize, oh, we actually have that information ahead of time when we're actually compiling the bytecode.


00:20:25.780 --> 00:20:34.780
So since the common case is that an exception isn't raised, then we can, you know, store that data in a separate table and say,


00:20:34.780 --> 00:20:41.580
oh, if an exception is raised at this instruction, then jump here without actually having to do any of that management at runtime.


00:20:41.580 --> 00:20:45.900
So it's a little more expensive, I believe, if an exception is raised.


00:20:45.900 --> 00:20:48.700
But in the case where an exception is not raised,


00:20:48.700 --> 00:20:54.300
I think it is basically as close to truly zero cost as possible.


00:20:54.300 --> 00:20:56.300
That's really cool.


00:20:56.300 --> 00:20:57.100
Yeah.


00:20:57.100 --> 00:20:58.620
I think that's the way it should be.


00:20:58.620 --> 00:21:03.980
Exceptions, as the word implies, is not the main thing that happens.


00:21:03.980 --> 00:21:07.500
It's some unusual case that has happened, right?


00:21:07.500 --> 00:21:12.060
So not always, but often means something has gone wrong.


00:21:12.060 --> 00:21:13.540
So if something goes wrong, well,


00:21:13.540 --> 00:21:17.360
you kind of put performance to the side anyway, right?


00:21:17.360 --> 00:21:20.660
- Yeah, well, and a lot of the sort of optimizations


00:21:20.660 --> 00:21:24.100
that you wanna see, especially in, for example,


00:21:24.100 --> 00:21:26.020
JIT code or whatever,


00:21:26.020 --> 00:21:28.260
exceptions are the sort of thing that mess that up,


00:21:28.260 --> 00:21:29.980
where if an exception is raised,


00:21:29.980 --> 00:21:31.060
okay, get out of the JIT code,


00:21:31.060 --> 00:21:35.420
go back to the slow land where we know what's going on


00:21:35.420 --> 00:21:39.260
and have better control of context and everything.


00:21:39.260 --> 00:21:41.900
But yeah, no, it's really exciting to see.


00:21:41.900 --> 00:21:44.700
It's really cool design.


00:21:44.700 --> 00:21:46.660
And yeah, it was Mark Shannon who did this.


00:21:46.660 --> 00:21:48.660
It was Mark Shannon who did a lot of this stuff.


00:21:48.660 --> 00:21:49.820
>>Yeah, very cool.


00:21:49.820 --> 00:21:52.260
So there's a bunch of improvements coming along.


00:21:52.260 --> 00:21:54.700
But what I want to really focus on here


00:21:54.700 --> 00:22:01.780
is the PEP 659, the specializing adaptive interpreter.


00:22:01.780 --> 00:22:03.860
And in addition to being on the team,


00:22:03.860 --> 00:22:05.540
You've created a really cool project,


00:22:05.540 --> 00:22:08.160
which we're gonna talk about as soon as we cover this one,


00:22:08.160 --> 00:22:10.360
about how you actually visualize this


00:22:10.360 --> 00:22:14.000
and maybe even change your code to make it faster,


00:22:14.000 --> 00:22:18.280
understanding how maybe opportunities might be missed


00:22:18.280 --> 00:22:21.860
for your code to be specialized or adapted.


00:22:21.860 --> 00:22:24.520
- Yeah, that's 659.


00:22:24.520 --> 00:22:27.660
I mean, the concepts are not too difficult,


00:22:27.660 --> 00:22:29.580
but the implementation is really hairy.


00:22:29.580 --> 00:22:33.320
So I think it definitely deserves to kind of be gone over


00:22:33.320 --> 00:22:38.680
in some detail because it's really cool when you get down to how it actually works and what it's doing to your code.


00:22:38.680 --> 00:22:42.280
Is this the biggest reason for performance boosts?


00:22:42.280 --> 00:22:47.080
I think it's the most important reason for performance boosts.


00:22:47.080 --> 00:22:50.200
I mean, any performance boost kind of depends on what you're doing, right?


00:22:50.200 --> 00:22:57.880
Like we did, for example, Pablo and Mark worked together on making Python to Python calls way faster and way more efficient.


00:22:57.880 --> 00:23:01.400
So if you're doing lots of recursive stuff, that's going to be the game changer for you.


00:23:01.400 --> 00:23:03.400
>> Okay.


00:23:03.400 --> 00:23:05.400
>> You know, we did all sorts of these--


00:23:05.400 --> 00:23:07.400
>> If you spend all your time writing loops


00:23:07.400 --> 00:23:09.400
that just do try, accept, try, accept.


00:23:09.400 --> 00:23:11.400
>> Yeah. >> That one's better.


00:23:11.400 --> 00:23:13.400
>> Yeah, if you're, yeah,


00:23:13.400 --> 00:23:15.400
you've got try, accept, and tight loops,


00:23:15.400 --> 00:23:17.400
or, you know, if you're,


00:23:17.400 --> 00:23:19.400
if you do lots of regular expressions,


00:23:19.400 --> 00:23:21.400
then our improvements in that area will probably matter


00:23:21.400 --> 00:23:23.400
more than this, but


00:23:23.400 --> 00:23:25.400
this is cool because


00:23:25.400 --> 00:23:27.400
we can build upon it


00:23:27.400 --> 00:23:29.400
to kind of unlock


00:23:29.400 --> 00:23:32.360
additional performance improvements in the future.


00:23:32.360 --> 00:23:36.280
We can kind of get into that once we have a better idea of how exactly it works.


00:23:36.280 --> 00:23:42.880
Yeah, sure. When I look at PEPs, usually it'll say what its status is


00:23:42.880 --> 00:23:45.040
and what version of Python it applies to.


00:23:45.040 --> 00:23:49.840
And I see this PEP, it doesn't say which version it applies to and its status is draft.


00:23:49.840 --> 00:23:51.840
What's the story here with that?


00:23:51.840 --> 00:23:57.520
Yeah, so I'm actually not sure what the story is behind the PEP itself.


00:23:57.520 --> 00:24:04.000
I think it's a good informational document that explains, you know, the changes that we did get into Python 3.11.


00:24:04.000 --> 00:24:09.120
But I don't think the PEP was ever formally accepted.


00:24:09.120 --> 00:24:11.600
As you can see, it's just an informational PEP.


00:24:11.600 --> 00:24:16.840
So it's kind of more the design of what exactly we're doing and how we plan to do it.


00:24:16.840 --> 00:24:25.200
Right, because it's not really talking about the implementation so much as like, here's the roadmap,


00:24:25.200 --> 00:24:27.000
and here's what we plan to do and stuff, right?


00:24:27.000 --> 00:24:31.800
Yeah, there's a lot of pros in there that says,


00:24:31.800 --> 00:24:34.980
here's how we might do it, but no promises.


00:24:34.980 --> 00:24:36.980
We could change this literally anytime.


00:24:36.980 --> 00:24:37.980
And we have.


00:24:37.980 --> 00:24:41.400
The design has changed fairly significantly


00:24:41.400 --> 00:24:44.080
since this PEP was first published,


00:24:44.080 --> 00:24:47.760
but we've updated the PEP so it can remain accurate.


00:24:47.760 --> 00:24:49.040
Yeah, cool.


00:24:49.040 --> 00:24:56.620
OK, so the background is when we're running code,


00:24:56.620 --> 00:25:00.020
It's not compiled and it's not static types, right?


00:25:00.020 --> 00:25:02.860
It's because it's Python, it's dynamic


00:25:02.860 --> 00:25:04.020
and the types could change.


00:25:04.020 --> 00:25:07.420
They could change because it just uses duck typing


00:25:07.420 --> 00:25:10.380
and we might just happen to pass different things over


00:25:10.380 --> 00:25:14.220
and we do have type hints, but as the word there is,


00:25:14.220 --> 00:25:16.100
it applies as a hint, not a requirement


00:25:16.100 --> 00:25:18.540
like C++ or C# or something.


00:25:18.540 --> 00:25:24.540
So you have to have the CPython runtime


00:25:24.540 --> 00:25:28.540
be as general as possible for many of its operations, right?


00:25:28.540 --> 00:25:34.540
Yeah, absolutely. And beyond just types, things like I could create a global variable at any time.


00:25:34.540 --> 00:25:36.540
I could delete a global variable at any time.


00:25:36.540 --> 00:25:40.540
I could add or remove arbitrary attributes from objects.


00:25:40.540 --> 00:25:48.540
All these sort of very Pythonic things about Python, or un-Pythonic depending on how you're looking at it.


00:25:48.540 --> 00:25:54.540
You know, these are all sort of things that would never fly in compiled languages.


00:25:54.540 --> 00:26:02.040
Yeah, and they mean you can't be overly specific about how you work with operations.


00:26:02.040 --> 00:26:06.040
So, for example, if you say, "I want to work with..."


00:26:06.040 --> 00:26:10.040
like, you know, "call this function and pass it the value of x."


00:26:10.040 --> 00:26:12.040
Well, where did x come from?


00:26:12.040 --> 00:26:14.040
Is x a built-in?


00:26:14.040 --> 00:26:16.040
Is it a global variable?


00:26:16.040 --> 00:26:18.040
Is it at the module level?


00:26:18.040 --> 00:26:21.880
Is it a parameter? Is it a local variable?


00:26:21.880 --> 00:26:24.880
All these things have to be discovered at runtime, right?


00:26:24.880 --> 00:26:26.880
- For the most part, yeah.


00:26:26.880 --> 00:26:28.880
- Yeah, for the most part.


00:26:28.880 --> 00:26:34.880
Yeah, so part of this adapting interpreter is


00:26:34.880 --> 00:26:36.880
it will run the code and it says,


00:26:36.880 --> 00:26:40.880
like every single time they said load this variable called x,


00:26:40.880 --> 00:26:44.880
it came out of the built-ins, not out of a module.


00:26:44.880 --> 00:26:48.580
And so we're gonna replace that code, specialize it,


00:26:48.580 --> 00:26:51.740
or quicken it, I've heard of quickening,


00:26:51.740 --> 00:26:53.780
so I'll have to work on the nomenclature a little bit.


00:26:53.780 --> 00:26:56.940
- Yeah, we can clear up the terms in a bit, yeah.


00:26:56.940 --> 00:26:58.760
- Yeah, yeah, but you're gonna take this code


00:26:58.760 --> 00:27:00.060
and you're gonna replace it,


00:27:00.060 --> 00:27:02.060
don't say just load an attribute


00:27:02.060 --> 00:27:04.100
or load a value from somewhere


00:27:04.100 --> 00:27:05.020
and go look in all the places,


00:27:05.020 --> 00:27:06.900
you're like, no, no, no, go look in the built-ins


00:27:06.900 --> 00:27:07.860
and just get it from there.


00:27:07.860 --> 00:27:10.660
And that skips a lot of steps, right?


00:27:10.660 --> 00:27:12.780
- Yep, yeah.


00:27:12.780 --> 00:27:14.380
- Or maybe, I'm doing math here


00:27:14.380 --> 00:27:16.820
And every single time, it's been an integer.


00:27:16.820 --> 00:27:18.460
So let's just do integer math and not


00:27:18.460 --> 00:27:21.500
arbitrary addition operator.


00:27:21.500 --> 00:27:23.700
Yeah, exactly.


00:27:23.700 --> 00:27:30.980
With a huge asterisk that if it does become a global variable


00:27:30.980 --> 00:27:34.460
or if it does start throwing floats at your addition


00:27:34.460 --> 00:27:37.500
operation that we don't set fault or even


00:27:37.500 --> 00:27:40.340
produce an incorrect result.


00:27:40.340 --> 00:27:44.740
Right, because you could say, use x.


00:27:44.740 --> 00:27:47.900
But before that, you might say, if some value is true,


00:27:47.900 --> 00:27:49.340
x equals this thing.


00:27:49.340 --> 00:27:52.140
It goes from being a built-in to a local variable,


00:27:52.140 --> 00:27:54.380
or some weird thing like that.


00:27:54.380 --> 00:27:56.980
If it overly specialized and couldn't fall back,


00:27:56.980 --> 00:28:01.060
well, bad things happen, right?


00:28:01.060 --> 00:28:02.780
Yeah, it would be surprising if you


00:28:02.780 --> 00:28:05.620
were getting the len function from the built-ins


00:28:05.620 --> 00:28:06.580
over and over and over.


00:28:06.580 --> 00:28:11.780
And then you, for some reason, defined len as a global.


00:28:11.780 --> 00:28:13.940
Python, the language specification


00:28:13.940 --> 00:28:15.980
says it's going to start loading the global now,


00:28:15.980 --> 00:28:20.380
regardless of where it may have lived before.


00:28:20.380 --> 00:28:23.100
And that's the same for attribute accesses.


00:28:23.100 --> 00:28:25.300
If you used to be getting an attribute off the class,


00:28:25.300 --> 00:28:27.960
and then you shadow it on the instance,


00:28:27.960 --> 00:28:30.120
you need to start getting it from the instance now.


00:28:30.120 --> 00:28:31.820
You can't keep getting it from the class.


00:28:31.820 --> 00:28:33.100
That's incorrect.


00:28:33.100 --> 00:28:35.660
Right, and this is one of those problems that arises from this


00:28:35.660 --> 00:28:41.060
a static dynamic language that can be changed as the code runs.


00:28:41.060 --> 00:28:43.060
Because if this was compiled,


00:28:43.060 --> 00:28:46.660
wherever those things came from and what they were,


00:28:46.660 --> 00:28:47.660
they can't change.


00:28:47.660 --> 00:28:50.460
Their type was set, their location was set.


00:28:50.460 --> 00:28:52.260
And so then the compiler can say,


00:28:52.260 --> 00:28:55.060
"Well, it's better if we inline this,"


00:28:55.060 --> 00:28:58.460
or "It's better if we do this machine operation


00:28:58.460 --> 00:29:00.260
that works on integers better,"


00:29:00.260 --> 00:29:03.460
or some special thing like that, right?


00:29:03.460 --> 00:29:05.260
It doesn't have to worry about it falling back.


00:29:05.260 --> 00:29:10.260
and back and I feel like that ability to adapt and change


00:29:10.260 --> 00:29:14.180
and just be super dynamic is what's kind of held it back


00:29:14.180 --> 00:29:15.540
a lot, right?


00:29:15.540 --> 00:29:17.580
- Yep, and I like that word that you used, adapt,


00:29:17.580 --> 00:29:18.780
'cause that's kind of a big part


00:29:18.780 --> 00:29:21.220
of how the new interpreter works.


00:29:21.220 --> 00:29:24.300
You can change your code and the interpreter adapts


00:29:24.300 --> 00:29:25.140
with you.


00:29:25.140 --> 00:29:28.580
If X starts being an attribute on the instance


00:29:28.580 --> 00:29:31.660
rather than from the class, well, soon the interpreter


00:29:31.660 --> 00:29:34.600
will learn that sometime later after running your program


00:29:34.600 --> 00:29:36.600
and then, okay, start doing the fast path


00:29:36.600 --> 00:29:40.000
for instance access rather than class access.


00:29:40.000 --> 00:29:42.320
- Right, okay, well, let's start there.


00:29:42.320 --> 00:29:46.240
How does it know, right?


00:29:46.240 --> 00:29:51.240
It doesn't compile, so it has to figure this stuff out.


00:29:51.240 --> 00:29:54.120
I run my code, why does it know


00:29:54.120 --> 00:29:55.800
that I can now treat these things


00:29:55.800 --> 00:29:59.000
X and Y as integers versus strings?


00:29:59.000 --> 00:30:02.280
- Yeah, so stepping back a little bit,


00:30:02.280 --> 00:30:03.720
how does this new interpreter work?


00:30:03.720 --> 00:30:11.720
So the big change, the headline is that the bytecode instructions


00:30:11.720 --> 00:30:14.240
can change themselves while they're running.


00:30:14.240 --> 00:30:17.880
So something that used to be a generic add operation


00:30:17.880 --> 00:30:22.920
can become something that is specialized, which is kind of--


00:30:22.920 --> 00:30:25.200
it's a specialized instruction is the terminology


00:30:25.200 --> 00:30:29.960
we use for adding two integers or adding two floats.


00:30:29.960 --> 00:30:35.120
And so this happens sort of in a couple different phases.


00:30:35.120 --> 00:30:39.440
After you've run your code for some amount of time,


00:30:39.440 --> 00:30:41.320
basically, after we've determined


00:30:41.320 --> 00:30:44.000
it's worth optimizing, because optimization isn't free,


00:30:44.000 --> 00:30:46.240
so some things only run once.


00:30:46.240 --> 00:30:48.400
It's module-level code or a class body.


00:30:48.400 --> 00:30:54.000
There's no reason to optimize that at all for later runs.


00:30:54.000 --> 00:30:58.960
And so we have heuristics for, OK, this code is warm.


00:30:58.960 --> 00:31:01.420
And that's a term that you hear in JITs often,


00:31:01.420 --> 00:31:05.720
because JITs have even higher overhead for specializing.


00:31:05.720 --> 00:31:09.760
And so basically, after we've determined


00:31:09.760 --> 00:31:13.000
that a block of code is warm, we quicken it,


00:31:13.000 --> 00:31:16.360
which is that term that you used earlier.


00:31:16.360 --> 00:31:19.440
And this basically means walking over the bytecode instructions


00:31:19.440 --> 00:31:26.040
and replacing many of them with what we call adaptive variants.


00:31:26.040 --> 00:31:28.640
And you can see an example in the PEP,


00:31:28.640 --> 00:31:30.720
But to walk through that example,


00:31:30.720 --> 00:31:34.400
if you have an attribute load, once the code is quickened,


00:31:34.400 --> 00:31:36.080
after we've determined it's warm,


00:31:36.080 --> 00:31:37.460
we walk over all the instructions.


00:31:37.460 --> 00:31:40.320
And all of the load attribute bytecode instructions


00:31:40.320 --> 00:31:43.840
become load adder adaptive.


00:31:43.840 --> 00:31:46.040
And what those adaptive instructions do


00:31:46.040 --> 00:31:48.840
is when we hit them, when we're actually


00:31:48.840 --> 00:31:52.600
doing the attribute load, in addition to actually loading


00:31:52.600 --> 00:31:56.600
the attribute, they will do some fact finding.


00:31:56.600 --> 00:31:58.200
they'll gather some information and say,


00:31:58.200 --> 00:31:59.880
OK, I loaded the attribute.


00:31:59.880 --> 00:32:01.000
Did it come from a class?


00:32:01.000 --> 00:32:02.080
Did it come from the instance?


00:32:02.080 --> 00:32:03.080
Did it come from a slot?


00:32:03.080 --> 00:32:04.200
Did it come from a dict?


00:32:04.200 --> 00:32:06.080
Did it come from a module?


00:32:06.080 --> 00:32:09.720
There's a bunch of different possibilities.


00:32:09.720 --> 00:32:14.720
And so using that information, the adaptive instruction


00:32:14.720 --> 00:32:17.800
can turn itself into one of the specialized instructions.


00:32:17.800 --> 00:32:19.840
So the example you have here on the screen,


00:32:19.840 --> 00:32:22.440
it can either be load at or instance value or module


00:32:22.440 --> 00:32:25.040
or slot.


00:32:25.040 --> 00:32:28.680
And what the specialized instructions do is really cool.


00:32:28.680 --> 00:32:31.600
Basically, they start with a couple of checks


00:32:31.600 --> 00:32:36.560
just to make sure that the assumptions are holding true.


00:32:36.560 --> 00:32:39.040
So for a load adder instance value,


00:32:39.040 --> 00:32:43.960
we check and make sure that, for example, the class


00:32:43.960 --> 00:32:47.560
of the object is as we expect, that our attribute isn't


00:32:47.560 --> 00:32:50.440
shadowed by a descriptor or something weird like that,


00:32:50.440 --> 00:32:53.120
or that we're not now getting it off of a class object


00:32:53.120 --> 00:32:55.720
or whatever.


00:32:55.720 --> 00:32:58.720
And then it has a very optimized form


00:32:58.720 --> 00:33:01.200
of getting the actual attribute.


00:33:01.200 --> 00:33:04.280
There's a lot of expensive work that you


00:33:04.280 --> 00:33:08.600
can skip if you know that you have an attribute that


00:33:08.600 --> 00:33:12.360
is coming directly off of the instance itself.


00:33:12.360 --> 00:33:16.320
>> Right, or another one is load at or slot.


00:33:16.320 --> 00:33:19.880
Slots are really interesting for Python performance.


00:33:19.880 --> 00:33:23.760
and they kind of capture more than a lot of the stuff,


00:33:23.760 --> 00:33:28.760
the difference of the possible and the common.


00:33:28.760 --> 00:33:32.200
And by that I mean, it's possible that every time


00:33:32.200 --> 00:33:35.340
you access a field off of a class,


00:33:35.340 --> 00:33:36.880
that it was dynamically added


00:33:36.880 --> 00:33:38.640
and it came from somewhere else and it's totally new


00:33:38.640 --> 00:33:40.400
and it could be any type.


00:33:40.400 --> 00:33:42.640
What's more likely though, is it's,


00:33:42.640 --> 00:33:44.460
the customer always has a name


00:33:44.460 --> 00:33:46.560
and the name is always a string, right?


00:33:46.560 --> 00:33:49.040
And with slots, you can sort of say,


00:33:49.040 --> 00:33:52.800
I don't want this particular class to be dynamic.


00:33:52.800 --> 00:33:54.320
And because of that, you can say,


00:33:54.320 --> 00:33:55.780
well, it doesn't need to have a dictionary


00:33:55.780 --> 00:33:57.280
that can evolve dynamically,


00:33:57.280 --> 00:33:59.480
which improves the access speed


00:33:59.480 --> 00:34:02.340
and the storage and all of that.


00:34:02.340 --> 00:34:04.960
And here you all are pointing out that,


00:34:04.960 --> 00:34:07.440
well, we could actually have a special op code


00:34:07.440 --> 00:34:11.500
that knows whenever I access X, X is a slot thing,


00:34:11.500 --> 00:34:13.920
skip all the other checks you might have to do


00:34:13.920 --> 00:34:15.680
before you get there.


00:34:15.680 --> 00:34:18.000
- Well, yeah, and even accessing the slot


00:34:18.000 --> 00:34:20.000
is going to be faster.


00:34:20.000 --> 00:34:24.160
So I'm not 100% brushed up on how load adder slot works,


00:34:24.160 --> 00:34:27.080
but I mean, the slots are implemented using descriptors.


00:34:27.080 --> 00:34:30.880
So to get the slot from your class,


00:34:30.880 --> 00:34:32.280
you still, or from your instance,


00:34:32.280 --> 00:34:34.040
you still need to go to the class,


00:34:34.040 --> 00:34:36.560
look up the attribute in the class dict,


00:34:36.560 --> 00:34:38.720
find the descriptor, verify it's a descriptor,


00:34:38.720 --> 00:34:39.560
all the descriptor. - Figure out it's offset


00:34:39.560 --> 00:34:41.560
into that list, yeah.


00:34:41.560 --> 00:34:42.400
- Exactly.


00:34:42.400 --> 00:34:45.480
We can do it even faster than that.


00:34:45.480 --> 00:34:47.600
So even if you do have slots,


00:34:47.600 --> 00:34:52.400
this happens really fast without even any dictionary lookups,


00:34:52.400 --> 00:34:52.920
I believe.


00:34:52.920 --> 00:34:55.320
We say, has the class changed?


00:34:55.320 --> 00:34:56.320
No.


00:34:56.320 --> 00:34:58.560
OK, cool.


00:34:58.560 --> 00:35:01.400
We'll get to this later, but we remember


00:35:01.400 --> 00:35:04.240
what offset the slot was at last time,


00:35:04.240 --> 00:35:06.600
and we just reach directly into the object and grab it.


00:35:06.600 --> 00:35:08.520
There's no dictionary lookups.


00:35:08.520 --> 00:35:10.320
We're not calling any descriptors


00:35:10.320 --> 00:35:12.440
or doing anything like that.


00:35:12.440 --> 00:35:15.360
It's about as close to a compiled language


00:35:15.360 --> 00:35:17.480
as a dynamic language could be.


00:35:17.480 --> 00:35:18.480
- Yeah. - Just verify,


00:35:18.480 --> 00:35:19.920
class hasn't changed, okay, reach in,


00:35:19.920 --> 00:35:21.120
I remember where it was.


00:35:21.120 --> 00:35:25.400
- Very cool, and it's all work,


00:35:25.400 --> 00:35:26.720
you know, I tried to kind of line this up,


00:35:26.720 --> 00:35:28.800
saying the possible and the common.


00:35:28.800 --> 00:35:31.840
Most likely, your code is not changing,


00:35:31.840 --> 00:35:33.600
and when it's well-written,


00:35:33.600 --> 00:35:36.240
it's probably using the same type.


00:35:36.240 --> 00:35:37.880
You know, it's not like, well, sometimes it's a string,


00:35:37.880 --> 00:35:40.360
and sometimes, like, that is the quote seven,


00:35:40.360 --> 00:35:42.320
and sometimes it's the actual integer seven.


00:35:42.320 --> 00:35:45.000
Like, it should probably always be one.


00:35:45.000 --> 00:35:49.320
You just don't express that in code unless you're using type ints, right?


00:35:49.320 --> 00:35:50.960
And they're not enforced.


00:35:50.960 --> 00:35:53.460
Yeah, and getting back to the adaptive nature


00:35:53.460 --> 00:35:56.060
and making sure that we are correct.


00:35:56.060 --> 00:35:59.300
If we had something that was a slotted instance


00:35:59.300 --> 00:36:02.800
coming through a bunch of times and then suddenly you throw a module in


00:36:02.800 --> 00:36:05.800
or something with an instance dictionary or something else,


00:36:05.800 --> 00:36:09.920
or maybe the attribute doesn't exist or it's a different type.


00:36:09.920 --> 00:36:14.320
Those quick checks that I mentioned that happened


00:36:14.320 --> 00:36:19.760
before we actually do the vast implementation of loading a slot.


00:36:19.760 --> 00:36:24.320
If any of those checks fail, then we basically


00:36:24.320 --> 00:36:26.680
fall back on the generic implementation.


00:36:26.680 --> 00:36:29.120
We say, oh, our assumptions don't hold.


00:36:29.120 --> 00:36:29.600
Go back.


00:36:29.600 --> 00:36:31.320
And if that happens enough times, then we


00:36:31.320 --> 00:36:33.360
go back to the adaptive form, and the whole cycle


00:36:33.360 --> 00:36:34.400
repeats itself.


00:36:34.400 --> 00:36:37.160
So if I'm throwing a bunch of integers


00:36:37.160 --> 00:36:41.200
into an add instruction, and then later I stop


00:36:41.200 --> 00:36:44.960
and I start throwing a bunch of strings into an ad instruction,


00:36:44.960 --> 00:36:47.040
we'll do the generic version of ad for a little bit


00:36:47.040 --> 00:36:48.520
while we're kind of switching over.


00:36:48.520 --> 00:36:50.920
But then the interpreter will kind of get the hint


00:36:50.920 --> 00:36:55.680
and start specializing for string addition later.


00:36:55.680 --> 00:36:58.880
And it's really cool to see that happen in practice.


00:36:58.880 --> 00:37:02.440
So we shouldn't-- we being Python developers that


00:37:02.440 --> 00:37:06.160
write code that just executes without thinking too very much


00:37:06.160 --> 00:37:08.320
about what that means--


00:37:08.320 --> 00:37:13.640
we should not have to worry or maybe even know that this is happening, right?


00:37:13.640 --> 00:37:18.600
If everything goes as it's supposed to, it should be completely transparent to us.


00:37:18.600 --> 00:37:23.160
- Yes, the only way that you should know that anything is different about 3.11


00:37:23.160 --> 00:37:30.640
is your CPU cycles, the cloud hosting bill at the end of the month.


00:37:30.640 --> 00:37:34.320
You should be able to upgrade and if behavior changes, that's a bug.


00:37:34.320 --> 00:37:36.240
Tell us about that.


00:37:36.240 --> 00:37:38.320
- Yeah, yeah, for sure.


00:37:38.320 --> 00:37:41.360
Well, going from this adaptive version,


00:37:41.360 --> 00:37:44.360
the adaptive instance sounds slightly more expensive


00:37:44.360 --> 00:37:48.760
than the just the old school load adder, for example,


00:37:48.760 --> 00:37:49.840
'cause it has to keep track


00:37:49.840 --> 00:37:52.800
and it does a little bit of inspecting


00:37:52.800 --> 00:37:54.240
to see what's going on.


00:37:54.240 --> 00:37:57.080
But then the new ones, once it gets adapted and quickened,


00:37:57.080 --> 00:37:58.560
it should be much faster.


00:37:58.560 --> 00:38:02.960
Is there a chance that it gets into some like weird loop


00:38:02.960 --> 00:38:06.640
where just about the time the adaptive one


00:38:06.640 --> 00:38:09.600
has decided to specialize it, it hits a case


00:38:09.600 --> 00:38:12.360
where it falls back and it ends up being slower


00:38:12.360 --> 00:38:14.680
rather than faster before?


00:38:14.680 --> 00:38:17.320
- Well, yeah, the worst case scenario would be


00:38:17.320 --> 00:38:22.320
you send the same type through n number of times


00:38:22.320 --> 00:38:25.720
and then right when it's gonna try to specialize you,


00:38:25.720 --> 00:38:27.000
send it through a different type.


00:38:27.000 --> 00:38:29.000
- Exactly, whatever, if n is the limit,


00:38:29.000 --> 00:38:31.040
like if it goes through n plus one times


00:38:31.040 --> 00:38:32.920
and then trips it back?


00:38:32.920 --> 00:38:33.420
Yeah.


00:38:33.420 --> 00:38:33.920
>> Yeah.


00:38:33.920 --> 00:38:36.320
Yeah, so that would be sort of the worst case scenario.


00:38:36.320 --> 00:38:38.960
But we have kind of ways of trying


00:38:38.960 --> 00:38:41.280
to avoid that, if at all possible.


00:38:41.280 --> 00:38:46.760
So for example, if we fail one of those checks,


00:38:46.760 --> 00:38:50.280
we don't immediately turn into the adaptive form.


00:38:50.280 --> 00:38:53.920
We will do it after that check has


00:38:53.920 --> 00:38:55.600
failed a certain number of times.


00:38:55.600 --> 00:38:58.440
And as just a concrete example, that number


00:38:58.440 --> 00:39:01.480
of times that we have hardcoded is a prime number.


00:39:01.480 --> 00:39:03.800
So it's less likely that you'll fall into these sort


00:39:03.800 --> 00:39:07.000
of patterns where it's like, oh, I send three ints through


00:39:07.000 --> 00:39:10.440
than a string, three ints than a string.


00:39:10.440 --> 00:39:13.480
It'd be hard to get that worst case behavior


00:39:13.480 --> 00:39:16.240
without being intentionally malicious.


00:39:16.240 --> 00:39:16.740
Sure.


00:39:16.740 --> 00:39:18.480
And on the long--


00:39:18.480 --> 00:39:20.520
also, by the way, we've got to keep in mind


00:39:20.520 --> 00:39:26.560
these are extremely small steps in our code.


00:39:26.560 --> 00:39:29.360
we might have multiple ones of these happening


00:39:29.360 --> 00:39:31.400
on a single line of what looks like,


00:39:31.400 --> 00:39:32.440
oh, there's one line of code,


00:39:32.440 --> 00:39:34.120
like, well, there's five,


00:39:34.120 --> 00:39:38.320
however many instructions,


00:39:38.320 --> 00:39:39.820
bytecode instructions happening,


00:39:39.820 --> 00:39:41.520
and some of them may be specialized


00:39:41.520 --> 00:39:43.260
and some of them not, right?


00:39:43.260 --> 00:39:45.520
- Yeah, exactly, and so the overall effect


00:39:45.520 --> 00:39:47.200
definitely smooths out,


00:39:47.200 --> 00:39:49.780
where, sure, you may have a worst-case behavior


00:39:49.780 --> 00:39:52.280
at one or two or three individual bytecode instructions,


00:39:52.280 --> 00:39:53.900
but your typical function is gonna have


00:39:53.900 --> 00:39:55.400
much more than that,


00:39:55.400 --> 00:39:58.860
even a smallish function is going to have 20 or 30 instructions


00:39:58.860 --> 00:40:00.860
if it's doing anything real.


00:40:00.860 --> 00:40:04.840
Yeah, if you care about its performance, it'll be doing a lot there.


00:40:04.840 --> 00:40:08.060
Exactly, and so some will specialize successfully, some won't,


00:40:08.060 --> 00:40:11.800
but in general, your code will get 25-ish percent faster.


00:40:11.800 --> 00:40:13.800
Is there a way you could know?


00:40:13.800 --> 00:40:16.940
Is there a way that you might be able to know if it's specialized or not?


00:40:16.940 --> 00:40:18.940
We'll get to that.


00:40:18.940 --> 00:40:23.940
It looks like if I go and use the DIS module,


00:40:23.940 --> 00:40:29.100
DIS, not for disrespect, but for disassembly.


00:40:29.100 --> 00:40:31.700
So you can say, import this,


00:40:31.700 --> 00:40:34.780
and then maybe from DIS, import this.


00:40:34.780 --> 00:40:36.660
You say DIS and give it a function or something,


00:40:36.660 --> 00:40:40.100
and it'll write out the bytecode of what's happening.


00:40:40.100 --> 00:40:43.100
Does all of this mean that if I do this in 3.11,


00:40:43.100 --> 00:40:48.100
I might see additional bytecodes than before?


00:40:48.620 --> 00:40:52.620
Instead of loadAdder, would I maybe see the loadAdder instance value?


00:40:52.620 --> 00:40:56.020
Will I actually be able to observe these specializations?


00:40:56.020 --> 00:41:01.720
Yeah, so if you pass a keyword argument to your disutilities,


00:41:01.720 --> 00:41:03.720
then yes, you will be able to see this.


00:41:03.720 --> 00:41:06.820
Okay, but if I don't, for compatibility reasons,


00:41:06.820 --> 00:41:10.320
like loadAdderAdaptive and loadAdderInstance,


00:41:10.320 --> 00:41:12.320
those are just going to return as loadAdder?


00:41:12.320 --> 00:41:14.320
LoadAdder, exactly.


00:41:14.320 --> 00:41:17.820
So the idea is anyone that's currently consuming the bytecode,


00:41:17.820 --> 00:41:19.820
they shouldn't have to worry about specializations


00:41:19.820 --> 00:41:22.320
because the idea is they're totally transparent.


00:41:22.320 --> 00:41:26.920
So they should only see what the original bytecode was.


00:41:26.920 --> 00:41:29.180
But if you want to get at it, then yeah.


00:41:29.180 --> 00:41:31.900
If any of the disutilities you can pass in,


00:41:31.900 --> 00:41:33.500
adaptive equals true.


00:41:33.500 --> 00:41:37.900
And that will show you these adaptive instructions.


00:41:37.900 --> 00:41:41.260
And again, you'll only see them if it's actually


00:41:41.260 --> 00:41:44.700
gets quickened, meaning if you run it a dozen times or so.


00:41:44.700 --> 00:41:47.380
- Okay, so if I wrote, say, a function,


00:41:47.380 --> 00:41:49.700
so often what you're doing if you're playing with dis,


00:41:49.700 --> 00:41:51.380
is like you write the function,


00:41:51.380 --> 00:41:55.940
and then you immediately print out the dis output.


00:41:55.940 --> 00:41:58.060
Maybe you've never called it, right?


00:41:58.060 --> 00:41:58.900
- Yeah.


00:41:58.900 --> 00:42:00.620
- And so that might actually give you a different,


00:42:00.620 --> 00:42:04.320
even if you said yes to the specialization output,


00:42:04.320 --> 00:42:06.900
that still might not give you anything interesting.


00:42:06.900 --> 00:42:08.820
- It won't give you, yeah, it'll just give you


00:42:08.820 --> 00:42:10.380
as if you hadn't passed the keyword argument.


00:42:10.380 --> 00:42:12.060
'Cause again, this all happens at runtime,


00:42:12.060 --> 00:42:14.060
So if the code isn't being run, nothing happens.


00:42:14.060 --> 00:42:18.560
You know, we don't specialize code that isn't ever run.


00:42:18.560 --> 00:42:20.560
What counts as warm?


00:42:20.560 --> 00:42:22.560
How many times do I got to call it?


00:42:22.560 --> 00:42:27.560
The official answer is that's an implementation detail of the interpreter,


00:42:27.560 --> 00:42:29.560
subject to change at any time.


00:42:29.560 --> 00:42:35.560
The actual answer is either 8 calls or 8 times through a loop in the function.


00:42:35.560 --> 00:42:39.560
So if your function has a loop that executes more than 8 times,


00:42:39.560 --> 00:42:41.560
or if you call it more than 8 times.


00:42:41.560 --> 00:42:45.560
just calling your function eight times should be enough to quicken it.


00:42:45.560 --> 00:42:49.560
Right, well, maybe that number changes in the future, but just having to say


00:42:49.560 --> 00:42:53.560
like, is it 10 or is it 10,000? You know what I mean?


00:42:53.560 --> 00:42:57.560
Where is the scale before I see something?


00:42:57.560 --> 00:43:01.560
Yeah, if you want to make sure it's quickened but you don't want to take up too much time, I'd say just run it a couple dozen times.


00:43:01.560 --> 00:43:05.560
As shorthand, when we're writing tests and stuff, we do like 100 or 1000.


00:43:05.560 --> 00:43:07.560
Okay.


00:43:07.560 --> 00:43:13.160
>> Because that also gives it time to actually adapt to the actual data that you're sending


00:43:13.160 --> 00:43:14.160
through it.


00:43:14.160 --> 00:43:16.240
Because it's not enough to just quicken it, then you'll just have a bunch of adaptive


00:43:16.240 --> 00:43:17.240
instructions.


00:43:17.240 --> 00:43:18.240
They actually have to see something.


00:43:18.240 --> 00:43:20.240
>> Yes, well, now we're paying attention, like great.


00:43:20.240 --> 00:43:23.240
Now it's time to pay attention too, right?


00:43:23.240 --> 00:43:28.400
>> Yeah, and you'll see that too, because if you have any sort of logic flow inside


00:43:28.400 --> 00:43:33.200
of your function, when you're looking at the bytecode, any paths that are hit will be specialized,


00:43:33.200 --> 00:43:35.840
and any paths that aren't obviously won't


00:43:35.840 --> 00:43:38.020
because we don't specialize that code.


00:43:38.020 --> 00:43:41.260
- So it has a bit of a code coverage aspect.


00:43:41.260 --> 00:43:43.440
- I did think about it.


00:43:43.440 --> 00:43:45.600
- If you look at it, you might see part of your code


00:43:45.600 --> 00:43:47.400
and it's just, it's unmodified


00:43:47.400 --> 00:43:49.000
because whatever you're doing to it


00:43:49.000 --> 00:43:51.920
didn't hit this else case ever.


00:43:51.920 --> 00:43:53.020
So.


00:43:53.020 --> 00:43:54.760
- Yeah, well, and that's what's really exciting


00:43:54.760 --> 00:43:56.240
about this too is when you're,


00:43:56.240 --> 00:43:58.660
if you run your code a bunch of times


00:43:58.660 --> 00:44:00.440
and then you call this on it,


00:44:01.480 --> 00:44:05.360
you see a lot of information that would potentially be useful


00:44:05.360 --> 00:44:08.080
if you were, for example, JIT compiling that function.


00:44:08.080 --> 00:44:13.080
You see at every addition site if you're adding floats or ints.


00:44:13.080 --> 00:44:16.080
You see at every attribute load site, whether it's a slot or not.


00:44:16.080 --> 00:44:18.680
You see where the dead code is, you see where the hot code is.


00:44:18.680 --> 00:44:22.840
All that stuff is getting back to what I said,


00:44:22.840 --> 00:44:25.880
how this enables us to build upon it in the future.


00:44:25.880 --> 00:44:30.240
Not only can we add more specializations or specialize more opcodes


00:44:30.240 --> 00:44:35.000
or do that more efficiently, we can also use that information


00:44:35.000 --> 00:44:38.800
to infer additional properties about the code that


00:44:38.800 --> 00:44:45.560
are useful for other, faster, lowered representations


00:44:45.560 --> 00:44:46.440
of the code.


00:44:46.440 --> 00:44:47.640
>>Luis: OK.


00:44:47.640 --> 00:44:50.720
Yeah, I can certainly see how that might inform some kind


00:44:50.720 --> 00:44:53.040
of JIT engine in the future.


00:44:53.040 --> 00:44:54.360
>>Jeremy: Yeah.


00:44:54.360 --> 00:44:56.640
>>Luis: Out in the audience, I don't know how much Julia


00:44:56.640 --> 00:44:59.360
you know, but there's a question that says,


00:44:59.360 --> 00:45:01.000
- This sounds similar to Julia.


00:45:01.000 --> 00:45:03.520
I have no idea whether it does or not.


00:45:03.520 --> 00:45:06.000
- There is a good chance it could be similar to Julia.


00:45:06.000 --> 00:45:07.960
I'm not sure, but now I'm gonna look it up


00:45:07.960 --> 00:45:08.800
'cause I'm curious.


00:45:08.800 --> 00:45:10.400
- Now you gotta know.


00:45:10.400 --> 00:45:12.720
- Yeah, maybe we can steal some from them, who knows?


00:45:12.720 --> 00:45:15.320
- Yeah, exactly, oh, they did do that one thing here.


00:45:15.320 --> 00:45:20.700
So I think the pep is interesting, the pep 659,


00:45:20.700 --> 00:45:22.160
people can check that out, but like you said,


00:45:22.160 --> 00:45:23.920
it's informational, so it's not really


00:45:23.920 --> 00:45:26.440
the implementation exactly.


00:45:26.440 --> 00:45:27.280
- Yeah.


00:45:27.280 --> 00:45:31.360
So let's talk a bit about your project


00:45:31.360 --> 00:45:35.320
that you did in addition to just being on the team.


00:45:35.320 --> 00:45:37.560
It's a personal project that you did


00:45:37.560 --> 00:45:39.680
that basically takes all of these ideas


00:45:39.680 --> 00:45:43.640
we've been talking about and says, well, two things.


00:45:43.640 --> 00:45:47.520
One, can I take code and look at that and get that answer?


00:45:47.520 --> 00:45:49.520
Again, kind of back to my code coverage example,


00:45:49.520 --> 00:45:52.480
like coloring code lines to mean stuff.


00:45:52.480 --> 00:45:54.680
And then what's interesting about this,


00:45:54.680 --> 00:45:56.880
and we'll talk through this example that you put up,


00:45:56.880 --> 00:45:59.380
is there's actionable stuff you could do


00:45:59.380 --> 00:46:00.580
to make your code faster


00:46:00.580 --> 00:46:02.920
if you were in a super tight loop section.


00:46:02.920 --> 00:46:06.100
Like I feel like applying this visualization


00:46:06.100 --> 00:46:10.440
could help you allow Python to specialize more


00:46:10.440 --> 00:46:12.140
rather than less.


00:46:12.140 --> 00:46:14.540
- Yeah, I mean, in general,


00:46:14.540 --> 00:46:17.540
this tool is really useful for us as maintainers


00:46:17.540 --> 00:46:20.020
of the specialization stuff


00:46:20.020 --> 00:46:24.220
because we get to see where we're failing to specialize.


00:46:24.220 --> 00:46:27.340
Because ideally, if we've done our job well,


00:46:27.340 --> 00:46:30.340
you should get faster Python without changing your code at all.


00:46:30.340 --> 00:46:35.180
So first and foremost, this is a tool for us in our work


00:46:35.180 --> 00:46:38.780
so that we can see, OK, what can we still work on here?


00:46:38.780 --> 00:46:41.980
But that is sort of a cool knock-on effect


00:46:41.980 --> 00:46:44.460
is that if you do run on your code, you also


00:46:44.460 --> 00:46:45.900
know where it's not specializing.


00:46:45.900 --> 00:46:48.680
And if you know enough about how specialization works,


00:46:48.680 --> 00:46:51.300
you may be able to fix that.


00:46:51.300 --> 00:46:57.060
But I would say a word of caution against getting two in the weeds


00:46:57.060 --> 00:46:59.380
and trying to get every single bytecode to do what you want


00:46:59.380 --> 00:47:04.700
because there are much better ways of making your code faster, I think.


00:47:04.700 --> 00:47:05.700
Yeah, absolutely.


00:47:05.700 --> 00:47:08.820
Well, but there are places where you're like,


00:47:08.820 --> 00:47:11.820
these two functions, I know we got 20,000 lines of Python,


00:47:11.820 --> 00:47:15.300
but these two, which are like 20 lines,


00:47:15.300 --> 00:47:18.220
they are so important and they happen so frequently.


00:47:18.220 --> 00:47:20.900
Anything you can do to make them faster matters.


00:47:20.900 --> 00:47:25.400
People rewrite that kind of stuff in Rust or in Cython.


00:47:25.400 --> 00:47:30.400
Before you go that far, maybe adding a dot zero


00:47:30.400 --> 00:47:32.660
on the end of a number is all it takes.


00:47:32.660 --> 00:47:33.500
Something like that, right?


00:47:33.500 --> 00:47:34.580
That's kind of what I'm getting at.


00:47:34.580 --> 00:47:36.860
Not to go crazy or try to think you should mess


00:47:36.860 --> 00:47:39.660
with the whole program, but there are these times


00:47:39.660 --> 00:47:43.100
where five lines matter a lot.


00:47:43.100 --> 00:47:44.900
- Yeah, sure.


00:47:44.900 --> 00:47:49.300
- Okay, well tell us about your project specialist.


00:47:50.140 --> 00:47:56.300
Yeah, so one really cool thing that our specializing


00:47:56.300 --> 00:47:59.980
adaptive interpreter does is we've


00:47:59.980 --> 00:48:04.140
worked really hard to basically make it easy for us


00:48:04.140 --> 00:48:06.460
to get information about how well specializations are


00:48:06.460 --> 00:48:07.860
working.


00:48:07.860 --> 00:48:09.940
So you can actually compile Python.


00:48:09.940 --> 00:48:12.980
It'll run a lot slower, but you can compile Python


00:48:12.980 --> 00:48:14.980
with this option with pystats.


00:48:14.980 --> 00:48:19.540
And that basically dumps all of the specialization stats.


00:48:19.540 --> 00:48:21.540
- Yeah, and you actually pointed out that you can,


00:48:21.540 --> 00:48:25.340
in the Faster CPython Ideas section,


00:48:25.340 --> 00:48:27.980
it lists out like a--


00:48:27.980 --> 00:48:29.100
- Yeah, so there's tons of counters.


00:48:29.100 --> 00:48:32.180
So you can see that when we run our benchmarks,


00:48:32.180 --> 00:48:35.140
load adder instance value is run, what, two billion times?


00:48:35.140 --> 00:48:36.340
Almost three billion times?


00:48:36.340 --> 00:48:41.140
And it misses its assumptions, 1% of those.


00:48:41.140 --> 00:48:42.900
Yeah, and so there's tons of these counters


00:48:42.900 --> 00:48:43.740
that you can dump.


00:48:43.740 --> 00:48:44.860
And that's really cool,


00:48:44.860 --> 00:48:46.940
'cause we can run our performance benchmarks


00:48:46.940 --> 00:48:49.060
and see how those numbers have changed,


00:48:49.060 --> 00:48:52.620
And even cooler than that, it allows us kind of separately


00:48:52.620 --> 00:48:54.340
to--


00:48:54.340 --> 00:48:56.540
for example, there's been at least one case


00:48:56.540 --> 00:48:58.500
where we've worked with a large company that


00:48:58.500 --> 00:49:00.940
has a big private internal app.


00:49:00.940 --> 00:49:03.340
And they can run it using Python 3.11.


00:49:03.340 --> 00:49:05.420
And we can get these stats without actually looking


00:49:05.420 --> 00:49:08.020
at the source code, which is really cool.


00:49:08.020 --> 00:49:08.820
And so we can see--


00:49:08.820 --> 00:49:10.180
>> We want to help you be faster.


00:49:10.180 --> 00:49:12.900
And we're working on the runtime, but we don't want to--


00:49:12.900 --> 00:49:14.180
>> But you don't want to show us your code.


00:49:14.180 --> 00:49:15.900
And so we're not going to look at it.


00:49:15.900 --> 00:49:17.740
>> You might not want to see it, yeah.


00:49:17.740 --> 00:49:20.620
And so those stats are really useful for knowing,


00:49:20.620 --> 00:49:26.340
OK, 90% of my attribute access were able to be specialized.


00:49:26.340 --> 00:49:27.580
What about that remaining 10%?


00:49:27.580 --> 00:49:29.380
Where are they?


00:49:29.380 --> 00:49:32.460
And then an additional question, why couldn't they


00:49:32.460 --> 00:49:33.540
be specialized?


00:49:33.540 --> 00:49:35.740
And that's something that's a lot easier to tell when


00:49:35.740 --> 00:49:37.660
you're looking at the code.


00:49:37.660 --> 00:49:39.860
And so this tool was basically--


00:49:39.860 --> 00:49:41.780
my original intention for writing it


00:49:41.780 --> 00:49:47.580
is once we get beyond seeing the stats for a benchmark,


00:49:47.580 --> 00:49:50.580
can we run something on it that makes it easy to tell at a glance


00:49:50.580 --> 00:49:54.160
where we're failing and how.


00:49:54.160 --> 00:49:56.920
Right, it's like saying that's 96% code coverage


00:49:56.920 --> 00:50:01.140
versus these two lines are the ones that are not getting covered.


00:50:01.140 --> 00:50:04.980
Exactly, you get a lot more information from actually getting those line numbers


00:50:04.980 --> 00:50:08.220
than from the 97% or whatever.


00:50:08.220 --> 00:50:11.820
Yeah, and so basically the way it works,


00:50:11.820 --> 00:50:15.560
we already talked about how in the DIS module,


00:50:15.560 --> 00:50:20.240
you can see which instructions are adaptive or specialized.


00:50:20.240 --> 00:50:24.320
And all that this tool does is it visualizes it for you.


00:50:24.320 --> 00:50:28.000
So literally, the implementation of this tool


00:50:28.000 --> 00:50:32.360
is just a for loop over this, where we just kind of


00:50:32.360 --> 00:50:34.080
categorize the different instructions


00:50:34.080 --> 00:50:36.840
and then map those to colors and all sorts of crazy nonsense.


00:50:36.840 --> 00:50:41.040
Yeah, and for people listening, imagine some code.


00:50:41.040 --> 00:50:45.960
And here you've got a for loop with the tuple decomposition.


00:50:45.960 --> 00:50:48.760
So you got for i,t in the numerator text


00:50:48.760 --> 00:50:50.360
that I go do some stuff.


00:50:50.360 --> 00:50:53.640
And it has the i and the t turned green,


00:50:53.640 --> 00:50:57.200
but then some dictionary access turned yellow.


00:50:57.200 --> 00:51:00.920
And it talks about, is it not at all specialized?


00:51:00.920 --> 00:51:04.960
Is it, did it try but fail to get specialized


00:51:04.960 --> 00:51:07.080
and things like that, right?


00:51:07.080 --> 00:51:07.900
- Yep, yeah.


00:51:07.900 --> 00:51:11.100
Green indicates successful specializations.


00:51:11.100 --> 00:51:17.340
Red are those adaptive instructions that are slightly slower and represent missed specializations.


00:51:17.340 --> 00:51:21.100
And yellow and orange are kind of a gradient.


00:51:21.100 --> 00:51:28.220
Because as we talked about, you know, one line of Python code can easily be 10 or 25 code instructions.


00:51:28.220 --> 00:51:34.860
So, you know, it's kind of a way of compressing that information into a visually pleasing form.


00:51:34.860 --> 00:51:38.140
And one thing I want to point out about this too is,


00:51:38.140 --> 00:51:43.140
you'll notice it's actually, you see characters within a line.


00:51:43.140 --> 00:51:46.340
And this is something that's really cool because this is piggybacking


00:51:46.340 --> 00:51:49.140
on a feature that's completely unrelated to specialization.


00:51:49.140 --> 00:51:54.140
Originally, when I was writing this, it highlighted each line.


00:51:54.140 --> 00:51:58.140
So you can see this line was kind of green, or this line was kind of yellow.


00:51:58.140 --> 00:52:02.140
But then I remembered, maybe you're familiar,


00:52:02.140 --> 00:52:07.300
In Python 3.11, we have really, really informative tracebacks


00:52:07.300 --> 00:52:09.940
where it will actually underline the part of the code


00:52:09.940 --> 00:52:14.660
that has a syntax error or that has an exception that was raised or something.


00:52:14.660 --> 00:52:20.500
Yeah, and so that's the pep that's linked first in the description there.


00:52:20.500 --> 00:52:26.540
It's called fine-grained error locate or fine-grained locations and tracebacks.


00:52:26.540 --> 00:52:27.040
Yeah.


00:52:27.040 --> 00:52:33.640
And so what that means is that previously we just had line number information in the bytecode,


00:52:33.640 --> 00:52:38.840
but now we have line number and end line number and start column and end column information,


00:52:38.840 --> 00:52:41.940
which means that due to this completely unrelated feature,


00:52:41.940 --> 00:52:48.440
we can now also map it directly to which characters in a source file correspond to individual bytecode instructions.


00:52:48.440 --> 00:52:49.440
That's super cool.


00:52:49.440 --> 00:52:49.640
Yeah.


00:52:49.640 --> 00:52:54.640
- Yeah, so for example, here we've got a string


00:52:54.640 --> 00:52:58.880
and you're accessing it by element, by passing an index,


00:52:58.880 --> 00:53:02.120
and you were able to highlight the square brackets


00:53:02.120 --> 00:53:05.480
as a separate classification on that array indexing


00:53:05.480 --> 00:53:07.880
or that string indexing.


00:53:07.880 --> 00:53:09.640
- Exactly, so it wouldn't have been as helpful


00:53:09.640 --> 00:53:13.480
to just see that that line was kind of yellow-orange-ish.


00:53:13.480 --> 00:53:15.520
You know, we see that the fast variable store


00:53:15.520 --> 00:53:17.160
was really, really quick.


00:53:18.520 --> 00:53:24.220
we see that the modulo operation


00:53:24.220 --> 00:53:27.760
and the indexing of string by int wasn't that fast.


00:53:27.760 --> 00:53:29.640
We weren't able to specialize it,


00:53:29.640 --> 00:53:36.440
but we were able to specialize the lookup of the name key,


00:53:36.440 --> 00:53:38.600
i, and len.


00:53:38.600 --> 00:53:41.360
Weren't able to specialize the function call of len on key.


00:53:41.360 --> 00:53:43.560
So that sort of information, that granularity,


00:53:43.560 --> 00:53:45.720
is really, really cool.


00:53:45.720 --> 00:53:47.000
>>Yeah, it is super cool.


00:53:47.000 --> 00:53:49.200
And I think a good way to go through this,


00:53:49.200 --> 00:53:52.700
you got some more background that you write about here,


00:53:52.700 --> 00:53:54.200
but we've already talked a lot about specializing.


00:53:54.200 --> 00:53:55.740
- Yeah, this is just summarizing the pet basically.


00:53:55.740 --> 00:53:56.580
- Yeah, exactly.


00:53:56.580 --> 00:53:59.460
People can check it out there if they want the TL,


00:53:59.460 --> 00:54:01.220
the too long didn't read version.


00:54:01.220 --> 00:54:03.940
But you've got this really nice example


00:54:03.940 --> 00:54:07.420
of what may be in the first few weeks


00:54:07.420 --> 00:54:10.900
of some kind of Python programming class.


00:54:10.900 --> 00:54:14.700
Write a program that converts Fahrenheit to Celsius


00:54:14.700 --> 00:54:16.820
and Celsius to Fahrenheit.


00:54:16.820 --> 00:54:20.540
and then just test that round tripping numbers


00:54:20.540 --> 00:54:23.380
gives you basically the same answer back


00:54:23.380 --> 00:54:25.780
within floating point variations, right?


00:54:25.780 --> 00:54:29.740
- Yeah, I really like this example because it,


00:54:29.740 --> 00:54:33.140
as we'll show it, it's kind of presented


00:54:33.140 --> 00:54:35.060
through the lens of performance optimization,


00:54:35.060 --> 00:54:37.700
but it also does a good job of showing you


00:54:37.700 --> 00:54:39.220
kind of how the interpreter works


00:54:39.220 --> 00:54:41.780
and how those little tweaks kind of cascade.


00:54:41.780 --> 00:54:43.940
- Absolutely.


00:54:44.780 --> 00:54:47.300
And it highlights certain things you can take advantage of


00:54:47.300 --> 00:54:50.660
that if you just slightly change the order,


00:54:50.660 --> 00:54:53.020
it actually has a different runtime behavior, which we


00:54:53.020 --> 00:54:54.980
don't often think about in Python.


00:54:54.980 --> 00:54:55.980
We were doing C++.


00:54:55.980 --> 00:54:59.140
We would maybe debate, do you dereference that pointer first,


00:54:59.140 --> 00:55:01.660
or can you do it in the loop?


00:55:01.660 --> 00:55:04.020
But not so much here.


00:55:04.020 --> 00:55:05.820
So let's go through--


00:55:05.820 --> 00:55:09.420
I mean, I guess just to remind people, Fahrenheit Celsius,


00:55:09.420 --> 00:55:12.980
you would say x equals f minus 32.


00:55:12.980 --> 00:55:16.500
And then you multiply the result once you've shifted the zero


00:55:16.500 --> 00:55:18.500
by 5 divided by 9.


00:55:18.500 --> 00:55:22.940
And the reverse is you multiply the Celsius by 9 divided by 5.


00:55:22.940 --> 00:55:25.140
And then you add the 32 to shift the zero again.


00:55:25.140 --> 00:55:27.180
And basically, that's all there is to it.


00:55:27.180 --> 00:55:28.720
And then you go through and say, well,


00:55:28.720 --> 00:55:32.700
let's run the specialist on it to get its output.


00:55:32.700 --> 00:55:36.540
And maybe talk about this first variation that we get here.


00:55:36.540 --> 00:55:38.700
>>Yeah, so as we were talking about,


00:55:38.700 --> 00:55:42.060
the red indicates there's adaptive instructions.


00:55:42.060 --> 00:55:45.340
and the green indicates the specialized instructions.


00:55:45.340 --> 00:55:48.060
So we can see here that some things were specialized very well.


00:55:48.060 --> 00:55:50.340
For instance, look at assertRoundTrip.


00:55:50.340 --> 00:55:52.340
That's bright green.


00:55:52.340 --> 00:55:54.860
Because it's in that hot loop,


00:55:54.860 --> 00:55:57.540
we got enough information about it to say,


00:55:57.540 --> 00:56:01.820
"Okay, assertRoundTrip is being loaded from the global namespace,


00:56:01.820 --> 00:56:06.700
and it's a Python function, so we can do that cool


00:56:06.700 --> 00:56:10.780
Python to Python call optimization."


00:56:10.780 --> 00:56:15.980
and that's basically as fast as any function call in Python is going to be.


00:56:15.980 --> 00:56:20.060
But some things aren't specialized.


00:56:20.060 --> 00:56:23.740
So the things that jump out, the things that we may want to actually


00:56:23.740 --> 00:56:28.900
take a closer look at would be the math, which is yellow and red.


00:56:28.900 --> 00:56:33.540
So, for instance, we can...


00:56:33.540 --> 00:56:38.060
the loads of the local variable f in that first function


00:56:38.060 --> 00:56:41.740
and the load of the constant 32.


00:56:41.740 --> 00:56:44.260
Those are yellow because the math


00:56:44.260 --> 00:56:46.420
that they're involved in, the subtraction operation,


00:56:46.420 --> 00:56:47.420
wasn't specialized.


00:56:47.420 --> 00:56:49.380
But the individual loads of those instructions


00:56:49.380 --> 00:56:50.700
were specialized.


00:56:50.700 --> 00:56:51.220
I see.


00:56:51.220 --> 00:56:53.460
So half yes, half no for what they were involved in.


00:56:53.460 --> 00:56:54.660
Yeah.


00:56:54.660 --> 00:56:57.620
Green plus red equals yellow.


00:56:57.620 --> 00:56:58.100
So yeah.


00:56:58.100 --> 00:57:00.220
So that subtraction wasn't specialized.


00:57:00.220 --> 00:57:04.620
And the reason is in 3.11, just based on the heuristics


00:57:04.620 --> 00:57:07.700
that we gathered, we determined it was worth it,


00:57:07.700 --> 00:57:10.920
at least for the time being, to optimize int plus int


00:57:10.920 --> 00:57:15.620
and float plus float, but not int plus float or float plus int.


00:57:15.620 --> 00:57:18.620
And so what we're doing here is we're subtracting


00:57:18.620 --> 00:57:21.580
a float and an int.


00:57:21.580 --> 00:57:26.460
And so we're able to see that that isn't specializable.


00:57:26.460 --> 00:57:30.220
But if we were to somehow change that so that it was two floats


00:57:30.220 --> 00:57:32.740
or two ints, then it would be specializable.


00:57:32.740 --> 00:57:33.500
Right.


00:57:33.500 --> 00:57:34.620
Because when I look at it, it looks


00:57:34.620 --> 00:57:36.660
like it absolutely should have been specialized.


00:57:36.660 --> 00:57:40.660
a float minus an int, the int is even a constant.


00:57:40.660 --> 00:57:44.660
Like you're, okay, well this is


00:57:44.660 --> 00:57:48.660
standard math, and it's always a float, and it's always an int, and it's always


00:57:48.660 --> 00:57:52.660
subtraction. It seems like that should just, well, the math


00:57:52.660 --> 00:57:56.660
should be obvious and fast. But because, as you pointed


00:57:56.660 --> 00:58:00.660
out, there's this peculiarity or maybe an implementation detail


00:58:00.660 --> 00:58:04.660
for the moment. - Absolutely an implementation detail. - Yeah, yeah, yeah. So, if it's


00:58:04.660 --> 00:58:05.900
It's an int and a float.


00:58:05.900 --> 00:58:09.020
Well, right now that problem is not solved.


00:58:09.020 --> 00:58:10.660
Maybe it will be in the future, right?


00:58:10.660 --> 00:58:12.700
It seems like pretty low-hanging fruit, but--


00:58:12.700 --> 00:58:13.980
Well, specializations aren't--


00:58:13.980 --> 00:58:14.980
--all the variations, right?


00:58:14.980 --> 00:58:16.460
Yeah, specializations aren't free.


00:58:16.460 --> 00:58:20.980
So for instance, when we're running


00:58:20.980 --> 00:58:22.700
those adaptive instructions, we need


00:58:22.700 --> 00:58:24.460
to check for all of the different possible


00:58:24.460 --> 00:58:25.540
specializations.


00:58:25.540 --> 00:58:27.620
So every time we add a new specialization,


00:58:27.620 --> 00:58:30.340
that has some cost.


00:58:30.340 --> 00:58:33.120
And basically, we determined, at least for the time being,


00:58:33.120 --> 00:58:37.120
Like I said, we've tried to do int plus float and float plus int.


00:58:37.120 --> 00:58:40.760
And at least based on the benchmarks that we have


00:58:40.760 --> 00:58:43.760
and the code that we've seen, it just isn't worth it.


00:58:43.760 --> 00:58:46.300
- Sure, okay. - Yeah.


00:58:46.300 --> 00:58:49.180
- Yeah. - And it's something like int plus int


00:58:49.180 --> 00:58:51.540
is very easy to do quickly.


00:58:51.540 --> 00:58:53.220
Float plus float is very easy to do quickly.


00:58:53.220 --> 00:58:56.660
Int plus float, there's some coercion that needs to happen there.


00:58:56.660 --> 00:59:01.380
- Right, there's already cost in there. - So yeah, it's not something that...


00:59:01.380 --> 00:59:04.380
It's something that costs some time to check,


00:59:04.380 --> 00:59:08.880
but we don't have a significantly faster way of doing it.


00:59:08.880 --> 00:59:13.880
[SIDE CONVERSATION]


00:59:13.880 --> 00:59:18.880
[SIDE CONVERSATION]


00:59:18.880 --> 00:59:23.880
[SIDE CONVERSATION]


00:59:23.880 --> 00:59:28.880
[SIDE CONVERSATION]


00:59:28.880 --> 00:59:32.320
and anyway, how about make it 32.0 instead of 32?


00:59:32.320 --> 00:59:33.320
>> Yep.


00:59:33.320 --> 00:59:35.320
>> And then bam, that whole line turns green, right?


00:59:35.320 --> 00:59:36.820
>> Yep.


00:59:36.820 --> 00:59:40.240
Yeah, so now you're basically doing that entire line


00:59:40.240 --> 00:59:42.160
using fast local variables


00:59:42.160 --> 00:59:45.440
and native floating point operations.


00:59:45.440 --> 00:59:48.000
You're just adding literally two C doubles together,


00:59:48.000 --> 00:59:50.000
which is really cool.


00:59:50.000 --> 00:59:51.520
>> Yeah, and this is what I was talking about,


00:59:51.520 --> 00:59:53.920
where you could look at that line and go,


00:59:53.920 --> 00:59:57.360
"Oh, well, I just wrote the integer 32,


00:59:57.360 --> 00:59:59.320
but I'm doing floating point math.


00:59:59.320 --> 01:00:00.920
It's not like I'm doing integer math.


01:00:00.920 --> 01:00:02.280
So if you just put, you know,


01:00:02.280 --> 01:00:06.040
write it as a constant with a zero, you know, dot zero on it


01:00:06.040 --> 01:00:09.020
that's a pretty low effort change.


01:00:09.020 --> 01:00:10.400
And here you go,


01:00:10.400 --> 01:00:13.280
Python can help you more and go faster, right?


01:00:13.280 --> 01:00:15.000
- Yeah, and that's not a transformation


01:00:15.000 --> 01:00:15.920
that we can do for you


01:00:15.920 --> 01:00:18.600
because if F is an instance of some user class


01:00:18.600 --> 01:00:20.420
that defines dunder sub,


01:00:20.420 --> 01:00:22.600
that would be a visible change


01:00:22.600 --> 01:00:24.840
if it started receiving a float


01:00:24.840 --> 01:00:26.560
as a right-hand argument instead of an int.


01:00:26.560 --> 01:00:28.800
So those are things that we can't do


01:00:28.800 --> 01:00:31.360
while making the language still the same.


01:00:31.360 --> 01:00:34.060
- Right, but your specialist tool can show you.


01:00:34.060 --> 01:00:39.080
And again, figure out where your code is slow


01:00:39.080 --> 01:00:41.680
and then consider whether, don't just like,


01:00:41.680 --> 01:00:44.280
well, we only got 100,000 lines,


01:00:44.280 --> 01:00:47.040
who's assigned to specializing today?


01:00:47.040 --> 01:00:50.240
- Yeah, and it also requires, this is a simpler example,


01:00:50.240 --> 01:00:54.360
but it does require a somewhat deep knowledge


01:00:54.360 --> 01:00:56.400
of how the specializations work.


01:00:56.400 --> 01:00:58.760
because for things other than binary operations,


01:00:58.760 --> 01:01:01.480
it's not going to become clear what the fix is.


01:01:01.480 --> 01:01:03.600
You just see kind of where the--


01:01:03.600 --> 01:01:05.200
I hesitate to even call it a problem,


01:01:05.200 --> 01:01:07.600
but you see where there's the potential for improvement,


01:01:07.600 --> 01:01:10.080
but not necessarily how to improve it.


01:01:10.080 --> 01:01:10.600
Yeah.


01:01:10.600 --> 01:01:12.240
And then you have another one in here


01:01:12.240 --> 01:01:13.960
that's, I think, really interesting,


01:01:13.960 --> 01:01:17.480
because so often when we're talking about math,


01:01:17.480 --> 01:01:21.600
and at least commutative operations,


01:01:21.600 --> 01:01:23.440
it doesn't matter which order you do them in.


01:01:23.440 --> 01:01:25.880
Like 5 times 7 times 3.


01:01:25.880 --> 01:01:27.640
If it's the first two and then the result,


01:01:27.640 --> 01:01:30.080
or you multiply the last two, and unless there's


01:01:30.080 --> 01:01:32.480
some weird floating point edge case


01:01:32.480 --> 01:01:37.840
that the IEEE representation goes haywire, it doesn't matter.


01:01:37.840 --> 01:01:40.120
And so for example, here you've got--


01:01:40.120 --> 01:01:43.040
to finish off the Fahrenheit to Celsius conversion,


01:01:43.040 --> 01:01:46.840
it's the x times 5 divided by 9.


01:01:46.840 --> 01:01:49.440
And that one is busted too for the same reason,


01:01:49.440 --> 01:01:51.000
because it's a 5.


01:01:51.000 --> 01:01:54.640
Yeah, because-- so this is kind of for two reasons.


01:01:54.640 --> 01:01:57.960
this line isn't as good as it could be under ideal conditions.


01:01:57.960 --> 01:02:01.760
So, you know, x is a floating point number, 5 is an integer,


01:02:01.760 --> 01:02:02.960
so we have the same problem.


01:02:02.960 --> 01:02:06.800
We specialize multiplication for int and int and float and float,


01:02:06.800 --> 01:02:08.920
but not for int and float.


01:02:08.920 --> 01:02:11.480
And the division is even a different problem.


01:02:11.480 --> 01:02:14.760
We don't try to specialize division at all,


01:02:14.760 --> 01:02:16.800
just for the reason that it's kind of problematic,


01:02:16.800 --> 01:02:18.600
because the right-hand side could be a zero,


01:02:18.600 --> 01:02:19.800
and then you have to check for that,


01:02:19.800 --> 01:02:25.960
and there's all sorts of things that you need to check for


01:02:25.960 --> 01:02:27.800
that make it not as much of a payoff.


01:02:27.800 --> 01:02:33.680
So we have both an operation that we can specialize,


01:02:33.680 --> 01:02:36.200
but it isn't being specialized, and then another one


01:02:36.200 --> 01:02:38.240
that we're not even trying to specialize at all.


01:02:38.240 --> 01:02:40.480
Right, right, right.


01:02:40.480 --> 01:02:42.160
But then back to the commutative thing,


01:02:42.160 --> 01:02:45.760
you're like, well, what if we did the division?


01:02:45.760 --> 01:02:48.280
What if we did the division like parentheses


01:02:48.280 --> 01:02:52.560
five divided by nine, and then x times that, right?


01:02:52.560 --> 01:02:55.760
- Yep, and so, waiting through more


01:02:55.760 --> 01:02:57.520
of these implementation details,


01:02:57.520 --> 01:03:00.440
Python's compiler, we have a bytecode compiler,


01:03:00.440 --> 01:03:02.000
it's not compiling to machine code,


01:03:02.000 --> 01:03:04.760
but it can perform simple optimizations like this.


01:03:04.760 --> 01:03:08.680
So by changing the order of operations,


01:03:08.680 --> 01:03:12.160
the bytecode compiler sees, oh, five divided by nine,


01:03:12.160 --> 01:03:13.760
I can do that at compile time once,


01:03:13.760 --> 01:03:16.040
rather than at runtime, literally every time


01:03:16.040 --> 01:03:19.240
through the loop, 'cause that's never going to change.


01:03:19.240 --> 01:03:20.080
And so by changing that--


01:03:20.080 --> 01:03:21.960
- Regardless of specialization, yeah, sorry,


01:03:21.960 --> 01:03:25.040
regardless of specialization, that's better anyway, right?


01:03:25.040 --> 01:03:28.480
'Cause that happens when the PYC file is generated


01:03:28.480 --> 01:03:31.760
or when the equivalent thing in memory is generated,


01:03:31.760 --> 01:03:35.520
and then it's just known as a constant, right?


01:03:35.520 --> 01:03:37.560
- Yeah, and you're doing no division of runtime anymore.


01:03:37.560 --> 01:03:39.800
So you turn this from two operations,


01:03:39.800 --> 01:03:43.040
one of which is pretty expensive, to just one operation.


01:03:44.640 --> 01:03:47.140
all you're doing is a multiply by a constant now.


01:03:47.140 --> 01:03:50.520
And so you can see that once we apply


01:03:50.520 --> 01:03:52.400
that transformation to our code,


01:03:52.400 --> 01:03:54.840
everything's all bright green and happy now in there.


01:03:54.840 --> 01:03:57.640
This is as specialized as it can be.


01:03:57.640 --> 01:04:00.000
- Right, because in Python 3,


01:04:00.000 --> 01:04:04.080
five divided by nine is a floating point, right?


01:04:04.080 --> 01:04:06.560
Doesn't modulo it out or whatever.


01:04:06.560 --> 01:04:10.480
Yeah, so then it becomes float times float,


01:04:10.480 --> 01:04:13.400
which then can be specialized in that first division part


01:04:13.400 --> 01:04:16.240
is something that is done at runtime,


01:04:16.240 --> 01:04:17.800
when it first runs, but only once,


01:04:17.800 --> 01:04:20.400
which is fantastic, like parse time, basically.


01:04:20.400 --> 01:04:24.680
So yeah, this function, or these functions,


01:04:24.680 --> 01:04:28.600
this code is much better as a result of understanding.


01:04:28.600 --> 01:04:30.280
- Yeah, and this transformation isn't something


01:04:30.280 --> 01:04:31.400
that Python can do for you,


01:04:31.400 --> 01:04:34.120
'cause it changes the semantics of the language.


01:04:34.120 --> 01:04:36.240
Again, if X is some user object,


01:04:36.240 --> 01:04:39.320
then it can observe the types that are being passed to it.


01:04:39.320 --> 01:04:41.160
Or if it's like a array or something,


01:04:41.160 --> 01:04:43.160
the D type could get messed up.


01:04:43.160 --> 01:04:44.720
- Yeah, if it implements multiply,


01:04:44.720 --> 01:04:47.240
it expected to receive the five.


01:04:47.240 --> 01:04:51.880
It didn't expect to receive 1.2715


01:04:51.880 --> 01:04:53.680
or whatever the heck that is, right?


01:04:53.680 --> 01:04:54.500
- Yep.


01:04:54.500 --> 01:04:56.460
- Yeah, cool.


01:04:56.460 --> 01:04:59.000
All right, well, this is a really cool tool.


01:04:59.000 --> 01:05:02.240
I definitely encourage people if they're listening,


01:05:02.240 --> 01:05:06.280
just come over and just, there's pictures of code and color.


01:05:06.280 --> 01:05:07.880
Just scroll quickly through it


01:05:07.880 --> 01:05:09.480
to see what we're talking about.


01:05:09.480 --> 01:05:12.200
And I find it super valuable


01:05:12.200 --> 01:05:15.100
because it highlights with color


01:05:15.100 --> 01:05:16.480
right on the code that you wrote.


01:05:16.480 --> 01:05:17.840
It doesn't spit out the byte code


01:05:17.840 --> 01:05:19.460
and say here's the byte code improvements,


01:05:19.460 --> 01:05:22.400
but it highlights your code and says the code you wrote


01:05:22.400 --> 01:05:25.280
is being improved by Python


01:05:25.280 --> 01:05:28.800
or not being improved by Python here, right?


01:05:28.800 --> 01:05:31.320
And just understanding that it might not matter


01:05:31.320 --> 01:05:33.460
and it might matter a lot to you, it depends.


01:05:33.460 --> 01:05:35.440
- Yeah, and another thing to highlight too


01:05:35.440 --> 01:05:36.860
that's kind of different about this tool


01:05:36.860 --> 01:05:39.520
from maybe most tools that you would use is,


01:05:39.520 --> 01:05:42.600
this isn't static analysis.


01:05:42.600 --> 01:05:46.160
It's not like mypy or PyLint where it's running over your code


01:05:46.160 --> 01:05:47.080
just in its file.


01:05:47.080 --> 01:05:49.760
You actually need to run your code under this tool


01:05:49.760 --> 01:05:51.520
for it to be able to do its thing.


01:05:51.520 --> 01:05:53.560
'Cause again, all this happens at runtime,


01:05:53.560 --> 01:05:56.320
so it's only after running the code


01:05:56.320 --> 01:05:58.560
that specialists can walk over and see


01:05:58.560 --> 01:05:59.920
where they've adapted. - Running the code,


01:05:59.920 --> 01:06:01.480
enough, right?


01:06:01.480 --> 01:06:05.240
- Yes, yeah, so for example, if I just had this function


01:06:05.240 --> 01:06:07.560
and I didn't actually call test conversions


01:06:07.560 --> 01:06:11.040
at the bottom there, at the dunder name equals main,


01:06:11.040 --> 01:06:12.520
everything would just be white,


01:06:12.520 --> 01:06:14.520
because nothing actually ran.


01:06:14.520 --> 01:06:16.960
- Right, right, so in this example here,


01:06:16.960 --> 01:06:20.000
you've got, let's see, two, four, six, eight, nine,


01:06:20.000 --> 01:06:21.320
surprising that number.


01:06:21.320 --> 01:06:23.920
You have nine test values that you're passing in,


01:06:23.920 --> 01:06:26.160
and you're looping over all those values and testing it.


01:06:26.160 --> 01:06:28.780
So you need to, if you're gonna apply this to your code,


01:06:28.780 --> 01:06:31.080
it's super important that you come up with a scenario


01:06:31.080 --> 01:06:36.080
of representative data, for now, n greater than eight.


01:06:36.840 --> 01:06:40.200
>> Or it's something that's loopy,


01:06:40.200 --> 01:06:43.320
it runs loops eight times or something.


01:06:43.320 --> 01:06:47.640
Basically, if the same bytecode instructions are being executed a bunch of times,


01:06:47.640 --> 01:06:48.920
that's how we tell that it's hot,


01:06:48.920 --> 01:06:52.720
whether that's in a loop or from repeated calls or whatever.


01:06:52.720 --> 01:06:55.200
>> I can see it's pretty easy to forget that,


01:06:55.200 --> 01:06:57.160
and people might run and go, "It didn't do anything.


01:06:57.160 --> 01:06:58.920
It did nothing. It's just all white."


01:06:58.920 --> 01:07:00.920
>> Yeah.


01:07:00.920 --> 01:07:03.000
>> Maybe you should add.


01:07:03.000 --> 01:07:08.000
I mean, I'm not trying to issue an audio PR or anything,


01:07:08.000 --> 01:07:09.640
but maybe it should have some kind of warning.


01:07:09.640 --> 01:07:12.840
Like if there's zero color at all, like a warning,


01:07:12.840 --> 01:07:13.920
like, are you sure you ran it?


01:07:13.920 --> 01:07:16.160
Because we don't think you did anything.


01:07:16.160 --> 01:07:17.880
- I actually really liked that request.


01:07:17.880 --> 01:07:18.720
I'm gonna do that.


01:07:18.720 --> 01:07:21.480
(laughing)


01:07:21.480 --> 01:07:22.640
- Yeah, 'cause you would know, right?


01:07:22.640 --> 01:07:23.480
Like you'd know if like,


01:07:23.480 --> 01:07:26.680
I've colored nothing in any color whatsoever.


01:07:26.680 --> 01:07:27.520
- Yes.


01:07:27.520 --> 01:07:28.360
- And something's up.


01:07:28.360 --> 01:07:29.180
- Yeah, and I look at it, I'm like,


01:07:29.180 --> 01:07:30.020
oh, I did something wrong.


01:07:30.020 --> 01:07:30.840
But someone else is gonna be like,


01:07:30.840 --> 01:07:31.680
Brent did something wrong.


01:07:31.680 --> 01:07:32.520
- Yes, exactly.


01:07:32.520 --> 01:07:35.360
- Got to protect my reputation, yeah.


01:07:35.360 --> 01:07:39.720
- Well, and just like limit the issues being raised.


01:07:39.720 --> 01:07:41.200
Like how many times do you want to say,


01:07:41.200 --> 01:07:44.480
did you remember to call it enough times?


01:07:44.480 --> 01:07:45.320
Yeah.


01:07:45.320 --> 01:07:46.920
- Yeah.


01:07:46.920 --> 01:07:48.800
- Cool, I definitely think people should check this out


01:07:48.800 --> 01:07:51.000
if they're interested in seeing how


01:07:51.000 --> 01:07:53.200
the adaptive specializing,


01:07:53.200 --> 01:07:56.720
specializing adaptive interpreter from Python 3.11


01:07:56.720 --> 01:07:57.640
is applied to their code.


01:07:57.640 --> 01:08:01.000
I guess also other caveat, like really not super handy


01:08:01.000 --> 01:08:03.400
if you try to do this with 3.10, you gotta have 3.11?


01:08:03.400 --> 01:08:06.200
It refuses to run under 3.10.


01:08:06.200 --> 01:08:09.700
Just because I accidentally made that mistake enough times


01:08:09.700 --> 01:08:13.000
where I just had the Python environment I had active was 3.10


01:08:13.000 --> 01:08:14.600
and like, it's not working.


01:08:14.600 --> 01:08:17.300
The keyword argument doesn't exist.


01:08:17.300 --> 01:08:18.400
Yeah, all that stuff.


01:08:18.400 --> 01:08:19.200
Yeah, yeah, yeah.


01:08:19.200 --> 01:08:22.400
So, so yeah, no, you need to be running 3.12, but,


01:08:22.400 --> 01:08:24.900
or sorry, 3.11 or 3.12.


01:08:24.900 --> 01:08:28.600
But, you know, as you showed earlier,


01:08:28.600 --> 01:08:30.400
you can download it from python.org.


01:08:30.400 --> 01:08:35.400
My favorite way of installing Python versions, Pyenv,


01:08:35.400 --> 01:08:38.400
has had 3.11 dev for a while now.


01:08:38.400 --> 01:08:43.400
They also have 3.12 dev if you are crazy and you want to try it out.


01:08:43.400 --> 01:08:47.400
But yeah, you do need a 3.11 to use this.


01:08:47.400 --> 01:08:48.400
Fantastic.


01:08:48.400 --> 01:08:49.400
Well, really great work.


01:08:49.400 --> 01:08:52.400
I think it's quite a contribution.


01:08:52.400 --> 01:08:55.400
It really highlights all the work that's being done in 3.11.


01:08:55.400 --> 01:08:58.400
So well done.


01:08:58.400 --> 01:08:59.400
Thanks.


01:08:59.400 --> 01:09:01.400
All right, now, before you get out of here,


01:09:01.400 --> 01:09:03.400
I gotta ask you the final two questions.


01:09:03.400 --> 01:09:05.240
If you're gonna write some Python code,


01:09:05.240 --> 01:09:07.280
if you're gonna work on specialist,


01:09:07.280 --> 01:09:09.480
what editor do you use?


01:09:09.480 --> 01:09:10.920
- I use VS Code.


01:09:10.920 --> 01:09:12.000
- Okay, right on.


01:09:12.000 --> 01:09:14.400
And then notable PyPI package,


01:09:14.400 --> 01:09:16.640
something you came across, like, oh, this thing is cool.


01:09:16.640 --> 01:09:19.680
Maybe not the most popular, but something that--


01:09:19.680 --> 01:09:21.400
- Yeah, I thought about this.


01:09:21.400 --> 01:09:22.320
Can I say two?


01:09:22.320 --> 01:09:23.600
Is it only a little bit more? - Yeah, two is fine.


01:09:23.600 --> 01:09:24.440
No, two's good. - Okay, cool.


01:09:24.440 --> 01:09:26.360
So there's two, I really like


01:09:28.160 --> 01:09:32.360
creative packages that kind of blur the line between what is Python and what isn't.


01:09:32.360 --> 01:09:36.880
So the first one is called PyMetal3, PyMTL3.


01:09:36.880 --> 01:09:41.080
It's just M-T-L, yeah, three.


01:09:41.080 --> 01:09:44.840
This is so cool, it allows you to design hardware using Python.


01:09:44.840 --> 01:09:53.280
And you can basically design everything from just a small set of logic gates


01:09:53.280 --> 01:09:58.080
to a full chip and then export it to Verilog


01:09:58.080 --> 01:09:59.440
and run it on an FPGA.


01:09:59.440 --> 01:10:02.400
And this is kind of my hardware background coming through.


01:10:02.400 --> 01:10:06.480
But yeah, my brother is actually studying


01:10:06.480 --> 01:10:08.480
at Cal Poly San Luis Obispo right now.


01:10:08.480 --> 01:10:10.760
And he is on a research team that's


01:10:10.760 --> 01:10:15.280
designing an entire processor in Python.


01:10:15.280 --> 01:10:19.520
And so basically, the processor itself is designed in Python.


01:10:19.520 --> 01:10:21.080
And you can test it with Python.


01:10:21.080 --> 01:10:22.680
So they're testing with hypothesis.


01:10:22.680 --> 01:10:26.300
And it's a really cool, creative way


01:10:26.300 --> 01:10:29.200
of doing this sort of stuff.


01:10:29.200 --> 01:10:31.000
>> Yeah, you don't need any special hardware


01:10:31.000 --> 01:10:33.240
to make it happen either, right?


01:10:33.240 --> 01:10:35.120
>> Yeah, exactly.


01:10:35.120 --> 01:10:37.040
You can just run it on your local machine,


01:10:37.040 --> 01:10:39.720
and now you've got a RISC-V chip running.


01:10:39.720 --> 01:10:40.720
>> Nice.


01:10:40.720 --> 01:10:44.560
>> Yeah, so the other one is another kind of cool, weird,


01:10:44.560 --> 01:10:47.840
low-level hardware-y package.


01:10:47.840 --> 01:10:49.720
I don't know if it counts as pip installable.


01:10:49.720 --> 01:10:51.160
It's called PeachPi.


01:10:51.160 --> 01:10:53.240
I don't know how well maintained it is,


01:10:53.240 --> 01:10:55.200
but you have to do that thing.


01:10:55.200 --> 01:11:00.160
Yeah, you have to do that thing where you tell pip to install


01:11:00.160 --> 01:11:02.160
from like a GitHub link.


01:11:02.160 --> 01:11:04.800
- All right, well, you can pip install from a GitHub link.


01:11:04.800 --> 01:11:07.960
Just, you gotta give it a really weird URL.


01:11:07.960 --> 01:11:09.360
It said just, yeah, yeah, yeah, yeah.


01:11:09.360 --> 01:11:10.520
Okay, got it, sure.


01:11:10.520 --> 01:11:11.800
- And so this is super cool.


01:11:11.800 --> 01:11:16.440
It's an x86_64 assembler in Python.


01:11:16.440 --> 01:11:21.200
So with this, you can basically implement a compiler,


01:11:21.200 --> 01:11:25.320
or if you feel like it, a just-in-time compiler


01:11:25.320 --> 01:11:27.680
for basically x86 hardware.


01:11:27.680 --> 01:11:31.200
So what this allows you to do is, in your Python code,


01:11:31.200 --> 01:11:34.600
it takes care of doing things like allocating hardware


01:11:34.600 --> 01:11:40.080
registers and labeling jumps and all that sort of stuff,


01:11:40.080 --> 01:11:42.040
calling conventions.


01:11:42.040 --> 01:11:45.160
And so you can specify exactly what assembly instructions


01:11:45.160 --> 01:11:47.840
you want to execute, assemble them,


01:11:47.840 --> 01:11:51.240
and then it will package them up in a Python function object,


01:11:51.240 --> 01:11:54.400
and you can call your assembly code from Python,


01:11:54.400 --> 01:11:55.640
which I think is so cool.


01:11:55.640 --> 01:12:00.440
- Wow, and it actually executes as assembly instructions?


01:12:00.440 --> 01:12:03.520
- Yes, yeah, so it's like faults and everything, yeah.


01:12:03.520 --> 01:12:04.920
- Well, yeah, of course.


01:12:04.920 --> 01:12:06.880
It's the most common thing it does.


01:12:06.880 --> 01:12:08.680
- Yeah, but I mean, like a simple example,


01:12:08.680 --> 01:12:11.000
you can pass in a Py object pointer,


01:12:11.000 --> 01:12:14.040
and then add, you know, eight or 16 or whatever


01:12:14.040 --> 01:12:16.420
to get the type of it and then return that


01:12:16.420 --> 01:12:18.380
and it will return the type.


01:12:18.380 --> 01:12:19.220
- Yeah, very cool.


01:12:19.220 --> 01:12:23.580
So you can see the code example on here for PeachBuy.


01:12:23.580 --> 01:12:24.860
I'll put the link in the show notes,


01:12:24.860 --> 01:12:27.020
but you do things like create an argument


01:12:27.020 --> 01:12:29.060
and then you create a general purpose register


01:12:29.060 --> 01:12:32.380
and you load the argument onto the register and whatnot.


01:12:32.380 --> 01:12:35.980
And you might call them the ISA SSE4 operation


01:12:35.980 --> 01:12:37.500
or whatever, pretty cool.


01:12:37.500 --> 01:12:38.620
- Yep.


01:12:38.620 --> 01:12:41.600
- Yeah, those are really, two really good ones.


01:12:41.600 --> 01:12:43.900
All right, final call to action.


01:12:43.900 --> 01:12:48.900
people are interested in Specialist and exploring the specializing adaptive interpreter.


01:12:48.900 --> 01:12:49.900
What do you tell them?


01:12:49.900 --> 01:12:56.900
I think the most important thing you can do is download or if you're feeling like it, build Python 3.11


01:12:56.900 --> 01:12:59.900
and try running it for yourself. See if your code gets faster.


01:12:59.900 --> 01:13:05.900
It probably will. If it doesn't, then Specialist could help show you where it's not.


01:13:05.900 --> 01:13:10.900
And if that is surprising to you, then you could report it to us.


01:13:10.900 --> 01:13:14.900
It's like, "Oh, my code got slower for some reason."


01:13:14.900 --> 01:13:19.900
And it looks like this specific pattern is what's causing it.


01:13:19.900 --> 01:13:21.900
That's something that we care about.


01:13:21.900 --> 01:13:27.900
Yeah, I suspect this interpreter is something that's never done.


01:13:27.900 --> 01:13:29.900
Yeah, there's always...


01:13:29.900 --> 01:13:31.900
You can always add more cases.


01:13:31.900 --> 01:13:35.900
Yeah, I mean, it's clear you could always add more cases.


01:13:35.900 --> 01:13:40.900
you could make it decide sooner or easier


01:13:40.900 --> 01:13:44.920
or more accurately when and how to specialize


01:13:44.920 --> 01:13:47.240
and add more by, there's like a lot of stuff you could do,


01:13:47.240 --> 01:13:51.080
right, as opposed to, well, yeah, now you read CSV file,


01:13:51.080 --> 01:13:53.000
that part is done.


01:13:53.000 --> 01:13:54.800
- Yeah, and again, if you're feeling up to it


01:13:54.800 --> 01:13:57.000
and you've got a huge pure Python app,


01:13:57.000 --> 01:13:59.520
you can even compile with stats and dump that out


01:13:59.520 --> 01:14:00.980
and take a peek at it.


01:14:00.980 --> 01:14:05.840
And, you know, we, I think you showed our repository earlier


01:14:05.840 --> 01:14:07.040
where we have our issue tracker,


01:14:07.040 --> 01:14:09.040
where we kind of just spitball ideas


01:14:09.040 --> 01:14:11.200
and keep track of work in progress.


01:14:11.200 --> 01:14:12.040
Yeah, this one.


01:14:12.040 --> 01:14:13.680
If you go to the issue tracker here.


01:14:13.680 --> 01:14:14.520
- Ah, sorry, I was wrong.


01:14:14.520 --> 01:14:15.680
And the ideas one, yeah.


01:14:15.680 --> 01:14:20.080
So you've got, it's faster-cpython/ideas on GitHub.


01:14:20.080 --> 01:14:21.580
- Yeah, so if you go to issues there,


01:14:21.580 --> 01:14:22.880
that's all our work in progress.


01:14:22.880 --> 01:14:26.520
And if you have experience optimizing dynamic languages


01:14:26.520 --> 01:14:28.240
or if you see a cool research paper


01:14:28.240 --> 01:14:30.240
or something that you want us to know about,


01:14:30.240 --> 01:14:33.280
you can open an issue here and, you know,


01:14:33.280 --> 01:14:35.660
this is where things get done.


01:14:35.660 --> 01:14:37.580
- Yeah, fantastic.


01:14:37.580 --> 01:14:40.380
Well, thank you for making Python faster.


01:14:40.380 --> 01:14:42.540
I think it's really, really important.


01:14:42.540 --> 01:14:45.020
I mean, I'm always a little bit conflicted


01:14:45.020 --> 01:14:48.580
because I have some pretty complicated web apps


01:14:48.580 --> 01:14:50.460
that get a decent amount of traffic


01:14:50.460 --> 01:14:52.940
and they've been fine, like really, really fine.


01:14:52.940 --> 01:14:56.300
You know, handful of milliseconds response time


01:14:56.300 --> 01:14:59.380
and they're doing all sorts of madness with databases


01:14:59.380 --> 01:15:01.800
and HTML and all kinds of stuff.


01:15:01.800 --> 01:15:02.900
So on one hand,


01:15:03.860 --> 01:15:05.980
I don't know if I need Python to be faster.


01:15:05.980 --> 01:15:07.780
But on the other, you know,


01:15:07.780 --> 01:15:10.340
people are deciding which language they're going to choose


01:15:10.340 --> 01:15:12.340
and where they can do their work.


01:15:12.340 --> 01:15:16.440
And sometimes, either perceived or real reasons,


01:15:16.440 --> 01:15:20.060
people think Python is not fast enough, right?


01:15:20.060 --> 01:15:22.260
And so this is important work


01:15:22.260 --> 01:15:24.140
that will really help some people


01:15:24.140 --> 01:15:26.060
and will help the community be stronger.


01:15:26.060 --> 01:15:27.540
So thank you.


01:15:27.540 --> 01:15:29.780
- Yeah, we love Python programmers.


01:15:29.780 --> 01:15:30.620
- Right on.


01:15:30.620 --> 01:15:32.340
All right, cool.


01:15:32.340 --> 01:15:34.020
Thank you so much for being here.


01:15:34.020 --> 01:15:35.180
It's great to chat with you.


01:15:35.180 --> 01:15:36.740
>> Yeah. Thanks again for having me.


01:15:36.740 --> 01:15:38.820
>> Yeah, you bet. Bye.

